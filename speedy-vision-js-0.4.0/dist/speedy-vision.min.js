/*!
 * speedy-vision.js v0.4.0
 * GPU-accelerated Computer Vision for JavaScript
 * https://github.com/alemart/speedy-vision-js
 * 
 * Copyright 2020 Alexandre Martins <alemartf(at)gmail.com> (https://github.com/alemart)
 * @license Apache-2.0
 * 
 * Date: 2020-10-08T15:27:02.948Z
 */
var Speedy=function(e){var t={};function i(n){if(t[n])return t[n].exports;var r=t[n]={i:n,l:!1,exports:{}};return e[n].call(r.exports,r,r.exports,i),r.l=!0,r.exports}return i.m=e,i.c=t,i.d=function(e,t,n){i.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:n})},i.r=function(e){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},i.t=function(e,t){if(1&t&&(e=i(e)),8&t)return e;if(4&t&&"object"==typeof e&&e&&e.__esModule)return e;var n=Object.create(null);if(i.r(n),Object.defineProperty(n,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var r in e)i.d(n,r,function(t){return e[t]}.bind(null,r));return n},i.n=function(e){var t=e&&e.__esModule?function(){return e.default}:function(){return e};return i.d(t,"a",t),t},i.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},i.p="",i(i.s=15)}([function(e,t,i){"use strict";i.d(t,"i",(function(){return r})),i.d(t,"h",(function(){return s})),i.d(t,"e",(function(){return o})),i.d(t,"a",(function(){return a})),i.d(t,"f",(function(){return c})),i.d(t,"g",(function(){return l})),i.d(t,"d",(function(){return d})),i.d(t,"k",(function(){return f})),i.d(t,"j",(function(){return p})),i.d(t,"c",(function(){return h})),i.d(t,"b",(function(){return u}));class n extends Error{constructor(e,t=null){super([e,t?t.toString():"[speedy-vision.js]"].join("\n-> ")),this._cause=t}get name(){return this.constructor.name}set name(e){}get cause(){return this._cause}}class r extends n{constructor(e="",t=null){super("Unsupported operation. "+e,t)}}class s extends n{constructor(e="",t=null){super("Method not implemented. "+e,t)}}class o extends n{constructor(e="",t=null){super("WebGL error. "+e,t)}}class a extends n{constructor(e="",t=null){super("Can't call abstract method. "+e,t)}}class c extends n{constructor(e="",t=null){super("Illegal argument. "+e,t)}}class l extends n{constructor(e="",t=null){super("Illegal operation. "+e,t)}}class d extends n{constructor(e="",t=null){super("File not found. "+e,t)}}class f extends n{constructor(e="",t=null){super("Timeout error. "+e,t)}}class p extends n{constructor(e="",t=null){super("Parse error. "+e,t)}}class h extends n{constructor(e="",t=null){super("Assertion failed. "+e,t)}}class u extends n{constructor(e="",t=null){super("Access denied. "+e,t)}}},function(e,t,i){"use strict";i.d(t,"b",(function(){return h})),i.d(t,"a",(function(){return u}));var n=i(5),r=i(4),s=i(0);const o=[/\/\*(.|\s)*?\*\//g,/\/\/.*$/gm],a=/^\s*@\s*include\s+"(.*?)"/gm,c=/@(\w+)@/g,l={MAX_TEXTURE_LENGTH:n.d,PYRAMID_MAX_LEVELS:n.e,LOG2_PYRAMID_MAX_SCALE:n.c,PYRAMID_MAX_OCTAVES:n.f,PIXELCOMPONENT_RED:r.d.RED,PIXELCOMPONENT_GREEN:r.d.GREEN,PIXELCOMPONENT_BLUE:r.d.BLUE,PIXELCOMPONENT_ALPHA:r.d.ALPHA,FIX_BITS:n.a,FIX_RESOLUTION:n.b};class d{static run(e){return String(e).replace(o[0],"").replace(o[1],"").replace(a,(e,t)=>d.run(function(e){if(String(e).match(/^[a-zA-Z0-9_\-]+\.glsl$/))return i(16)("./"+e);throw new s.d(`Shader preprocessor: can't read file "${e}"`)}(t))).replace(c,(e,t)=>String(l[t]||"UNDEFINED_CONSTANT"))}}const f='#version 300 es\nprecision highp int;\nprecision mediump float;\nprecision mediump sampler2D;\n\nout vec4 color;\nin vec2 texCoord;\nuniform vec2 texSize;\n\n@include "global.glsl"\n';class p{constructor(e){const t=e.filepath||null,n=t?i(17)("./"+t):e.source||"";this._userSource=n,this._fragmentSource=d.run(f+n),this._vertexSource=d.run("#version 300 es\nin vec2 a_position;\nin vec2 a_texCoord;\nout vec2 texCoord;\n\nvoid main() {\n    gl_Position = vec4(a_position, 0.0, 1.0);\n    texCoord = a_texCoord;\n}"),this._filepath=t||"<in-memory>",this._uniform=this._autodetectUniforms(this._fragmentSource),this._arguments=[]}static create(e){return new p({source:e})}static import(e){if(!String(e).match(/^[a-zA-Z0-9_\-\/]+\.glsl$/))throw new s.d(`Can't import shader: "${e}"`);return new p({filepath:e})}withArguments(...e){this._arguments=e.map(e=>String(e));for(const e of this._arguments)if(!this._uniform.hasOwnProperty(e)&&!this._uniform.hasOwnProperty(e+"[0]"))throw new s.f(`Argument "${e}" has not been declared in the shader`);return this}withDefines(e){const t=[];for(const i of Object.keys(e))t.push(`#define ${i} ${e[i]}\n`);const i=f+t.join("")+this._userSource;return this._fragmentSource=d.run(i),this}get fragmentSource(){return this._fragmentSource}get vertexSource(){return this._vertexSource}get attributes(){return p._attr||(p._attr=Object.freeze({position:"a_position",texCoord:"a_texCoord"}))}get arguments(){return this._arguments}get uniforms(){return Object.keys(this._uniform)}uniformType(e){if(!this._uniform.hasOwnProperty(e))throw new s.f(`Unrecognized uniform variable: "${e}"`);return this._uniform[e]}_autodetectUniforms(e){const t=e,i=/^\s*uniform\s+(highp\s+|mediump\s+|lowp\s+)?(\w+)\s+([^;]+)/gm,n={};let r;for(;null!==(r=i.exec(t));){const e=r[2],t=r[3].split(",").map(e=>e.trim()).filter(e=>e);for(const i of t)if(i.endsWith("]")){if(!(r=i.match(/(\w+)\s*\[\s*(\d+)\s*\]$/)))throw new s.j(`Unspecified array length for uniform "${i}" in the shader`);const[t,o]=[r[1],Number(r[2])];for(let i=0;i<o;i++)n[`${t}[${i}]`]=e}else n[i]=e}return Object.freeze(n)}}function h(e){return p.import(e)}function u(e){return p.create(e)}},function(e,t,i){"use strict";i.d(t,"a",(function(){return r}));var n=i(0);class r{static warning(e,...t){const i=[e,...t].join(" ");return console.warn("[speedy-vision.js]",i),i}static log(e,...t){return[e,...t].join(" ")}static assert(e,t=""){if(!e)throw new n.c(t)}static enum(...e){return Object.freeze(e.reduce((e,t)=>(e[t]=Symbol(t),e),{}))}static get setZeroTimeout(){return this._setZeroTimeout||(this._setZeroTimeout=(()=>{const e="0%"+Math.random().toString(36).slice(2),t=[];return window.addEventListener("message",i=>{i.source===window&&i.data===e&&(event.stopPropagation(),t.shift().call(window))},!0),function(i){t.push(i),window.postMessage(e,"*")}})())}static functionArguments(e){const t=e.toString(),i=t.startsWith("function")?"function\\s.*\\(([^)]*)\\)":t.startsWith("(")?"\\(([^)]*)\\).*=>":"([^=]+).*=>",r=new RegExp(i).exec(t);if(null!==r){return r[1].replace(/\/\*.*?\*\//g,"").split(",").map(e=>e.replace(/=.*$/,"").trim()).filter(e=>e)}throw new n.j("Can't detect function arguments of "+t)}static getAllPropertyDescriptors(e){if(e){const t=Object.getPrototypeOf(e);return{...r.getAllPropertyDescriptors(t),...Object.getOwnPropertyDescriptors(e)}}return Object.create(null)}static createCanvas(e,t){const i=document.createElement("canvas");return i.width=e,i.height=t,i}static gaussianNoise(e=0,t=1){const i=2*Math.PI;let n,r=Math.random();do{n=Math.random()}while(n<=Number.EPSILON);return Math.sqrt(-2*Math.log(n))*Math.sin(i*r)*t+e}static gaussianKernel(e,t=-1,i=!0){if(t<0&&(t=0|Math.ceil(5*e),t+=1-t%2),(t|=0)<1||t%2==0)throw new n.f(`Invalid kernel size given to gaussianKernel: ${t} x 1`);if(e<=0)throw new n.f("Invalid sigma given to gaussianKernel: "+e);const r=new Array(t),s=t>>1,o=1.4142135623730951*+e,a=.3275911,c=.254829592,l=-.284496736,d=1.421413741,f=-1.453152027,p=1.061405429;let h=0;for(let e=0;e<t;e++){let t=(e-s+.5)/o,i=(e-s-.5)/o,n=1,u=1;t<0&&(n=-1,t=-t),i<0&&(u=-1,i=-i);const m=1/(1+a*t),v=1/(1+a*i),g=((((p*v+f)*v+d)*v+l)*v+c)*v,_=(n*(1-((((p*m+f)*m+d)*m+l)*m+c)*m*Math.exp(-t*t))-u*(1-g*Math.exp(-i*i)))/(2*o);r[e]=_,h+=_}return i?r.map(e=>e/h):r}static cartesian(e,t){return[].concat(...e.map(e=>t.map(t=>[e,t])))}static symmetricRange(e){if((e|=0)<0)throw new n.f("Expected a non-negative integer as input");return[...Array(2*e+1).keys()].map(t=>t-e)}static range(e){if((e|=0)<=0)throw new n.f("Expected a positive integer as input");return[...Array(e).keys()]}}},function(e,t,i){"use strict";i.r(t),i.d(t,"conv2D",(function(){return o})),i.d(t,"convX",(function(){return a})),i.d(t,"convY",(function(){return c})),i.d(t,"createKernel2D",(function(){return d})),i.d(t,"createKernel1D",(function(){return f})),i.d(t,"texConv2D",(function(){return p})),i.d(t,"texConvX",(function(){return h})),i.d(t,"texConvY",(function(){return u}));var n=i(1),r=i(2),s=i(0);function o(e,t=1){const i=new Float32Array(e.map(e=>+e*+t)),o=0|Math.sqrt(i.length),a=o>>1;if(o<1||o%2==0)throw new s.f("Can't perform a 2D convolution with an invalid kSize of "+o);if(o*o!=i.length)throw new s.f(`Invalid 2D convolution kernel of ${i.length} elements (expected: square)`);const c=a<=7?"pixelAtShortOffset":"pixelAtLongOffset",l=`\n    uniform sampler2D image;\n\n    void main()\n    {\n        float alpha = threadPixel(image).a;\n        vec4 result = vec4(0.0f, 0.0f, 0.0f, 0.0f);\n\n        ${d=(e,t,i)=>`\n        result += ${c}(image, ivec2(${0|i}, ${0|t})) * float(${+e});\n    `,r.a.cartesian(r.a.symmetricRange(a),r.a.symmetricRange(a)).map(e=>d(i[(e[0]+a)*o+(e[1]+a)],e[0],e[1])).join("\n")}\n\n        color = vec4(result.rgb, alpha);\n    }\n    `;var d;return Object(n.a)(l).withArguments("image")}function a(e,t=1){return l("x",e,t)}function c(e,t=1){return l("y",e,t)}function l(e,t,i=1){const o=new Float32Array(t.map(e=>+e*+i)),a=o.length,c=a>>1;if(a<1||a%2==0)throw new s.f("Can't perform a 1D convolution with an invalid kSize of "+a);if("x"!=e&&"y"!=e)throw new s.f(`Can't perform 1D convolution: invalid axis "${e}"`);const l=c<=7?"pixelAtShortOffset":"pixelAtLongOffset",d=`\n    uniform sampler2D image;\n\n    void main()\n    {\n        float alpha = threadPixel(image).a;\n        vec4 pixel = vec4(0.0f, 0.0f, 0.0f, 0.0f);\n\n        ${f=(t,i)=>"x"==e?`\n        pixel += ${l}(image, ivec2(${0|i}, 0)) * float(${+t});\n    `:`\n        pixel += ${l}(image, ivec2(0, ${0|i})) * float(${+t});\n    `,r.a.symmetricRange(c).reduce((e,t)=>e+f(o[t+c],t),"")}\n\n        color = vec4(pixel.rgb, alpha);\n    }\n    `;var f;return Object(n.a)(d).withArguments("image")}function d(e){if((e|=0)<1||e%2==0)throw new s.f("Can't create a 2D texture kernel of size "+e);const t=`\n    uniform float kernel[${e*e}];\n\n    void main()\n    {\n        ivec2 thread = threadLocation();\n        float val = kernel[(${e}) * thread.y + thread.x];\n\n        float e0 = floor(val);\n        float e1 = 256.0f * fract(val);\n        float e2 = 256.0f * fract(e1);\n        float e3 = 256.0f * fract(e2);\n\n        color = vec4(e0, floor(e1) / 256.0f, floor(e2) / 256.0f, floor(e3) / 256.0f);\n    }\n    `;return Object(n.a)(t).withArguments("kernel")}function f(e){if((e|=0)<1||e%2==0)throw new s.f("Can't create a 1D texture kernel of size "+e);const t=`\n    uniform float kernel[${e}];\n\n    void main()\n    {\n        ivec2 thread = threadLocation();\n        float val = kernel[thread.x];\n\n        float e0 = floor(val);\n        float e1 = 256.0f * fract(val);\n        float e2 = 256.0f * fract(e1);\n        float e3 = 256.0f * fract(e2);\n\n        color = vec4(e0, floor(e1) / 256.0f, floor(e2) / 256.0f, floor(e3) / 256.0f);\n    }\n    `;return Object(n.a)(t).withArguments("kernel")}function p(e){const t=e>>1;if(e<1||e%2==0)throw new s.f("Can't perform a texture-based 2D convolution with an invalid kernel size of "+e);const i=t<=7?"pixelAtShortOffset":"pixelAtLongOffset",o=`\n    const vec4 magic = vec4(1.0f, 1.0f, 1.0f / 256.0f, 1.0f / 65536.0f);\n    uniform sampler2D image, texKernel;\n    uniform float scale, offset;\n\n    void main()\n    {\n        vec4 kernel = vec4(0.0f, 0.0f, 0.0f, 0.0f);\n        vec4 result = vec4(0.0f, 0.0f, 0.0f, 0.0f);\n        float alpha = threadPixel(image).a;\n        float value = 0.0f;\n\n        ${a=(e,n)=>`\n        kernel = pixelAt(texKernel, ivec2(${e+t}, ${n+t}));\n        value = dot(kernel, magic) * scale + offset;\n        result += ${i}(image, ivec2(${e}, ${n})) * value;\n    `,r.a.cartesian(r.a.symmetricRange(t),r.a.symmetricRange(t)).map(e=>a(e[0],e[1])).join("\n")}\n\n        result = clamp(result, 0.0f, 1.0f);\n        color = vec4(result.rgb, alpha);\n    }\n    `;var a;return Object(n.a)(o).withArguments("image","texKernel","scale","offset")}const h=e=>m(e,"x"),u=e=>m(e,"y");function m(e,t){const i=e>>1;if(e<1||e%2==0)throw new s.f("Can't perform a texture-based 2D convolution with an invalid kernel size of "+e);if("x"!=t&&"y"!=t)throw new s.f(`Can't perform a texture-based 1D convolution: invalid axis "${t}"`);const o=i<=7?"pixelAtShortOffset":"pixelAtLongOffset",a=`\n    const vec4 magic = vec4(1.0f, 1.0f, 1.0f / 256.0f, 1.0f / 65536.0f);\n    uniform sampler2D image, texKernel;\n    uniform float scale, offset;\n\n    void main()\n    {\n        vec4 kernel = vec4(0.0f, 0.0f, 0.0f, 0.0f);\n        vec4 result = vec4(0.0f, 0.0f, 0.0f, 0.0f);\n        float alpha = threadPixel(image).a;\n        float value = 0.0f;\n\n        ${c=e=>"x"==t?`\n        kernel = pixelAt(texKernel, ivec2(${e+i}, 0));\n        value = dot(kernel, magic) * scale + offset;\n        result += ${o}(image, ivec2(${e}, 0)) * value;\n    `:`\n        kernel = pixelAt(texKernel, ivec2(${e+i}, 0));\n        value = dot(kernel, magic) * scale + offset;\n        result += ${o}(image, ivec2(0, ${e})) * value;\n    `,r.a.symmetricRange(i).map(c).join("\n")}\n\n        result = clamp(result, 0.0f, 1.0f);\n        color = vec4(result.rgb, alpha);\n    }\n    `;var c;return Object(n.a)(a).withArguments("image","texKernel","scale","offset")}},function(e,t,i){"use strict";i.d(t,"c",(function(){return r})),i.d(t,"b",(function(){return s})),i.d(t,"d",(function(){return o})),i.d(t,"a",(function(){return a}));var n=i(2);const r=n.a.enum("Image","Video","Canvas","Bitmap"),s=n.a.enum("RGB","Greyscale","Binary"),o=Object.freeze({RED:1,GREEN:2,BLUE:4,ALPHA:8,ALL:15}),a=Object.freeze({[o.RED]:0,[o.GREEN]:1,[o.BLUE]:2,[o.ALPHA]:3})},function(e,t,i){"use strict";i.d(t,"e",(function(){return n})),i.d(t,"f",(function(){return r})),i.d(t,"c",(function(){return s})),i.d(t,"a",(function(){return o})),i.d(t,"b",(function(){return a})),i.d(t,"d",(function(){return c}));const n=4,r=2*n-1,s=Math.log2(2),o=3,a=1*(1<<o),c=(1<<16-o)-2},function(e,t,i){"use strict";i.r(t),i.d(t,"median",(function(){return o}));var n=i(1),r=i(2),s=i(0);function o(e){if((e|=0)<=1||e%2==0)throw new s.f(`Can't create median filter with a ${e}x${e} window`);const t=e>>1,i=t<=7?"pixelAtShortOffset":"pixelAtLongOffset",o=e*e,a=o>>1,c=`\n    uniform sampler2D image;\n\n    void main()\n    {\n        float v[${o}], swpv;\n        int m;\n\n        // read pixels\n        ${l=(e,t,n)=>`\n        v[${e}] = ${i}(image, ivec2(${n}, ${t})).g;\n    `,r.a.cartesian(r.a.symmetricRange(t),r.a.symmetricRange(t)).map((e,t)=>l(t,e[0],e[1])).join("\n")}\n\n        // sort v[0..med]\n        ${(e=>r.a.range(a+1).map(e).join("\n"))(e=>`\n        m = ${e};\n        ${(e=>r.a.range(o-(e+1)).map(t=>t+e+1).map(e=>`\n        m += int(v[${e}] >= v[m]) * (${e} - m);\n    `).join("\n"))(e)}\n        swpv = v[${e}];\n        v[${e}] = v[m];\n        v[m] = swpv;\n    `)}\n\n        // return the median\n        color = vec4(v[${a}], v[${a}], v[${a}], 1.0f);\n    }\n    `;var l;return Object(n.a)(c).withArguments("image")}},function(e,t){e.exports="#ifndef _COLORS_GLSL\n#define _COLORS_GLSL\n#define PIXELCOMPONENT_RED   @PIXELCOMPONENT_RED@\n#define PIXELCOMPONENT_GREEN @PIXELCOMPONENT_GREEN@\n#define PIXELCOMPONENT_BLUE  @PIXELCOMPONENT_BLUE@\n#define PIXELCOMPONENT_ALPHA @PIXELCOMPONENT_ALPHA@\n#endif"},function(e,t){e.exports="#ifndef _FIXEDPOINT_GLSL\n#define _FIXEDPOINT_GLSL\n#define fixed_t int\n#define fixed2_t ivec2\nconst int FIX_BITS = int(@FIX_BITS@);\nconst float FIX_RESOLUTION = float(@FIX_RESOLUTION@);\n#define itofix(x) fixed_t((x) << FIX_BITS)\n#define fixtoi(f) int((x) >> FIX_BITS)\n#define ftofix(x) fixed_t((x) * FIX_RESOLUTION + 0.5f)\n#define fixtof(f) (float(f) / FIX_RESOLUTION)\n#define ivec2tofix(x) fixed2_t((x) << FIX_BITS)\n#define fixtoivec2(f) ivec2((x) >> FIX_BITS)\n#define vec2tofix(v) fixed2_t((v) * FIX_RESOLUTION + vec2(0.5f))\n#define fixtovec2(f) (vec2(f) / FIX_RESOLUTION)\n#endif"},function(e,t){e.exports="#ifndef _GLOBAL_GLSL\n#define _GLOBAL_GLSL\n#define threadLocation() ivec2(texCoord * texSize)\n#define outputSize() ivec2(texSize)\n#define DEBUG(scalar) do { color = vec4(float(scalar), 0.0f, 0.0f, 1.0f); return; } while(false)\n#define threadPixel(img) textureLod((img), texCoord, 0.0f)\n#define pixelAt(img, pos) texelFetch((img), (pos), 0)\n#define pixelAtShortOffset(img, offset) textureLodOffset((img), texCoord, 0.0f, (offset))\n#define pixelAtLongOffset(img, offset) textureLod((img), texCoord + vec2(offset) / texSize, 0.0f)\n#define subpixelAt(img, pos) textureLod((img), ((pos) + vec2(0.5f)) / texSize, 0.0f)\n#endif"},function(e,t){e.exports='#ifndef _KEYPOINTS_GLSL\n#define _KEYPOINTS_GLSL\n@include "pyramids.glsl"\n@include "orientation.glsl"\n@include "fixed-point.glsl"\nstruct Keypoint\n{\nvec2 position;\nfloat orientation;\nfloat lod;\nfloat score;\n};\nstruct KeypointAddress\n{\nint base;\nint offset;\n};\n#define readKeypointData(encodedKeypoints, encoderLength, keypointAddress) texelFetch((encodedKeypoints), ivec2((keypointAddress) % (encoderLength), (keypointAddress) / (encoderLength)), 0)\n#define sizeofEncodedKeypoint(descriptorSize) (8 + (descriptorSize))\n#define findKeypointIndex(address, descriptorSize) ((address).base / ((sizeofEncodedKeypoint(descriptorSize)) / 4))\nKeypointAddress findKeypointAddress(ivec2 thread, int encoderLength, int descriptorSize)\n{\nint threadRaster = thread.y * encoderLength + thread.x;\nint pixelsPerKeypoint = sizeofEncodedKeypoint(descriptorSize) / 4;\nKeypointAddress address;\nint keypointIndex = int(threadRaster / pixelsPerKeypoint);\naddress.base = keypointIndex * pixelsPerKeypoint;\naddress.offset = threadRaster % pixelsPerKeypoint;\nreturn address;\n}\nKeypoint decodeKeypoint(sampler2D encodedKeypoints, int encoderLength, KeypointAddress address)\n{\nKeypoint keypoint;\nint positionAddress = address.base;\nint propertiesAddress = address.base + 1;\nvec4 rawEncodedPosition = readKeypointData(encodedKeypoints, encoderLength, positionAddress);\nivec4 encodedPosition = ivec4(rawEncodedPosition * 255.0f);\nkeypoint.position = fixtovec2(fixed2_t(\nencodedPosition.r | (encodedPosition.g << 8),\nencodedPosition.b | (encodedPosition.a << 8)\n));\nvec4 encodedProperties = readKeypointData(encodedKeypoints, encoderLength, propertiesAddress);\nkeypoint.orientation = decodeOrientation(encodedProperties.g);\nkeypoint.lod = decodeLod(encodedProperties.r);\nkeypoint.score = encodedProperties.b;\nreturn keypoint;\n}\nvec4 encodeKeypointPosition(vec2 position)\n{\nfixed2_t pos = vec2tofix(position);\nfixed2_t lo = pos & 255;\nfixed2_t hi = pos >> 8;\nreturn vec4(float(lo.x), float(hi.x), float(lo.y), float(hi.y)) / 255.0f;\n}\n#define encodeNullKeypointPosition() (vec4(1.0f))\n#define encodeDiscardedKeypointPosition() (vec4(254.0f / 255.0f, vec3(1.0f)))\nbool isDiscardedOrNullKeypoint(Keypoint keypoint)\n{\nconst float F_MAX_TEXTURE_LENGTH = float(@MAX_TEXTURE_LENGTH@);\nreturn keypoint.position.x > F_MAX_TEXTURE_LENGTH || keypoint.position.y > F_MAX_TEXTURE_LENGTH;\n}\n#endif'},function(e,t){e.exports="#ifndef _MATH_GLSL\n#define _MATH_GLSL\n#define TWO_PI          6.28318530718f\n#define PI              3.14159265359f\n#define PI_OVER_2       1.57079632679f\n#define PI_OVER_4       0.78539816339f\n#define INV_PI          0.3183098861837907f\n#define USE_FAST_ATAN\n#ifdef USE_FAST_ATAN\nfloat fastAtan(float x)\n{\nfloat w = 1.0f - abs(x);\nreturn (w >= 0.0f) ?\n(PI_OVER_4 + 0.273f * w) * x :\nsign(x) * PI_OVER_2 - (PI_OVER_4 + 0.273f * (1.0f - abs(1.0f / x))) / x;\n}\n#else\n#define fastAtan(x) atan(x)\n#endif\n#ifdef USE_FAST_ATAN\nfloat fastAtan2(float y, float x)\n{\nreturn (x == 0.0f) ? PI_OVER_2 * sign(y) : fastAtan(y / x) + float(x < 0.0f) * PI * sign(y);\n}\n#else\n#define fastAtan2(y, x) atan((y), (x))\n#endif\n#endif"},function(e,t){e.exports='#ifndef _ORIENTATION_GLSL\n#define _ORIENTATION_GLSL\n@include "math.glsl"\n#define encodeOrientation(angle) ((angle) * INV_PI + 1.0f) * 0.5f\n#define decodeOrientation(value) ((value) * 2.0f - 1.0f) * PI\n#endif'},function(e,t){e.exports="#ifndef _PYRAMIDS_GLSL\n#define _PYRAMIDS_GLSL\n#define pyrPixel(pyr, lod) textureLod((pyr), texCoord, (lod))\n#define pyrPixelAtOffset(pyr, lod, pot, offset) textureLod((pyr), texCoord + ((pot) * vec2(offset)) / texSize, (lod))\n#define pyrPixelAt(pyr, pos, lod) textureLod((pyr), (vec2(pos) + vec2(0.5f)) / texSize, (lod))\n#define pyrPixelAtEx(pyr, pos, lod, pyrBaseSize) textureLod((pyr), (vec2(pos) + vec2(0.5f)) / vec2(pyrBaseSize), (lod))\n#define pyrSubpixelAtEx(pyr, pos, lod, pyrBaseSize) textureLod((pyr), ((pos) + vec2(0.5f)) / vec2(pyrBaseSize), (lod))\n#define pyrSubpixelAtExOffset(pyr, pos, lod, pot, offset, pyrBaseSize) textureLod((pyr), (((pos) + vec2(0.5f)) + ((pot) * vec2(offset))) / vec2(pyrBaseSize), (lod))\nconst int PYRAMID_MAX_OCTAVES = int(@PYRAMID_MAX_OCTAVES@);\nconst int PYRAMID_MAX_LEVELS = int(@PYRAMID_MAX_LEVELS@);\nconst float F_PYRAMID_MAX_LEVELS = float(@PYRAMID_MAX_LEVELS@);\nconst float LOG2_PYRAMID_MAX_SCALE = float(@LOG2_PYRAMID_MAX_SCALE@);\nfloat encodeLod(float lod)\n{\nreturn (LOG2_PYRAMID_MAX_SCALE + lod) / (LOG2_PYRAMID_MAX_SCALE + F_PYRAMID_MAX_LEVELS);\n}\nfloat decodeLod(float encodedLod)\n{\nreturn mix(0.0f,\nencodedLod * (LOG2_PYRAMID_MAX_SCALE + F_PYRAMID_MAX_LEVELS) - LOG2_PYRAMID_MAX_SCALE,\nencodedLod < 1.0f\n);\n}\n#define isSameEncodedLod(alpha1, alpha2) (abs((alpha1) - (alpha2)) < encodedLodEps)\nconst float encodedLodEps = 0.2f / (LOG2_PYRAMID_MAX_SCALE + F_PYRAMID_MAX_LEVELS);\n#endif"},function(e,t){e.exports="#ifndef _SOBEL_GLSL\n#define _SOBEL_GLSL\nvec4 encodeSobel(vec2 df)\n{\nvec2 zeroes = vec2(0.0f, 0.0f);\nvec2 dmax = -max(df, zeroes);\nvec2 dmin = min(df, zeroes);\nreturn exp2(vec4(dmax, dmin));\n}\nvec2 decodeSobel(vec4 encodedSobel)\n{\nvec4 lg = log2(encodedSobel);\nreturn vec2(lg.b - lg.r, lg.a - lg.g);\n}\n#endif"},function(e,t,i){e.exports=i(53).Speedy},function(e,t,i){var n={"./colors.glsl":7,"./fixed-point.glsl":8,"./global.glsl":9,"./keypoints.glsl":10,"./math.glsl":11,"./orientation.glsl":12,"./pyramids.glsl":13,"./sobel.glsl":14};function r(e){var t=s(e);return i(t)}function s(e){if(!i.o(n,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return n[e]}r.keys=function(){return Object.keys(n)},r.resolve=s,e.exports=r,r.id=16},function(e,t,i){var n={"./colors/rgb2grey.glsl":18,"./encoders/encode-keypoint-offsets.glsl":19,"./encoders/encode-keypoints.glsl":20,"./encoders/upload-keypoints.glsl":21,"./enhancements/nightvision.glsl":22,"./enhancements/normalize-image.glsl":23,"./filters/convolution":3,"./filters/convolution.js":3,"./filters/fast-median.glsl":24,"./filters/median":6,"./filters/median.js":6,"./filters/multiscale-sobel.glsl":25,"./include/colors.glsl":7,"./include/fixed-point.glsl":8,"./include/global.glsl":9,"./include/keypoints.glsl":10,"./include/math.glsl":11,"./include/orientation.glsl":12,"./include/pyramids.glsl":13,"./include/sobel.glsl":14,"./keypoints/brisk.glsl":26,"./keypoints/fast-score12.glsl":27,"./keypoints/fast-score16.glsl":28,"./keypoints/fast-score8.glsl":29,"./keypoints/fast5.glsl":30,"./keypoints/fast7.glsl":31,"./keypoints/fast9lg.glsl":32,"./keypoints/harris-cutoff.glsl":33,"./keypoints/multiscale-fast.glsl":34,"./keypoints/multiscale-harris.glsl":35,"./keypoints/multiscale-suppression.glsl":36,"./keypoints/nonmax-suppression.glsl":37,"./keypoints/orb-descriptor.glsl":38,"./keypoints/orientation-via-centroid.glsl":39,"./keypoints/samescale-suppression.glsl":40,"./pyramids/downsample2.glsl":41,"./pyramids/downsample3.glsl":42,"./pyramids/upsample2.glsl":43,"./pyramids/upsample3.glsl":44,"./trackers/lk-discard.glsl":45,"./trackers/lk.glsl":46,"./utils/copy-components.glsl":47,"./utils/fill-components.glsl":48,"./utils/fill.glsl":49,"./utils/flip-y.glsl":50,"./utils/identity.glsl":51,"./utils/scan-minmax2d.glsl":52};function r(e){var t=s(e);return i(t)}function s(e){if(!i.o(n,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return n[e]}r.keys=function(){return Object.keys(n)},r.resolve=s,e.exports=r,r.id=17},function(e,t){e.exports="const vec4 grey = vec4(0.299f, 0.587f, 0.114f, 0.0f);\nuniform sampler2D image;\nvoid main()\n{\nvec4 pixel = threadPixel(image);\nfloat g = dot(pixel, grey);\ncolor = vec4(g, g, g, 1.0f);\n}"},function(e,t){e.exports="uniform sampler2D image;\nuniform ivec2 imageSize;\nuniform int maxIterations;\nvoid main()\n{\nvec4 pixel = threadPixel(image);\nivec2 pos = threadLocation();\nint offset = -1;\nwhile(offset < maxIterations && pos.y < imageSize.y && pixelAt(image, pos).r == 0.0f) {\n++offset;\npos.x = (pos.x + 1) % imageSize.x;\npos.y += int(pos.x == 0);\n}\ncolor = vec4(pixel.r, float(max(0, offset)) / 255.0f, pixel.ba);\n}"},function(e,t){e.exports='@include "keypoints.glsl"\nuniform sampler2D image;\nuniform ivec2 imageSize;\nuniform int encoderLength;\nuniform int descriptorSize;\nbool findQthKeypoint(int q, out ivec2 position, out vec4 pixel)\n{\nint i = 0, p = -1;\nposition = ivec2(0, 0);\nwhile(position.y < imageSize.y) {\npixel = texelFetch(image, position, 0);\np += int(pixel.r > 0.0f);\nif(p == q)\nreturn true;\ni += 1 + int(pixel.g * 255.0f);\nposition = ivec2(i % imageSize.x, i / imageSize.x);\n}\nreturn false;\n}\nvoid main()\n{\nivec2 thread = threadLocation();\nKeypointAddress address = findKeypointAddress(thread, encoderLength, descriptorSize);\nint q = findKeypointIndex(address, descriptorSize);\nivec2 position;\nvec4 pixel;\ncolor = vec4(0.0f);\nif(address.offset > 1)\nreturn;\ncolor = encodeNullKeypointPosition();\nif(!findQthKeypoint(q, position, pixel))\nreturn;\ncolor = (address.offset == 1) ? vec4(\npixel.a,\nencodeOrientation(0.0f),\npixel.r,\n0.0f\n) : encodeKeypointPosition(\nvec2(position)\n);\n}'},function(e,t){e.exports='@include "keypoints.glsl"\nuniform int keypointCount;\nuniform int encoderLength;\nuniform int descriptorSize;\n#ifndef KEYPOINT_BUFFER_LENGTH\n#error Must specify KEYPOINT_BUFFER_LENGTH\n#endif\nlayout(std140) uniform KeypointBuffer\n{\nvec4 keypointBuffer[KEYPOINT_BUFFER_LENGTH];\n};\nvoid main()\n{\nivec2 thread = threadLocation();\nKeypointAddress address = findKeypointAddress(thread, encoderLength, descriptorSize);\nint q = findKeypointIndex(address, descriptorSize);\ncolor = vec4(1.0f);\nif(q >= keypointCount)\nreturn;\nvec4 data = keypointBuffer[q];\nswitch(address.offset) {\ncase 0: {\nfixed2_t pos = vec2tofix(data.xy);\nfixed2_t lo = pos & 255;\nfixed2_t hi = pos >> 8;\ncolor = vec4(float(lo.x), float(hi.x), float(lo.y), float(hi.y)) / 255.0f;\nbreak;\n}\ncase 1: {\nfloat score = data.w;\nfloat scale = encodeLod(data.z);\nfloat rotation = encodeOrientation(0.0f);\ncolor = vec4(scale, rotation, score, 0.0f);\nbreak;\n}\ndefault: {\ncolor = vec4(0.0f);\nbreak;\n}\n}\n}'},function(e,t){e.exports="uniform sampler2D image;\nuniform sampler2D illuminationMap;\nuniform float gain;\nuniform float offset;\nuniform float decay;\nconst mat3 rgb2yuv = mat3(\n0.299f, -0.14713f, 0.615f,\n0.587f, -0.28886f, -0.51499f,\n0.114f, 0.436f, -0.10001f\n);\nconst mat3 yuv2rgb = mat3(\n1.0f, 1.0f, 1.0f,\n0.0f, -0.39465f, 2.03211f,\n1.13983f, -0.58060f, 0.0f\n);\nconst float eps = 0.0001f;\nconst float sqrt2 = 1.4142135623730951f;\nconst float magic = 20.0f;\nconst vec2 center = vec2(0.5f);\nvoid main()\n{\nvec4 pixel = threadPixel(image);\nvec4 imapPixel = threadPixel(illuminationMap);\nfloat lambda = -sqrt2 * log(max(1.0f - decay, eps));\nfloat dist = length(texCoord - center);\nfloat vgain = gain * exp(-lambda * dist);\nfloat normalizedGain = 2.0f * vgain;\nfloat normalizedOffset = 2.0f * offset - 1.0f;\n#ifdef GREYSCALE\nfloat luma = 1.0 / (1.0 + exp(-normalizedGain * magic * (pixel.g - imapPixel.g)));\nluma = clamp(luma + normalizedOffset, 0.0f, 1.0f);\ncolor = vec4(luma, luma, luma, 1.0f);\n#else\nvec3 yuvPixel = rgb2yuv * pixel.rgb;\nvec3 yuvImapPixel = rgb2yuv * imapPixel.rgb;\nfloat luma = 1.0 / (1.0 + exp(-normalizedGain * magic * (yuvPixel.r - yuvImapPixel.r)));\nluma += normalizedOffset;\nvec3 rgbCorrectedPixel = yuv2rgb * vec3(luma, yuvPixel.gb);\nrgbCorrectedPixel = clamp(rgbCorrectedPixel, 0.0f, 1.0f);\ncolor = vec4(rgbCorrectedPixel, 1.0f);\n#endif\n}"},function(e,t){e.exports="#ifdef GREYSCALE\nuniform sampler2D minmax2d;\n#else\nuniform sampler2D minmax2dRGB[3];\n#endif\nuniform float minValue;\nuniform float maxValue;\nconst float eps = 1.0f / 255.0f;\nvoid main()\n{\nvec2 minmax = clamp(vec2(minValue, maxValue), 0.0f, 255.0f) / 255.0f;\nvec4 newMin = vec4(minmax.x);\nvec4 newRange = vec4(minmax.y - minmax.x);\nvec4 alpha = vec4(1.0f, newMin.x, newRange.x, 1.0f);\n#ifdef GREYSCALE\nvec4 pixel = threadPixel(minmax2d);\nmat4 channel = mat4(pixel, pixel, pixel, alpha);\n#else\nmat4 channel = mat4(\nthreadPixel(minmax2dRGB[0]),\nthreadPixel(minmax2dRGB[1]),\nthreadPixel(minmax2dRGB[2]),\nalpha\n);\n#endif\nvec4 oldMin = vec4(channel[0].g, channel[1].g, channel[2].g, channel[3].g);\nvec4 oldRange = max(vec4(channel[0].b, channel[1].b, channel[2].b, channel[3].b), eps);\nvec4 oldIntensity = vec4(channel[0].a, channel[1].a, channel[2].a, channel[3].a);\nvec4 newIntensity = (oldIntensity - oldMin) * newRange / oldRange + newMin;\ncolor = newIntensity;\n}"},function(e,t){e.exports="uniform sampler2D image;\n#define SORT(i, j) t = p[i] + p[j]; p[i] = min(p[i], p[j]); p[j] = t - p[i];\nvoid main()\n{\nfloat median, t;\n#if WINDOW_SIZE == 3\nfloat p[9];\np[0] = pixelAtShortOffset(image, ivec2(-1,-1)).g;\np[1] = pixelAtShortOffset(image, ivec2(0,-1)).g;\np[2] = pixelAtShortOffset(image, ivec2(1,-1)).g;\np[3] = pixelAtShortOffset(image, ivec2(-1,0)).g;\np[4] = pixelAtShortOffset(image, ivec2(0,0)).g;\np[5] = pixelAtShortOffset(image, ivec2(1,0)).g;\np[6] = pixelAtShortOffset(image, ivec2(-1,1)).g;\np[7] = pixelAtShortOffset(image, ivec2(0,1)).g;\np[8] = pixelAtShortOffset(image, ivec2(1,1)).g;\nSORT(1,2);\nSORT(4,5);\nSORT(7,8);\nSORT(0,1);\nSORT(3,4);\nSORT(6,7);\nSORT(1,2);\nSORT(4,5);\nSORT(7,8);\nSORT(0,3);\nSORT(5,8);\nSORT(4,7);\nSORT(3,6);\nSORT(1,4);\nSORT(2,5);\nSORT(4,7);\nSORT(4,2);\nSORT(6,4);\nSORT(4,2);\nmedian = p[4];\n#elif WINDOW_SIZE == 5\nfloat p[25];\np[0] = pixelAtShortOffset(image, ivec2(-2,-2)).g;\np[1] = pixelAtShortOffset(image, ivec2(-1,-2)).g;\np[2] = pixelAtShortOffset(image, ivec2(0,-2)).g;\np[3] = pixelAtShortOffset(image, ivec2(1,-2)).g;\np[4] = pixelAtShortOffset(image, ivec2(2,-2)).g;\np[5] = pixelAtShortOffset(image, ivec2(-2,-1)).g;\np[6] = pixelAtShortOffset(image, ivec2(-1,-1)).g;\np[7] = pixelAtShortOffset(image, ivec2(0,-1)).g;\np[8] = pixelAtShortOffset(image, ivec2(1,-1)).g;\np[9] = pixelAtShortOffset(image, ivec2(2,-1)).g;\np[10] = pixelAtShortOffset(image, ivec2(-2,0)).g;\np[11] = pixelAtShortOffset(image, ivec2(-1,0)).g;\np[12] = pixelAtShortOffset(image, ivec2(0,0)).g;\np[13] = pixelAtShortOffset(image, ivec2(1,0)).g;\np[14] = pixelAtShortOffset(image, ivec2(2,0)).g;\np[15] = pixelAtShortOffset(image, ivec2(-2,1)).g;\np[16] = pixelAtShortOffset(image, ivec2(-1,1)).g;\np[17] = pixelAtShortOffset(image, ivec2(0,1)).g;\np[18] = pixelAtShortOffset(image, ivec2(1,1)).g;\np[19] = pixelAtShortOffset(image, ivec2(2,1)).g;\np[20] = pixelAtShortOffset(image, ivec2(-2,2)).g;\np[21] = pixelAtShortOffset(image, ivec2(-1,2)).g;\np[22] = pixelAtShortOffset(image, ivec2(0,2)).g;\np[23] = pixelAtShortOffset(image, ivec2(1,2)).g;\np[24] = pixelAtShortOffset(image, ivec2(2,2)).g;\nSORT(0,1);\nSORT(3,4);\nSORT(2,4);\nSORT(2,3);\nSORT(6,7);\nSORT(5,7);\nSORT(5,6);\nSORT(9,10);\nSORT(8,10);\nSORT(8,9);\nSORT(12,13);\nSORT(11,13);\nSORT(11,12);\nSORT(15,16);\nSORT(14,16);\nSORT(14,15);\nSORT(18,19);\nSORT(17,19);\nSORT(17,18);\nSORT(21,22);\nSORT(20,22);\nSORT(20,21);\nSORT(23,24);\nSORT(2,5);\nSORT(3,6);\nSORT(0,6);\nSORT(0,3);\nSORT(4,7);\nSORT(1,7);\nSORT(1,4);\nSORT(11,14);\nSORT(8,14);\nSORT(8,11);\nSORT(12,15);\nSORT(9,15);\nSORT(9,12);\nSORT(13,16);\nSORT(10,16);\nSORT(10,13);\nSORT(20,23);\nSORT(17,23);\nSORT(17,20);\nSORT(21,24);\nSORT(18,24);\nSORT(18,21);\nSORT(19,22);\nSORT(8,17);\nSORT(9,18);\nSORT(0,18);\nSORT(0,9);\nSORT(10,19);\nSORT(1,19);\nSORT(1,10);\nSORT(11,20);\nSORT(2,20);\nSORT(2,11);\nSORT(12,21);\nSORT(3,21);\nSORT(3,12);\nSORT(13,22);\nSORT(4,22);\nSORT(4,13);\nSORT(14,23);\nSORT(5,23);\nSORT(5,14);\nSORT(15,24);\nSORT(6,24);\nSORT(6,15);\nSORT(7,16);\nSORT(7,19);\nSORT(13,21);\nSORT(15,23);\nSORT(7,13);\nSORT(7,15);\nSORT(1,9);\nSORT(3,11);\nSORT(5,17);\nSORT(11,17);\nSORT(9,17);\nSORT(4,10);\nSORT(6,12);\nSORT(7,14);\nSORT(4,6);\nSORT(4,7);\nSORT(12,14);\nSORT(10,14);\nSORT(6,7);\nSORT(10,12);\nSORT(6,10);\nSORT(6,17);\nSORT(12,17);\nSORT(7,17);\nSORT(7,10);\nSORT(12,18);\nSORT(7,12);\nSORT(10,18);\nSORT(12,20);\nSORT(10,20);\nSORT(10,12);\nmedian = p[12];\n#else\n#error Unsupported window size\n#endif\ncolor = vec4(median, median, median, 1.0f);\n}"},function(e,t){e.exports='@include "sobel.glsl"\n@include "pyramids.glsl"\nuniform sampler2D pyramid;\nuniform float lod;\nconst mat3 horizontalKernel = mat3(\n-1.0f, 0.0f, 1.0f,\n-2.0f, 0.0f, 2.0f,\n-1.0f, 0.0f, 1.0f\n);\nconst mat3 verticalKernel = mat3(\n1.0f, 2.0f, 1.0f,\n0.0f, 0.0f, 0.0f,\n-1.0f,-2.0f,-1.0f\n);\nconst vec3 ones = vec3(1.0f, 1.0f, 1.0f);\nvoid main()\n{\nfloat pot = exp2(lod);\nmat3 neighbors = mat3(\npyrPixelAtOffset(pyramid, lod, pot, ivec2(-1, -1)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(0, -1)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(1, -1)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(-1, 0)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(0, 0)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(1, 0)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(-1, 1)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(0, 1)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(1, 1)).g\n);\nmat3 sobelX = matrixCompMult(horizontalKernel, neighbors);\nmat3 sobelY = matrixCompMult(verticalKernel, neighbors);\nvec2 df = vec2(\ndot(sobelX[0] + sobelX[1] + sobelX[2], ones),\ndot(sobelY[0] + sobelY[1] + sobelY[2], ones)\n);\ncolor = encodeSobel(df);\n}'},function(e,t){e.exports="uniform sampler2D image, layerA, layerB;\nuniform float scaleA, scaleB, lgM, h;\nvoid main()\n{\nvec4 pixel = threadPixel(image);\nfloat score = pixel.r;\nivec2 zero = ivec2(0, 0);\nivec2 sizeA = textureSize(layerA, 0);\nivec2 sizeB = textureSize(layerB, 0);\nvec2 mid = (texCoord * texSize) + vec2(0.5f, 0.5f);\nivec2 pa = clamp(ivec2(ceil(mid * scaleA - 1.0f)), zero, sizeA - 2);\nivec2 pb = clamp(ivec2(ceil(mid * scaleB - 1.0f)), zero, sizeB - 2);\nvec4 a00 = pixelAt(layerA, pa);\nvec4 a10 = pixelAt(layerA, pa + ivec2(1, 0));\nvec4 a01 = pixelAt(layerA, pa + ivec2(0, 1));\nvec4 a11 = pixelAt(layerA, pa + ivec2(1, 1));\nvec4 b00 = pixelAt(layerB, pb);\nvec4 b10 = pixelAt(layerB, pb + ivec2(1, 0));\nvec4 b01 = pixelAt(layerB, pb + ivec2(0, 1));\nvec4 b11 = pixelAt(layerB, pb + ivec2(1, 1));\nfloat maxScore = max(\nmax(max(a00.r, a10.r), max(a01.r, a11.r)),\nmax(max(b00.r, b10.r), max(b01.r, b11.r))\n);\ncolor = vec4(0.0f, pixel.gba);\nif(score < maxScore || score == 0.0f)\nreturn;\nvec2 ea = fract(mid * scaleA);\nvec2 eb = fract(mid * scaleB);\nfloat isa = a00.b * (1.0f - ea.x) * (1.0f - ea.y) +\na10.b * ea.x * (1.0f - ea.y) +\na01.b * (1.0f - ea.x) * ea.y +\na11.b * ea.x * ea.y;\nfloat isb = b00.b * (1.0f - eb.x) * (1.0f - eb.y) +\nb10.b * eb.x * (1.0f - eb.y) +\nb01.b * (1.0f - eb.x) * eb.y +\nb11.b * eb.x * eb.y;\ncolor = (isa > score && isa > isb) ? vec4(isa, pixel.gb, a00.a) : pixel;\ncolor = (isb > score && isb > isa) ? vec4(isb, pixel.gb, b00.a) : pixel;\nfloat y1 = isa, y2 = isb, y3 = score;\nfloat x1 = lgM - (lgM + h) * a00.a;\nfloat x2 = lgM - (lgM + h) * b00.a;\nfloat x3 = lgM - (lgM + h) * pixel.a;\nfloat dn = (x1 - x2) * (x1 - x3) * (x2 - x3);\nif(abs(dn) < 0.00001f)\nreturn;\nfloat a = (x3 * (y2 - y1) + x2 * (y1 - y3) + x1 * (y3 - y2)) / dn;\nif(a >= 0.0f)\nreturn;\nfloat b = (x3 * x3 * (y1 - y2) + x2 * x2 * (y3 - y1) + x1 * x1 * (y2 - y3)) / dn;\nfloat c = (x2 * x3 * (x2 - x3) * y1 + x3 * x1 * (x3 - x1) * y2 + x1 * x2 * (x1 - x2) * y3) / dn;\nfloat xv = -b / (2.0f * a);\nfloat yv = c - (b * b) / (4.0f * a);\nif(xv < min(x1, min(x2, x3)) || xv > max(x1, max(x2, x3)))\nreturn;\nfloat interpolatedScale = (lgM - xv) / (lgM + h);\nfloat interpolatedScore = clamp(yv, 0.0f, 1.0f);\ncolor = vec4(interpolatedScore, pixel.gb, interpolatedScale);\n}"},function(e,t){e.exports="uniform sampler2D image;\nuniform float threshold;\nvoid main()\n{\nvec4 pixel = threadPixel(image);\nfloat t = clamp(threshold, 0.0f, 1.0f);\nfloat ct = pixel.g + t, c_t = pixel.g - t;\nfloat p0 = pixelAtShortOffset(image, ivec2(0, 2)).g;\nfloat p1 = pixelAtShortOffset(image, ivec2(1, 2)).g;\nfloat p2 = pixelAtShortOffset(image, ivec2(2, 1)).g;\nfloat p3 = pixelAtShortOffset(image, ivec2(2, 0)).g;\nfloat p4 = pixelAtShortOffset(image, ivec2(2, -1)).g;\nfloat p5 = pixelAtShortOffset(image, ivec2(1, -2)).g;\nfloat p6 = pixelAtShortOffset(image, ivec2(0, -2)).g;\nfloat p7 = pixelAtShortOffset(image, ivec2(-1, -2)).g;\nfloat p8 = pixelAtShortOffset(image, ivec2(-2, -1)).g;\nfloat p9 = pixelAtShortOffset(image, ivec2(-2, 0)).g;\nfloat p10 = pixelAtShortOffset(image, ivec2(-2, 1)).g;\nfloat p11 = pixelAtShortOffset(image, ivec2(-1, 2)).g;\nvec2 scores = vec2(0.0f, 0.0f);\nscores += vec2(max(c_t - p0, 0.0f), max(p0 - ct, 0.0f));\nscores += vec2(max(c_t - p1, 0.0f), max(p1 - ct, 0.0f));\nscores += vec2(max(c_t - p2, 0.0f), max(p2 - ct, 0.0f));\nscores += vec2(max(c_t - p3, 0.0f), max(p3 - ct, 0.0f));\nscores += vec2(max(c_t - p4, 0.0f), max(p4 - ct, 0.0f));\nscores += vec2(max(c_t - p5, 0.0f), max(p5 - ct, 0.0f));\nscores += vec2(max(c_t - p6, 0.0f), max(p6 - ct, 0.0f));\nscores += vec2(max(c_t - p7, 0.0f), max(p7 - ct, 0.0f));\nscores += vec2(max(c_t - p8, 0.0f), max(p8 - ct, 0.0f));\nscores += vec2(max(c_t - p9, 0.0f), max(p9 - ct, 0.0f));\nscores += vec2(max(c_t - p10, 0.0f), max(p10 - ct, 0.0f));\nscores += vec2(max(c_t - p11, 0.0f), max(p11 - ct, 0.0f));\nfloat score = max(scores.x, scores.y) / 12.0f;\ncolor = vec4(score * step(1.0f, pixel.r), pixel.g, score, pixel.a);\n}"},function(e,t){e.exports="uniform sampler2D image;\nuniform float threshold;\nconst vec4 zeroes = vec4(0.0f, 0.0f, 0.0f, 0.0f);\nconst vec4 ones = vec4(1.0f, 1.0f, 1.0f, 1.0f);\nvoid main()\n{\nvec4 pixel = threadPixel(image);\nfloat t = clamp(threshold, 0.0f, 1.0f);\nfloat ct = pixel.g + t, c_t = pixel.g - t;\nmat4 mp = mat4(\npixelAtShortOffset(image, ivec2(0, 3)).g,\npixelAtShortOffset(image, ivec2(1, 3)).g,\npixelAtShortOffset(image, ivec2(2, 2)).g,\npixelAtShortOffset(image, ivec2(3, 1)).g,\npixelAtShortOffset(image, ivec2(3, 0)).g,\npixelAtShortOffset(image, ivec2(3, -1)).g,\npixelAtShortOffset(image, ivec2(2, -2)).g,\npixelAtShortOffset(image, ivec2(1, -3)).g,\npixelAtShortOffset(image, ivec2(0, -3)).g,\npixelAtShortOffset(image, ivec2(-1, -3)).g,\npixelAtShortOffset(image, ivec2(-2, -2)).g,\npixelAtShortOffset(image, ivec2(-3, -1)).g,\npixelAtShortOffset(image, ivec2(-3, 0)).g,\npixelAtShortOffset(image, ivec2(-3, 1)).g,\npixelAtShortOffset(image, ivec2(-2, 2)).g,\npixelAtShortOffset(image, ivec2(-1, 3)).g\n);\nmat4 mct = mp - mat4(\nct, ct, ct, ct,\nct, ct, ct, ct,\nct, ct, ct, ct,\nct, ct, ct, ct\n), mc_t = mat4(\nc_t, c_t, c_t, c_t,\nc_t, c_t, c_t, c_t,\nc_t, c_t, c_t, c_t,\nc_t, c_t, c_t, c_t\n) - mp;\nvec4 bs = max(mc_t[0], zeroes), ds = max(mct[0], zeroes);\nbs += max(mc_t[1], zeroes); ds += max(mct[1], zeroes);\nbs += max(mc_t[2], zeroes); ds += max(mct[2], zeroes);\nbs += max(mc_t[3], zeroes); ds += max(mct[3], zeroes);\nfloat score = max(dot(bs, ones), dot(ds, ones)) / 16.0f;\ncolor = vec4(score * step(1.0f, pixel.r), pixel.g, score, pixel.a);\n}"},function(e,t){e.exports="uniform sampler2D image;\nuniform float threshold;\nvoid main()\n{\nvec4 pixel = threadPixel(image);\nfloat t = clamp(threshold, 0.0f, 1.0f);\nfloat ct = pixel.g + t, c_t = pixel.g - t;\nfloat p0 = pixelAtShortOffset(image, ivec2(0, 1)).g;\nfloat p1 = pixelAtShortOffset(image, ivec2(1, 1)).g;\nfloat p2 = pixelAtShortOffset(image, ivec2(1, 0)).g;\nfloat p3 = pixelAtShortOffset(image, ivec2(1, -1)).g;\nfloat p4 = pixelAtShortOffset(image, ivec2(0, -1)).g;\nfloat p5 = pixelAtShortOffset(image, ivec2(-1, -1)).g;\nfloat p6 = pixelAtShortOffset(image, ivec2(-1, 0)).g;\nfloat p7 = pixelAtShortOffset(image, ivec2(-1, 1)).g;\nvec2 scores = vec2(0.0f, 0.0f);\nscores += vec2(max(c_t - p0, 0.0f), max(p0 - ct, 0.0f));\nscores += vec2(max(c_t - p1, 0.0f), max(p1 - ct, 0.0f));\nscores += vec2(max(c_t - p2, 0.0f), max(p2 - ct, 0.0f));\nscores += vec2(max(c_t - p3, 0.0f), max(p3 - ct, 0.0f));\nscores += vec2(max(c_t - p4, 0.0f), max(p4 - ct, 0.0f));\nscores += vec2(max(c_t - p5, 0.0f), max(p5 - ct, 0.0f));\nscores += vec2(max(c_t - p6, 0.0f), max(p6 - ct, 0.0f));\nscores += vec2(max(c_t - p7, 0.0f), max(p7 - ct, 0.0f));\nfloat score = max(scores.x, scores.y) / 8.0f;\ncolor = vec4(score * step(1.0f, pixel.r), pixel.g, score, pixel.a);\n}"},function(e,t){e.exports="uniform sampler2D image;\nuniform float threshold;\nvoid main()\n{\nivec2 thread = threadLocation();\nivec2 size = outputSize();\nvec4 pixel = threadPixel(image);\ncolor = vec4(0.0f, pixel.gba);\nif(\nthread.x >= 3 && thread.x < size.x - 3 &&\nthread.y >= 3 && thread.y < size.y - 3\n) {\nfloat t = clamp(threshold, 0.0f, 1.0f);\nfloat c = pixel.g;\nfloat ct = c + t, c_t = c - t;\nfloat p0 = pixelAtShortOffset(image, ivec2(0, 1)).g;\nfloat p1 = pixelAtShortOffset(image, ivec2(1, 1)).g;\nfloat p2 = pixelAtShortOffset(image, ivec2(1, 0)).g;\nfloat p3 = pixelAtShortOffset(image, ivec2(1, -1)).g;\nfloat p4 = pixelAtShortOffset(image, ivec2(0, -1)).g;\nfloat p5 = pixelAtShortOffset(image, ivec2(-1, -1)).g;\nfloat p6 = pixelAtShortOffset(image, ivec2(-1, 0)).g;\nfloat p7 = pixelAtShortOffset(image, ivec2(-1, 1)).g;\nbool possibleCorner =\n((c_t > p1 || c_t > p5) && (c_t > p3 || c_t > p7)) ||\n((ct < p1  || ct < p5)  && (ct < p3  || ct < p7))  ;\nif(possibleCorner) {\nint bright = 0, dark = 0, bc = 0, dc = 0;\nif(c_t > p0) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p0) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p1) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p1) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p2) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p2) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p3) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p3) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p4) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p4) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p5) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p5) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p6) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p6) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p7) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p7) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(bright < 5 && dark < 5) {\nif(bc > 0 && bc < 5) do {\nif(c_t > p0)           bc += 1; else break;\nif(c_t > p1 && bc < 5) bc += 1; else break;\nif(c_t > p2 && bc < 5) bc += 1; else break;\nif(c_t > p3 && bc < 5) bc += 1; else break;\n} while(false);\nif(dc > 0 && dc < 5) do {\nif(ct < p0)           dc += 1; else break;\nif(ct < p1 && dc < 5) dc += 1; else break;\nif(ct < p2 && dc < 5) dc += 1; else break;\nif(ct < p3 && dc < 5) dc += 1; else break;\n} while(false);\nif(bc >= 5 || dc >= 5)\ncolor = vec4(1.0f, pixel.gba);\n}\nelse {\ncolor = vec4(1.0f, pixel.gba);\n}\n}\n}\n}"},function(e,t){e.exports="uniform sampler2D image;\nuniform float threshold;\nvoid main()\n{\nivec2 thread = threadLocation();\nivec2 size = outputSize();\nvec4 pixel = threadPixel(image);\ncolor = vec4(0.0f, pixel.gba);\nif(\nthread.x >= 3 && thread.x < size.x - 3 &&\nthread.y >= 3 && thread.y < size.y - 3\n) {\nfloat t = clamp(threshold, 0.0f, 1.0f);\nfloat c = pixel.g;\nfloat ct = c + t, c_t = c - t;\nfloat p0 = pixelAtShortOffset(image, ivec2(0, 2)).g;\nfloat p1 = pixelAtShortOffset(image, ivec2(1, 2)).g;\nfloat p2 = pixelAtShortOffset(image, ivec2(2, 1)).g;\nfloat p3 = pixelAtShortOffset(image, ivec2(2, 0)).g;\nfloat p4 = pixelAtShortOffset(image, ivec2(2, -1)).g;\nfloat p5 = pixelAtShortOffset(image, ivec2(1, -2)).g;\nfloat p6 = pixelAtShortOffset(image, ivec2(0, -2)).g;\nfloat p7 = pixelAtShortOffset(image, ivec2(-1, -2)).g;\nfloat p8 = pixelAtShortOffset(image, ivec2(-2, -1)).g;\nfloat p9 = pixelAtShortOffset(image, ivec2(-2, 0)).g;\nfloat p10 = pixelAtShortOffset(image, ivec2(-2, 1)).g;\nfloat p11 = pixelAtShortOffset(image, ivec2(-1, 2)).g;\nbool possibleCorner =\n((c_t > p0 || c_t > p6) && (c_t > p3 || c_t > p9)) ||\n((ct < p0  || ct < p6)  && (ct < p3  || ct < p9))  ;\nif(possibleCorner) {\nint bright = 0, dark = 0, bc = 0, dc = 0;\nif(c_t > p0) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p0) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p1) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p1) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p2) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p2) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p3) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p3) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p4) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p4) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p5) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p5) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p6) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p6) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p7) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p7) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p8) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p8) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p9) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p9) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p10) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p10) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(c_t > p11) { dc = 0; bc += 1; if(bc > bright) bright = bc; }\nelse { bc = 0; if(ct < p11) { dc += 1; if(dc > dark) dark = dc; } else dc = 0; }\nif(bright < 7 && dark < 7) {\nif(bc > 0 && bc < 7) do {\nif(c_t > p0)           bc += 1; else break;\nif(c_t > p1 && bc < 7) bc += 1; else break;\nif(c_t > p2 && bc < 7) bc += 1; else break;\nif(c_t > p3 && bc < 7) bc += 1; else break;\nif(c_t > p4 && bc < 7) bc += 1; else break;\nif(c_t > p5 && bc < 7) bc += 1; else break;\n} while(false);\nif(dc > 0 && dc < 7) do {\nif(ct < p0)           dc += 1; else break;\nif(ct < p1 && dc < 7) dc += 1; else break;\nif(ct < p2 && dc < 7) dc += 1; else break;\nif(ct < p3 && dc < 7) dc += 1; else break;\nif(ct < p4 && dc < 7) dc += 1; else break;\nif(ct < p5 && dc < 7) dc += 1; else break;\n} while(false);\nif(bc >= 7 || dc >= 7)\ncolor = vec4(1.0f, pixel.gba);\n}\nelse {\ncolor = vec4(1.0f, pixel.gba);\n}\n}\n}\n}"},function(e,t){e.exports="uniform sampler2D image;\nuniform float threshold;\nconst ivec4 margin = ivec4(3, 3, 4, 4);\nvoid main()\n{\nvec4 pixel = threadPixel(image);\nivec2 thread = threadLocation();\nivec2 size = outputSize();\ncolor = vec4(0.0f, pixel.gba);\nif(any(lessThan(ivec4(thread, size - thread), margin)))\nreturn;\nfloat t = clamp(threshold, 0.0f, 1.0f);\nfloat ct = pixel.g + t, c_t = pixel.g - t;\nfloat p0 = pixelAtShortOffset(image, ivec2(0, 3)).g;\nfloat p4 = pixelAtShortOffset(image, ivec2(3, 0)).g;\nfloat p8 = pixelAtShortOffset(image, ivec2(0, -3)).g;\nfloat p12 = pixelAtShortOffset(image, ivec2(-3, 0)).g;\nif(!(\n((c_t > p0 || c_t > p8) && (c_t > p4 || c_t > p12)) ||\n((ct < p0  || ct < p8)  && (ct < p4  || ct < p12))\n))\nreturn;\nfloat p1 = pixelAtShortOffset(image, ivec2(1, 3)).g;\nfloat p2 = pixelAtShortOffset(image, ivec2(2, 2)).g;\nfloat p3 = pixelAtShortOffset(image, ivec2(3, 1)).g;\nfloat p5 = pixelAtShortOffset(image, ivec2(3, -1)).g;\nfloat p6 = pixelAtShortOffset(image, ivec2(2, -2)).g;\nfloat p7 = pixelAtShortOffset(image, ivec2(1, -3)).g;\nfloat p9 = pixelAtShortOffset(image, ivec2(-1, -3)).g;\nfloat p10 = pixelAtShortOffset(image, ivec2(-2, -2)).g;\nfloat p11 = pixelAtShortOffset(image, ivec2(-3, -1)).g;\nfloat p13 = pixelAtShortOffset(image, ivec2(-3, 1)).g;\nfloat p14 = pixelAtShortOffset(image, ivec2(-2, 2)).g;\nfloat p15 = pixelAtShortOffset(image, ivec2(-1, 3)).g;\nbool A=(p0>ct),B=(p1>ct),C=(p2>ct),D=(p3>ct),E=(p4>ct),F=(p5>ct),G=(p6>ct),H=(p7>ct),I=(p8>ct),J=(p9>ct),K=(p10>ct),L=(p11>ct),M=(p12>ct),N=(p13>ct),O=(p14>ct),P=(p15>ct),a=(p0<c_t),b=(p1<c_t),c=(p2<c_t),d=(p3<c_t),e=(p4<c_t),f=(p5<c_t),g=(p6<c_t),h=(p7<c_t),i=(p8<c_t),j=(p9<c_t),k=(p10<c_t),l=(p11<c_t),m=(p12<c_t),n=(p13<c_t),o=(p14<c_t),p=(p15<c_t);\nbool isCorner=A&&(B&&(K&&L&&J&&(M&&N&&O&&P||G&&H&&I&&(M&&N&&O||F&&(M&&N||E&&(M||D))))||C&&(K&&L&&M&&(N&&O&&P||G&&H&&I&&J&&(N&&O||F&&(N||E)))||D&&(N&&(L&&M&&(K&&G&&H&&I&&J&&(O||F)||O&&P)||k&&l&&m&&e&&f&&g&&h&&i&&j)||E&&(O&&(M&&N&&(K&&L&&G&&H&&I&&J||P)||k&&l&&m&&n&&f&&g&&h&&i&&j)||F&&(P&&(N&&O||k&&l&&m&&n&&o&&g&&h&&i&&j)||G&&(O&&P||H&&(P||I)||k&&l&&m&&n&&o&&p&&h&&i&&j)||k&&l&&m&&n&&o&&h&&i&&j&&(p||g))||k&&l&&m&&n&&h&&i&&j&&(o&&(p||g)||f&&(o&&p||g)))||k&&l&&m&&h&&i&&j&&(n&&(o&&p||g&&(o||f))||e&&(n&&o&&p||g&&(n&&o||f))))||k&&l&&h&&i&&j&&(m&&(n&&o&&p||g&&(n&&o||f&&(n||e)))||d&&(m&&n&&o&&p||g&&(m&&n&&o||f&&(m&&n||e)))))||k&&h&&i&&j&&(l&&(m&&n&&o&&p||g&&(m&&n&&o||f&&(m&&n||e&&(m||d))))||c&&(l&&m&&n&&o&&p||g&&(l&&m&&n&&o||f&&(l&&m&&n||e&&(l&&m||d))))))||K&&I&&J&&(L&&M&&N&&O&&P||G&&H&&(L&&M&&N&&O||F&&(L&&M&&N||E&&(L&&M||D&&(L||C)))))||h&&i&&j&&(b&&(k&&l&&m&&n&&o&&p||g&&(k&&l&&m&&n&&o||f&&(k&&l&&m&&n||e&&(k&&l&&m||d&&(k&&l||c)))))||k&&(l&&m&&n&&o&&p||g&&(l&&m&&n&&o||f&&(l&&m&&n||e&&(l&&m||d&&(l||c)))))))||B&&(H&&I&&J&&(K&&L&&M&&N&&O&&P&&a||G&&(K&&L&&M&&N&&O&&a||F&&(K&&L&&M&&N&&a||E&&(K&&L&&M&&a||D&&(K&&L&&a||C)))))||a&&k&&i&&j&&(l&&m&&n&&o&&p||g&&h&&(l&&m&&n&&o||f&&(l&&m&&n||e&&(l&&m||d&&(l||c))))))||C&&(K&&H&&I&&J&&(L&&M&&N&&O&&P&&a&&b||G&&(L&&M&&N&&O&&a&&b||F&&(L&&M&&N&&a&&b||E&&(L&&M&&a&&b||D))))||a&&b&&k&&l&&j&&(m&&n&&o&&p||g&&h&&i&&(m&&n&&o||f&&(m&&n||e&&(m||d)))))||D&&(K&&L&&H&&I&&J&&(M&&N&&O&&P&&a&&b&&c||G&&(M&&N&&O&&a&&b&&c||F&&(M&&N&&a&&b&&c||E)))||a&&b&&k&&l&&m&&c&&(n&&o&&p||g&&h&&i&&j&&(n&&o||f&&(n||e))))||E&&(K&&L&&M&&H&&I&&J&&(N&&O&&P&&a&&b&&c&&d||G&&(N&&O&&a&&b&&c&&d||F))||a&&b&&l&&m&&n&&c&&d&&(k&&g&&h&&i&&j&&(o||f)||o&&p))||F&&(K&&L&&M&&N&&H&&I&&J&&(O&&P&&a&&b&&c&&d&&e||G)||a&&b&&m&&n&&o&&c&&d&&e&&(k&&l&&g&&h&&i&&j||p))||G&&(K&&L&&M&&N&&O&&H&&I&&J||a&&b&&n&&o&&p&&c&&d&&e&&f)||H&&(K&&L&&M&&N&&O&&P&&I&&J||a&&b&&o&&p&&c&&d&&e&&f&&g)||a&&(b&&(k&&l&&j&&(m&&n&&o&&p||g&&h&&i&&(m&&n&&o||f&&(m&&n||e&&(m||d))))||c&&(k&&l&&m&&(n&&o&&p||g&&h&&i&&j&&(n&&o||f&&(n||e)))||d&&(l&&m&&n&&(k&&g&&h&&i&&j&&(o||f)||o&&p)||e&&(m&&n&&o&&(k&&l&&g&&h&&i&&j||p)||f&&(n&&o&&p||g&&(o&&p||h&&(p||i)))))))||k&&i&&j&&(l&&m&&n&&o&&p||g&&h&&(l&&m&&n&&o||f&&(l&&m&&n||e&&(l&&m||d&&(l||c))))))||h&&i&&j&&(k&&l&&m&&n&&o&&p||g&&(k&&l&&m&&n&&o||f&&(k&&l&&m&&n||e&&(k&&l&&m||d&&(k&&l||c&&(b||k))))));\ncolor = vec4(float(isCorner), pixel.gba);\n}"},function(e,t){e.exports="uniform sampler2D corners;\nuniform sampler2D maxScore;\nuniform float quality;\nvoid main()\n{\nvec4 pixel = threadPixel(corners);\nfloat threshold = threadPixel(maxScore).r * clamp(quality, 0.0f, 1.0f);\nfloat score = step(threshold, pixel.r) * pixel.r;\ncolor = vec4(score, pixel.gba);\n}"},function(e,t){e.exports='@include "pyramids.glsl"\nuniform sampler2D pyramid;\nuniform float threshold;\nuniform int numberOfOctaves;\nconst ivec4 margin = ivec4(3, 3, 4, 4);\nconst vec4 zeroes = vec4(0.0f, 0.0f, 0.0f, 0.0f);\nconst vec4 ones = vec4(1.0f, 1.0f, 1.0f, 1.0f);\nvoid main()\n{\nvec4 pixel = threadPixel(pyramid);\nivec2 thread = threadLocation();\nivec2 size = outputSize();\nfloat t = clamp(threshold, 0.0f, 1.0f);\nfloat ct = pixel.g + t, c_t = pixel.g - t;\nvec2 best = vec2(0.0f, pixel.a);\n#ifdef USE_HARRIS_SCORE\nvec2 dfmm[PYRAMID_MAX_OCTAVES], dfm0[PYRAMID_MAX_OCTAVES], dfm1[PYRAMID_MAX_OCTAVES],\ndf0m[PYRAMID_MAX_OCTAVES], df00[PYRAMID_MAX_OCTAVES], df01[PYRAMID_MAX_OCTAVES],\ndf1m[PYRAMID_MAX_OCTAVES], df10[PYRAMID_MAX_OCTAVES], df11[PYRAMID_MAX_OCTAVES];\nfloat pyrpix = 0.0f;\nfor(int l = 0; l < numberOfOctaves; l++) {\nfloat lod = float(l) * 0.5f;\nfloat pot = exp2(lod);\npyrpix = pyrPixelAtOffset(pyramid, lod, pot, ivec2(-1,-1)).g;\ndfmm[l] = vec2(dFdx(pyrpix), dFdy(pyrpix));\npyrpix = pyrPixelAtOffset(pyramid, lod, pot, ivec2(-1,0)).g;\ndfm0[l] = vec2(dFdx(pyrpix), dFdy(pyrpix));\npyrpix = pyrPixelAtOffset(pyramid, lod, pot, ivec2(-1,1)).g;\ndfm1[l] = vec2(dFdx(pyrpix), dFdy(pyrpix));\npyrpix = pyrPixelAtOffset(pyramid, lod, pot, ivec2(0,-1)).g;\ndf0m[l] = vec2(dFdx(pyrpix), dFdy(pyrpix));\npyrpix = pyrPixelAtOffset(pyramid, lod, pot, ivec2(0,0)).g;\ndf00[l] = vec2(dFdx(pyrpix), dFdy(pyrpix));\npyrpix = pyrPixelAtOffset(pyramid, lod, pot, ivec2(0,1)).g;\ndf01[l] = vec2(dFdx(pyrpix), dFdy(pyrpix));\npyrpix = pyrPixelAtOffset(pyramid, lod, pot, ivec2(1,-1)).g;\ndf1m[l] = vec2(dFdx(pyrpix), dFdy(pyrpix));\npyrpix = pyrPixelAtOffset(pyramid, lod, pot, ivec2(1,0)).g;\ndf10[l] = vec2(dFdx(pyrpix), dFdy(pyrpix));\npyrpix = pyrPixelAtOffset(pyramid, lod, pot, ivec2(1,1)).g;\ndf11[l] = vec2(dFdx(pyrpix), dFdy(pyrpix));\n}\n#endif\ncolor = vec4(0.0f, pixel.g, 0.0f, pixel.a);\nfloat lod = 0.0f, pot = 1.0f;\nfor(int octave = 0; octave < numberOfOctaves; octave++, pot = exp2(lod += 0.5f)) {\npixel = pyrPixel(pyramid, lod);\nct = pixel.g + t;\nc_t = pixel.g - t;\nvec4 p4k = vec4(\npyrPixelAtOffset(pyramid, lod, pot, ivec2(0, 3)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(3, 0)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(0, -3)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(-3, 0)).g\n);\nmat4 mp = mat4(\np4k.x,\np4k.y,\np4k.z,\np4k.w,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(1, 3)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(3, -1)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(-1, -3)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(-3, 1)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(2, 2)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(2, -2)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(-2, -2)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(-2, 2)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(3, 1)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(1, -3)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(-3, -1)).g,\npyrPixelAtOffset(pyramid, lod, pot, ivec2(-1, 3)).g\n);\nbool A=(mp[0][0]>ct),B=(mp[1][0]>ct),C=(mp[2][0]>ct),D=(mp[3][0]>ct),E=(mp[0][1]>ct),F=(mp[1][1]>ct),G=(mp[2][1]>ct),H=(mp[3][1]>ct),I=(mp[0][2]>ct),J=(mp[1][2]>ct),K=(mp[2][2]>ct),L=(mp[3][2]>ct),M=(mp[0][3]>ct),N=(mp[1][3]>ct),O=(mp[2][3]>ct),P=(mp[3][3]>ct),a=(mp[0][0]<c_t),b=(mp[1][0]<c_t),c=(mp[2][0]<c_t),d=(mp[3][0]<c_t),e=(mp[0][1]<c_t),f=(mp[1][1]<c_t),g=(mp[2][1]<c_t),h=(mp[3][1]<c_t),i=(mp[0][2]<c_t),j=(mp[1][2]<c_t),k=(mp[2][2]<c_t),l=(mp[3][2]<c_t),m=(mp[0][3]<c_t),n=(mp[1][3]<c_t),o=(mp[2][3]<c_t),p=(mp[3][3]<c_t);\nbool isCorner=A&&(B&&(K&&L&&J&&(M&&N&&O&&P||G&&H&&I&&(M&&N&&O||F&&(M&&N||E&&(M||D))))||C&&(K&&L&&M&&(N&&O&&P||G&&H&&I&&J&&(N&&O||F&&(N||E)))||D&&(N&&(L&&M&&(K&&G&&H&&I&&J&&(O||F)||O&&P)||k&&l&&m&&e&&f&&g&&h&&i&&j)||E&&(O&&(M&&N&&(K&&L&&G&&H&&I&&J||P)||k&&l&&m&&n&&f&&g&&h&&i&&j)||F&&(P&&(N&&O||k&&l&&m&&n&&o&&g&&h&&i&&j)||G&&(O&&P||H&&(P||I)||k&&l&&m&&n&&o&&p&&h&&i&&j)||k&&l&&m&&n&&o&&h&&i&&j&&(p||g))||k&&l&&m&&n&&h&&i&&j&&(o&&(p||g)||f&&(o&&p||g)))||k&&l&&m&&h&&i&&j&&(n&&(o&&p||g&&(o||f))||e&&(n&&o&&p||g&&(n&&o||f))))||k&&l&&h&&i&&j&&(m&&(n&&o&&p||g&&(n&&o||f&&(n||e)))||d&&(m&&n&&o&&p||g&&(m&&n&&o||f&&(m&&n||e)))))||k&&h&&i&&j&&(l&&(m&&n&&o&&p||g&&(m&&n&&o||f&&(m&&n||e&&(m||d))))||c&&(l&&m&&n&&o&&p||g&&(l&&m&&n&&o||f&&(l&&m&&n||e&&(l&&m||d))))))||K&&I&&J&&(L&&M&&N&&O&&P||G&&H&&(L&&M&&N&&O||F&&(L&&M&&N||E&&(L&&M||D&&(L||C)))))||h&&i&&j&&(b&&(k&&l&&m&&n&&o&&p||g&&(k&&l&&m&&n&&o||f&&(k&&l&&m&&n||e&&(k&&l&&m||d&&(k&&l||c)))))||k&&(l&&m&&n&&o&&p||g&&(l&&m&&n&&o||f&&(l&&m&&n||e&&(l&&m||d&&(l||c)))))))||B&&(H&&I&&J&&(K&&L&&M&&N&&O&&P&&a||G&&(K&&L&&M&&N&&O&&a||F&&(K&&L&&M&&N&&a||E&&(K&&L&&M&&a||D&&(K&&L&&a||C)))))||a&&k&&i&&j&&(l&&m&&n&&o&&p||g&&h&&(l&&m&&n&&o||f&&(l&&m&&n||e&&(l&&m||d&&(l||c))))))||C&&(K&&H&&I&&J&&(L&&M&&N&&O&&P&&a&&b||G&&(L&&M&&N&&O&&a&&b||F&&(L&&M&&N&&a&&b||E&&(L&&M&&a&&b||D))))||a&&b&&k&&l&&j&&(m&&n&&o&&p||g&&h&&i&&(m&&n&&o||f&&(m&&n||e&&(m||d)))))||D&&(K&&L&&H&&I&&J&&(M&&N&&O&&P&&a&&b&&c||G&&(M&&N&&O&&a&&b&&c||F&&(M&&N&&a&&b&&c||E)))||a&&b&&k&&l&&m&&c&&(n&&o&&p||g&&h&&i&&j&&(n&&o||f&&(n||e))))||E&&(K&&L&&M&&H&&I&&J&&(N&&O&&P&&a&&b&&c&&d||G&&(N&&O&&a&&b&&c&&d||F))||a&&b&&l&&m&&n&&c&&d&&(k&&g&&h&&i&&j&&(o||f)||o&&p))||F&&(K&&L&&M&&N&&H&&I&&J&&(O&&P&&a&&b&&c&&d&&e||G)||a&&b&&m&&n&&o&&c&&d&&e&&(k&&l&&g&&h&&i&&j||p))||G&&(K&&L&&M&&N&&O&&H&&I&&J||a&&b&&n&&o&&p&&c&&d&&e&&f)||H&&(K&&L&&M&&N&&O&&P&&I&&J||a&&b&&o&&p&&c&&d&&e&&f&&g)||a&&(b&&(k&&l&&j&&(m&&n&&o&&p||g&&h&&i&&(m&&n&&o||f&&(m&&n||e&&(m||d))))||c&&(k&&l&&m&&(n&&o&&p||g&&h&&i&&j&&(n&&o||f&&(n||e)))||d&&(l&&m&&n&&(k&&g&&h&&i&&j&&(o||f)||o&&p)||e&&(m&&n&&o&&(k&&l&&g&&h&&i&&j||p)||f&&(n&&o&&p||g&&(o&&p||h&&(p||i)))))))||k&&i&&j&&(l&&m&&n&&o&&p||g&&h&&(l&&m&&n&&o||f&&(l&&m&&n||e&&(l&&m||d&&(l||c))))))||h&&i&&j&&(k&&l&&m&&n&&o&&p||g&&(k&&l&&m&&n&&o||f&&(k&&l&&m&&n||e&&(k&&l&&m||d&&(k&&l||c&&(b||k))))));\nfloat score = 0.0f;\n#ifdef USE_HARRIS_SCORE\nvec2 df0 = dfmm[octave], df1 = dfm0[octave], df2 = dfm1[octave],\ndf3 = df0m[octave], df4 = df00[octave], df5 = df01[octave],\ndf6 = df1m[octave], df7 = df10[octave], df8 = df11[octave];\nvec3 hm = vec3(0.0f);\nhm += vec3(df0.x * df0.x, df0.x * df0.y, df0.y * df0.y);\nhm += vec3(df1.x * df1.x, df1.x * df1.y, df1.y * df1.y);\nhm += vec3(df2.x * df2.x, df2.x * df2.y, df2.y * df2.y);\nhm += vec3(df3.x * df3.x, df3.x * df3.y, df3.y * df3.y);\nhm += vec3(df4.x * df4.x, df4.x * df4.y, df4.y * df4.y);\nhm += vec3(df5.x * df5.x, df5.x * df5.y, df5.y * df5.y);\nhm += vec3(df6.x * df6.x, df6.x * df6.y, df6.y * df6.y);\nhm += vec3(df7.x * df7.x, df7.x * df7.y, df7.y * df7.y);\nhm += vec3(df8.x * df8.x, df8.x * df8.y, df8.y * df8.y);\nfloat response = 0.5f * (hm.x + hm.z - sqrt((hm.x - hm.z) * (hm.x - hm.z) + 4.0f * hm.y * hm.y));\nscore = max(0.0f, response / 5.0f);\n#else\nmat4 mct = mp - mat4(\nct, ct, ct, ct,\nct, ct, ct, ct,\nct, ct, ct, ct,\nct, ct, ct, ct\n), mc_t = mat4(\nc_t, c_t, c_t, c_t,\nc_t, c_t, c_t, c_t,\nc_t, c_t, c_t, c_t,\nc_t, c_t, c_t, c_t\n) - mp;\nvec4 bs = max(mc_t[0], zeroes), ds = max(mct[0], zeroes);\nbs += max(mc_t[1], zeroes); ds += max(mct[1], zeroes);\nbs += max(mc_t[2], zeroes); ds += max(mct[2], zeroes);\nbs += max(mc_t[3], zeroes); ds += max(mct[3], zeroes);\nscore = max(dot(bs, ones), dot(ds, ones)) / 16.0f;\n#endif\nscore *= float(isCorner);\nivec2 remainder = thread % int(pot);\nscore *= float(remainder.x + remainder.y == 0);\nfloat scale = encodeLod(lod);\nbest = (score > best.x) ? vec2(score, scale) : best;\n}\ncolor.rba = best.xxy;\n}'},function(e,t){e.exports='@include "sobel.glsl"\n@include "pyramids.glsl"\nuniform sampler2D pyramid;\nuniform int windowSize;\nuniform int numberOfOctaves;\nuniform sampler2D sobelDerivatives[@PYRAMID_MAX_OCTAVES@];\nvec4 pickSobelDerivatives(int index, ivec2 offset)\n{\nswitch(index) {\ncase 0:  return textureLod(sobelDerivatives[0], texCoord + vec2(offset) / texSize, 0.0f);\ncase 1:  return textureLod(sobelDerivatives[1], texCoord + vec2(offset) / texSize, 0.0f);\ncase 2:  return textureLod(sobelDerivatives[2], texCoord + vec2(offset) / texSize, 0.0f);\ncase 3:  return textureLod(sobelDerivatives[3], texCoord + vec2(offset) / texSize, 0.0f);\ncase 4:  return textureLod(sobelDerivatives[4], texCoord + vec2(offset) / texSize, 0.0f);\ncase 5:  return textureLod(sobelDerivatives[5], texCoord + vec2(offset) / texSize, 0.0f);\ncase 6:  return textureLod(sobelDerivatives[6], texCoord + vec2(offset) / texSize, 0.0f);\ndefault: return textureLod(sobelDerivatives[0], texCoord + vec2(offset) / texSize, 0.0f);\n}\n}\nvoid main()\n{\nivec2 thread = threadLocation();\nvec4 pixel = threadPixel(pyramid);\nvec2 best = vec2(0.0f, pixel.a);\nint r = (windowSize - 1) / 2;\nfor(int octave = 0; octave < numberOfOctaves; octave++) {\nvec3 m = vec3(0.0f, 0.0f, 0.0f);\nfor(int j = 0; j < windowSize; j++) {\nfor(int i = 0; i < windowSize; i++) {\nvec2 df = decodeSobel(pickSobelDerivatives(octave, ivec2(i-r, j-r)));\nm += vec3(df.x * df.x, df.x * df.y, df.y * df.y);\n}\n}\nfloat response = 0.5f * (m.x + m.z - sqrt((m.x - m.z) * (m.x - m.z) + 4.0f * m.y * m.y));\nfloat score = clamp(response / 8.0f, 0.0f, 1.0f);\nfloat lod = 0.5f * float(octave);\nfloat scale = encodeLod(lod);\nbest = (score > best.x) ? vec2(score, scale) : best;\n}\ncolor = vec4(best.x, pixel.g, best.xy);\n}'},function(e,t){e.exports='@include "pyramids.glsl"\nuniform sampler2D image;\n#define ENABLE_INNER_RING\n#define ENABLE_MIDDLE_RING\n#define ENABLE_OUTER_RING\nvoid main()\n{\nvec4 pixel = threadPixel(image);\nfloat lod = decodeLod(pixel.a);\nfloat lodJump = 0.5f;\ncolor = pixel;\nif(pixel.r == 0.0f)\nreturn;\n#ifdef ENABLE_INNER_RING\nvec4 p0 = pixelAtShortOffset(image, ivec2(0, 1));\nvec4 p1 = pixelAtShortOffset(image, ivec2(1, 1));\nvec4 p2 = pixelAtShortOffset(image, ivec2(1, 0));\nvec4 p3 = pixelAtShortOffset(image, ivec2(1, -1));\nvec4 p4 = pixelAtShortOffset(image, ivec2(0, -1));\nvec4 p5 = pixelAtShortOffset(image, ivec2(-1, -1));\nvec4 p6 = pixelAtShortOffset(image, ivec2(-1, 0));\nvec4 p7 = pixelAtShortOffset(image, ivec2(-1, 1));\n#else\nvec4 p0, p1, p2, p3, p4, p5, p6, p7;\np0 = p1 = p2 = p3 = p4 = p5 = p6 = p7 = vec4(0.0f, 0.0f, 0.0f, 1.0f);\n#endif\n#ifdef ENABLE_MIDDLE_RING\nvec4 q0 = pixelAtShortOffset(image, ivec2(0, 2));\nvec4 q1 = pixelAtShortOffset(image, ivec2(1, 2));\nvec4 q2 = pixelAtShortOffset(image, ivec2(2, 2));\nvec4 q3 = pixelAtShortOffset(image, ivec2(2, 1));\nvec4 q4 = pixelAtShortOffset(image, ivec2(2, 0));\nvec4 q5 = pixelAtShortOffset(image, ivec2(2, -1));\nvec4 q6 = pixelAtShortOffset(image, ivec2(2, -2));\nvec4 q7 = pixelAtShortOffset(image, ivec2(1, -2));\nvec4 q8 = pixelAtShortOffset(image, ivec2(0, -2));\nvec4 q9 = pixelAtShortOffset(image, ivec2(-1, -2));\nvec4 q10 = pixelAtShortOffset(image, ivec2(-2, -2));\nvec4 q11 = pixelAtShortOffset(image, ivec2(-2, -1));\nvec4 q12 = pixelAtShortOffset(image, ivec2(-2, 0));\nvec4 q13 = pixelAtShortOffset(image, ivec2(-2, 1));\nvec4 q14 = pixelAtShortOffset(image, ivec2(-2, 2));\nvec4 q15 = pixelAtShortOffset(image, ivec2(-1, 2));\n#else\nvec4 q0, q1, q2, q3, q4, q5, q6, q7, q8, q9, q10, q11, q12, q13, q14, q15;\nq0 = q1 = q2 = q3 = q4 = q5 = q6 = q7 = q8 = q9 = q10 =\nq11 = q12 = q13 = q14 = q15= vec4(0.0f, 0.0f, 0.0f, 1.0f);\n#endif\n#ifdef ENABLE_OUTER_RING\nvec4 r0 = pixelAtShortOffset(image, ivec2(0, 3));\nvec4 r1 = pixelAtShortOffset(image, ivec2(1, 3));\nvec4 r2 = pixelAtShortOffset(image, ivec2(3, 1));\nvec4 r3 = pixelAtShortOffset(image, ivec2(3, 0));\nvec4 r4 = pixelAtShortOffset(image, ivec2(3, -1));\nvec4 r5 = pixelAtShortOffset(image, ivec2(1, -3));\nvec4 r6 = pixelAtShortOffset(image, ivec2(0, -3));\nvec4 r7 = pixelAtShortOffset(image, ivec2(-1, -3));\nvec4 r8 = pixelAtShortOffset(image, ivec2(-3, -1));\nvec4 r9 = pixelAtShortOffset(image, ivec2(-3, 0));\nvec4 r10 = pixelAtShortOffset(image, ivec2(-3, 1));\nvec4 r11 = pixelAtShortOffset(image, ivec2(-1, 3));\nvec4 r12 = pixelAtShortOffset(image, ivec2(0, 4));\nvec4 r13 = pixelAtShortOffset(image, ivec2(4, 0));\nvec4 r14 = pixelAtShortOffset(image, ivec2(0, -4));\nvec4 r15 = pixelAtShortOffset(image, ivec2(-4, 0));\n#else\nvec4 r0, r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12, r13, r14, r15;\nr0 = r1 = r2 = r3 = r4 = r5 = r6 = r7 = r8 = r9 = r10 =\nr11 = r12 = r13 = r14 = r15 = vec4(0.0f, 0.0f, 0.0f, 1.0f);\n#endif\nfloat lodPlus = min(lod + lodJump, F_PYRAMID_MAX_LEVELS - 1.0f);\nfloat lodMinus = max(lod - lodJump, 0.0f);\nfloat alphaPlus = encodeLod(lodPlus);\nfloat alphaMinus = encodeLod(lodMinus);\nmat3 innerScore = mat3(\np0.r * float(isSameEncodedLod(p0.a, alphaPlus) || isSameEncodedLod(p0.a, alphaMinus)),\np1.r * float(isSameEncodedLod(p1.a, alphaPlus) || isSameEncodedLod(p1.a, alphaMinus)),\np2.r * float(isSameEncodedLod(p2.a, alphaPlus) || isSameEncodedLod(p2.a, alphaMinus)),\np3.r * float(isSameEncodedLod(p3.a, alphaPlus) || isSameEncodedLod(p3.a, alphaMinus)),\np4.r * float(isSameEncodedLod(p4.a, alphaPlus) || isSameEncodedLod(p4.a, alphaMinus)),\np5.r * float(isSameEncodedLod(p5.a, alphaPlus) || isSameEncodedLod(p5.a, alphaMinus)),\np6.r * float(isSameEncodedLod(p6.a, alphaPlus) || isSameEncodedLod(p6.a, alphaMinus)),\np7.r * float(isSameEncodedLod(p7.a, alphaPlus) || isSameEncodedLod(p7.a, alphaMinus)),\n0.0f\n);\nmat4 middleScore = mat4(\nq0.r * float(isSameEncodedLod(q0.a, alphaPlus) || isSameEncodedLod(q0.a, alphaMinus)),\nq1.r * float(isSameEncodedLod(q1.a, alphaPlus) || isSameEncodedLod(q1.a, alphaMinus)),\nq2.r * float(isSameEncodedLod(q2.a, alphaPlus) || isSameEncodedLod(q2.a, alphaMinus)),\nq3.r * float(isSameEncodedLod(q3.a, alphaPlus) || isSameEncodedLod(q3.a, alphaMinus)),\nq4.r * float(isSameEncodedLod(q4.a, alphaPlus) || isSameEncodedLod(q4.a, alphaMinus)),\nq5.r * float(isSameEncodedLod(q5.a, alphaPlus) || isSameEncodedLod(q5.a, alphaMinus)),\nq6.r * float(isSameEncodedLod(q6.a, alphaPlus) || isSameEncodedLod(q6.a, alphaMinus)),\nq7.r * float(isSameEncodedLod(q7.a, alphaPlus) || isSameEncodedLod(q7.a, alphaMinus)),\nq8.r * float(isSameEncodedLod(q8.a, alphaPlus) || isSameEncodedLod(q8.a, alphaMinus)),\nq9.r * float(isSameEncodedLod(q9.a, alphaPlus) || isSameEncodedLod(q9.a, alphaMinus)),\nq10.r * float(isSameEncodedLod(q10.a, alphaPlus) || isSameEncodedLod(q10.a, alphaMinus)),\nq11.r * float(isSameEncodedLod(q11.a, alphaPlus) || isSameEncodedLod(q11.a, alphaMinus)),\nq12.r * float(isSameEncodedLod(q12.a, alphaPlus) || isSameEncodedLod(q12.a, alphaMinus)),\nq13.r * float(isSameEncodedLod(q13.a, alphaPlus) || isSameEncodedLod(q13.a, alphaMinus)),\nq14.r * float(isSameEncodedLod(q14.a, alphaPlus) || isSameEncodedLod(q14.a, alphaMinus)),\nq15.r * float(isSameEncodedLod(q15.a, alphaPlus) || isSameEncodedLod(q15.a, alphaMinus))\n);\nmat4 outerScore = mat4(\nr0.r * float(isSameEncodedLod(r0.a, alphaPlus) || isSameEncodedLod(r0.a, alphaMinus)),\nr1.r * float(isSameEncodedLod(r1.a, alphaPlus) || isSameEncodedLod(r1.a, alphaMinus)),\nr2.r * float(isSameEncodedLod(r2.a, alphaPlus) || isSameEncodedLod(r2.a, alphaMinus)),\nr3.r * float(isSameEncodedLod(r3.a, alphaPlus) || isSameEncodedLod(r3.a, alphaMinus)),\nr4.r * float(isSameEncodedLod(r4.a, alphaPlus) || isSameEncodedLod(r4.a, alphaMinus)),\nr5.r * float(isSameEncodedLod(r5.a, alphaPlus) || isSameEncodedLod(r5.a, alphaMinus)),\nr6.r * float(isSameEncodedLod(r6.a, alphaPlus) || isSameEncodedLod(r6.a, alphaMinus)),\nr7.r * float(isSameEncodedLod(r7.a, alphaPlus) || isSameEncodedLod(r7.a, alphaMinus)),\nr8.r * float(isSameEncodedLod(r8.a, alphaPlus) || isSameEncodedLod(r8.a, alphaMinus)),\nr9.r * float(isSameEncodedLod(r9.a, alphaPlus) || isSameEncodedLod(r9.a, alphaMinus)),\nr10.r * float(isSameEncodedLod(r10.a, alphaPlus) || isSameEncodedLod(r10.a, alphaMinus)),\nr11.r * float(isSameEncodedLod(r11.a, alphaPlus) || isSameEncodedLod(r11.a, alphaMinus)),\nr12.r * float(isSameEncodedLod(r12.a, alphaPlus) || isSameEncodedLod(r12.a, alphaMinus)),\nr13.r * float(isSameEncodedLod(r13.a, alphaPlus) || isSameEncodedLod(r13.a, alphaMinus)),\nr14.r * float(isSameEncodedLod(r14.a, alphaPlus) || isSameEncodedLod(r14.a, alphaMinus)),\nr15.r * float(isSameEncodedLod(r15.a, alphaPlus) || isSameEncodedLod(r15.a, alphaMinus))\n);\nvec3 maxInnerScore3 = max(innerScore[0], max(innerScore[1], innerScore[2]));\nvec4 maxMiddleScore4 = max(max(middleScore[0], middleScore[1]), max(middleScore[2], middleScore[3]));\nvec4 maxOuterScore4 = max(max(outerScore[0], outerScore[1]), max(outerScore[2], outerScore[3]));\nfloat maxInnerScore = max(maxInnerScore3.x, max(maxInnerScore3.y, maxInnerScore3.z));\nfloat maxMiddleScore = max(max(maxMiddleScore4.x, maxMiddleScore4.y), max(maxMiddleScore4.z, maxMiddleScore4.w));\nfloat maxOuterScore = max(max(maxOuterScore4.x, maxOuterScore4.y), max(maxOuterScore4.z, maxOuterScore4.w));\nfloat maxScore = max(maxInnerScore, max(maxMiddleScore, maxOuterScore));\nfloat myScore = step(maxScore, pixel.r) * pixel.r;\ncolor = vec4(myScore, pixel.gba);\n}'},function(e,t){e.exports="uniform sampler2D image;\nvoid main()\n{\nfloat p0 = pixelAtShortOffset(image, ivec2(0, 1)).r;\nfloat p1 = pixelAtShortOffset(image, ivec2(1, 1)).r;\nfloat p2 = pixelAtShortOffset(image, ivec2(1, 0)).r;\nfloat p3 = pixelAtShortOffset(image, ivec2(1, -1)).r;\nfloat p4 = pixelAtShortOffset(image, ivec2(0, -1)).r;\nfloat p5 = pixelAtShortOffset(image, ivec2(-1, -1)).r;\nfloat p6 = pixelAtShortOffset(image, ivec2(-1, 0)).r;\nfloat p7 = pixelAtShortOffset(image, ivec2(-1, 1)).r;\nfloat m = max(\nmax(max(p0, p1), max(p2, p3)),\nmax(max(p4, p5), max(p6, p7))\n);\nvec4 pixel = threadPixel(image);\nfloat score = step(m, pixel.r) * pixel.r;\ncolor = vec4(score, pixel.gba);\n}"},function(e,t){e.exports='@include "keypoints.glsl"\nuniform sampler2D encodedCorners;\nuniform int encoderLength;\nuniform sampler2D pyramid;\nconst int descriptorSize = 32;\nconst ivec4 pat31[256] = ivec4[256](\nivec4(8,-3,9,5),\nivec4(4,2,7,-12),\nivec4(-11,9,-8,2),\nivec4(7,-12,12,-13),\nivec4(2,-13,2,12),\nivec4(1,-7,1,6),\nivec4(-2,-10,-2,-4),\nivec4(-13,-13,-11,-8),\nivec4(-13,-3,-12,-9),\nivec4(10,4,11,9),\nivec4(-13,-8,-8,-9),\nivec4(-11,7,-9,12),\nivec4(7,7,12,6),\nivec4(-4,-5,-3,0),\nivec4(-13,2,-12,-3),\nivec4(-9,0,-7,5),\nivec4(12,-6,12,-1),\nivec4(-3,6,-2,12),\nivec4(-6,-13,-4,-8),\nivec4(11,-13,12,-8),\nivec4(4,7,5,1),\nivec4(5,-3,10,-3),\nivec4(3,-7,6,12),\nivec4(-8,-7,-6,-2),\nivec4(-2,11,-1,-10),\nivec4(-13,12,-8,10),\nivec4(-7,3,-5,-3),\nivec4(-4,2,-3,7),\nivec4(-10,-12,-6,11),\nivec4(5,-12,6,-7),\nivec4(5,-6,7,-1),\nivec4(1,0,4,-5),\nivec4(9,11,11,-13),\nivec4(4,7,4,12),\nivec4(2,-1,4,4),\nivec4(-4,-12,-2,7),\nivec4(-8,-5,-7,-10),\nivec4(4,11,9,12),\nivec4(0,-8,1,-13),\nivec4(-13,-2,-8,2),\nivec4(-3,-2,-2,3),\nivec4(-6,9,-4,-9),\nivec4(8,12,10,7),\nivec4(0,9,1,3),\nivec4(7,-5,11,-10),\nivec4(-13,-6,-11,0),\nivec4(10,7,12,1),\nivec4(-6,-3,-6,12),\nivec4(10,-9,12,-4),\nivec4(-13,8,-8,-12),\nivec4(-13,0,-8,-4),\nivec4(3,3,7,8),\nivec4(5,7,10,-7),\nivec4(-1,7,1,-12),\nivec4(3,-10,5,6),\nivec4(2,-4,3,-10),\nivec4(-13,0,-13,5),\nivec4(-13,-7,-12,12),\nivec4(-13,3,-11,8),\nivec4(-7,12,-4,7),\nivec4(6,-10,12,8),\nivec4(-9,-1,-7,-6),\nivec4(-2,-5,0,12),\nivec4(-12,5,-7,5),\nivec4(3,-10,8,-13),\nivec4(-7,-7,-4,5),\nivec4(-3,-2,-1,-7),\nivec4(2,9,5,-11),\nivec4(-11,-13,-5,-13),\nivec4(-1,6,0,-1),\nivec4(5,-3,5,2),\nivec4(-4,-13,-4,12),\nivec4(-9,-6,-9,6),\nivec4(-12,-10,-8,-4),\nivec4(10,2,12,-3),\nivec4(7,12,12,12),\nivec4(-7,-13,-6,5),\nivec4(-4,9,-3,4),\nivec4(7,-1,12,2),\nivec4(-7,6,-5,1),\nivec4(-13,11,-12,5),\nivec4(-3,7,-2,-6),\nivec4(7,-8,12,-7),\nivec4(-13,-7,-11,-12),\nivec4(1,-3,12,12),\nivec4(2,-6,3,0),\nivec4(-4,3,-2,-13),\nivec4(-1,-13,1,9),\nivec4(7,1,8,-6),\nivec4(1,-1,3,12),\nivec4(9,1,12,6),\nivec4(-1,-9,-1,3),\nivec4(-13,-13,-10,5),\nivec4(7,7,10,12),\nivec4(12,-5,12,9),\nivec4(6,3,7,11),\nivec4(5,-13,6,10),\nivec4(2,-12,2,3),\nivec4(3,8,4,-6),\nivec4(2,6,12,-13),\nivec4(9,-12,10,3),\nivec4(-8,4,-7,9),\nivec4(-11,12,-4,-6),\nivec4(1,12,2,-8),\nivec4(6,-9,7,-4),\nivec4(2,3,3,-2),\nivec4(6,3,11,0),\nivec4(3,-3,8,-8),\nivec4(7,8,9,3),\nivec4(-11,-5,-6,-4),\nivec4(-10,11,-5,10),\nivec4(-5,-8,-3,12),\nivec4(-10,5,-9,0),\nivec4(8,-1,12,-6),\nivec4(4,-6,6,-11),\nivec4(-10,12,-8,7),\nivec4(4,-2,6,7),\nivec4(-2,0,-2,12),\nivec4(-5,-8,-5,2),\nivec4(7,-6,10,12),\nivec4(-9,-13,-8,-8),\nivec4(-5,-13,-5,-2),\nivec4(8,-8,9,-13),\nivec4(-9,-11,-9,0),\nivec4(1,-8,1,-2),\nivec4(7,-4,9,1),\nivec4(-2,1,-1,-4),\nivec4(11,-6,12,-11),\nivec4(-12,-9,-6,4),\nivec4(3,7,7,12),\nivec4(5,5,10,8),\nivec4(0,-4,2,8),\nivec4(-9,12,-5,-13),\nivec4(0,7,2,12),\nivec4(-1,2,1,7),\nivec4(5,11,7,-9),\nivec4(3,5,6,-8),\nivec4(-13,-4,-8,9),\nivec4(-5,9,-3,-3),\nivec4(-4,-7,-3,-12),\nivec4(6,5,8,0),\nivec4(-7,6,-6,12),\nivec4(-13,6,-5,-2),\nivec4(1,-10,3,10),\nivec4(4,1,8,-4),\nivec4(-2,-2,2,-13),\nivec4(2,-12,12,12),\nivec4(-2,-13,0,-6),\nivec4(4,1,9,3),\nivec4(-6,-10,-3,-5),\nivec4(-3,-13,-1,1),\nivec4(7,5,12,-11),\nivec4(4,-2,5,-7),\nivec4(-13,9,-9,-5),\nivec4(7,1,8,6),\nivec4(7,-8,7,6),\nivec4(-7,-4,-7,1),\nivec4(-8,11,-7,-8),\nivec4(-13,6,-12,-8),\nivec4(2,4,3,9),\nivec4(10,-5,12,3),\nivec4(-6,-5,-6,7),\nivec4(8,-3,9,-8),\nivec4(2,-12,2,8),\nivec4(-11,-2,-10,3),\nivec4(-12,-13,-7,-9),\nivec4(-11,0,-10,-5),\nivec4(5,-3,11,8),\nivec4(-2,-13,-1,12),\nivec4(-1,-8,0,9),\nivec4(-13,-11,-12,-5),\nivec4(-10,-2,-10,11),\nivec4(-3,9,-2,-13),\nivec4(2,-3,3,2),\nivec4(-9,-13,-4,0),\nivec4(-4,6,-3,-10),\nivec4(-4,12,-2,-7),\nivec4(-6,-11,-4,9),\nivec4(6,-3,6,11),\nivec4(-13,11,-5,5),\nivec4(11,11,12,6),\nivec4(7,-5,12,-2),\nivec4(-1,12,0,7),\nivec4(-4,-8,-3,-2),\nivec4(-7,1,-6,7),\nivec4(-13,-12,-8,-13),\nivec4(-7,-2,-6,-8),\nivec4(-8,5,-6,-9),\nivec4(-5,-1,-4,5),\nivec4(-13,7,-8,10),\nivec4(1,5,5,-13),\nivec4(1,0,10,-13),\nivec4(9,12,10,-1),\nivec4(5,-8,10,-9),\nivec4(-1,11,1,-13),\nivec4(-9,-3,-6,2),\nivec4(-1,-10,1,12),\nivec4(-13,1,-8,-10),\nivec4(8,-11,10,-6),\nivec4(2,-13,3,-6),\nivec4(7,-13,12,-9),\nivec4(-10,-10,-5,-7),\nivec4(-10,-8,-8,-13),\nivec4(4,-6,8,5),\nivec4(3,12,8,-13),\nivec4(-4,2,-3,-3),\nivec4(5,-13,10,-12),\nivec4(4,-13,5,-1),\nivec4(-9,9,-4,3),\nivec4(0,3,3,-9),\nivec4(-12,1,-6,1),\nivec4(3,2,4,-8),\nivec4(-10,-10,-10,9),\nivec4(8,-13,12,12),\nivec4(-8,-12,-6,-5),\nivec4(2,2,3,7),\nivec4(10,6,11,-8),\nivec4(6,8,8,-12),\nivec4(-7,10,-6,5),\nivec4(-3,-9,-3,9),\nivec4(-1,-13,-1,5),\nivec4(-3,-7,-3,4),\nivec4(-8,-2,-8,3),\nivec4(4,2,12,12),\nivec4(2,-5,3,11),\nivec4(6,-9,11,-13),\nivec4(3,-1,7,12),\nivec4(11,-1,12,4),\nivec4(-3,0,-3,6),\nivec4(4,-11,4,12),\nivec4(2,-4,2,1),\nivec4(-10,-6,-8,1),\nivec4(-13,7,-11,1),\nivec4(-13,12,-11,-13),\nivec4(6,0,11,-13),\nivec4(0,-1,1,4),\nivec4(-13,3,-9,-2),\nivec4(-9,8,-6,-3),\nivec4(-13,-6,-8,-2),\nivec4(5,-9,8,10),\nivec4(2,7,3,-9),\nivec4(-1,-6,-1,-1),\nivec4(9,5,11,-2),\nivec4(11,-3,12,-8),\nivec4(3,0,3,5),\nivec4(-1,4,0,10),\nivec4(3,-6,4,5),\nivec4(-13,0,-10,5),\nivec4(5,8,12,11),\nivec4(8,9,9,-6),\nivec4(7,-4,8,-12),\nivec4(-10,4,-10,9),\nivec4(7,3,12,4),\nivec4(9,-7,10,-2),\nivec4(7,0,12,-2),\nivec4(-1,-6,0,-11)\n);\nvoid getPair(int index, float kcos, float ksin, out ivec2 p, out ivec2 q)\n{\nivec4 data = pat31[index];\nvec2 op = vec2(data.xy);\nvec2 oq = vec2(data.zw);\np = ivec2(round(op.x * kcos - op.y * ksin), round(op.x * ksin + op.y * kcos));\nq = ivec2(round(oq.x * kcos - oq.y * ksin), round(oq.x * ksin + oq.y * kcos));\n}\nvoid main()\n{\nvec4 pixel = threadPixel(encodedCorners);\nivec2 thread = threadLocation();\nKeypointAddress address = findKeypointAddress(thread, encoderLength, descriptorSize);\nint descriptorCell = address.offset - 2;\ncolor = pixel;\nif(descriptorCell < 0)\nreturn;\nKeypoint keypoint = decodeKeypoint(encodedCorners, encoderLength, address);\nif(isDiscardedOrNullKeypoint(keypoint))\nreturn;\nfloat pot = exp2(keypoint.lod);\nfloat kcos = cos(keypoint.orientation);\nfloat ksin = sin(keypoint.orientation);\nvec2 imageSize = vec2(textureSize(pyramid, 0));\nint patternStart = 32 * descriptorCell;\nuint test[4] = uint[4](0u, 0u, 0u, 0u);\nfor(int t = 0; t < 4; t++) {\nuint bits = 0u;\nivec2 p, q;\nvec4 a, b;\nint i = t * 8;\nfor(int j = 0; j < 8; j++) {\ngetPair(patternStart + i + j, kcos, ksin, p, q);\na = pyrPixelAtEx(pyramid, round(keypoint.position + pot * vec2(p)), keypoint.lod, imageSize);\nb = pyrPixelAtEx(pyramid, round(keypoint.position + pot * vec2(q)), keypoint.lod, imageSize);\nbits |= uint(a.g < b.g) << j;\n}\ntest[t] = bits;\n}\ncolor = vec4(float(test[0]), float(test[1]), float(test[2]), float(test[3])) / 255.0f;\n}'},function(e,t){e.exports='@include "keypoints.glsl"\nuniform sampler2D pyramid;\nuniform sampler2D encodedKeypoints;\nuniform int patchRadius;\nuniform int descriptorSize;\nuniform int encoderLength;\nconst int patchStart[8] = int[8](0, 0, 8, 28, 64, 132, 228, 356);\nconst int patchPointCount[8] = int[8](0, 8, 20, 36, 68, 96, 128, 168);\nconst ivec2 patchData[524] = ivec2[524](\nivec2(-1,-1),ivec2(0,-1),ivec2(1,-1),ivec2(-1,0),ivec2(1,0),ivec2(-1,1),ivec2(0,1),ivec2(1,1),\nivec2(-1,-2),ivec2(0,-2),ivec2(1,-2),ivec2(-2,-1),ivec2(-1,-1),ivec2(0,-1),ivec2(1,-1),ivec2(2,-1),ivec2(-2,0),ivec2(-1,0),ivec2(1,0),ivec2(2,0),ivec2(-2,1),ivec2(-1,1),ivec2(0,1),ivec2(1,1),ivec2(2,1),ivec2(-1,2),ivec2(0,2),ivec2(1,2),\nivec2(-1,-3),ivec2(0,-3),ivec2(1,-3),ivec2(-2,-2),ivec2(-1,-2),ivec2(0,-2),ivec2(1,-2),ivec2(2,-2),ivec2(-3,-1),ivec2(-2,-1),ivec2(-1,-1),ivec2(0,-1),ivec2(1,-1),ivec2(2,-1),ivec2(3,-1),ivec2(-3,0),ivec2(-2,0),ivec2(-1,0),ivec2(1,0),ivec2(2,0),ivec2(3,0),ivec2(-3,1),ivec2(-2,1),ivec2(-1,1),ivec2(0,1),ivec2(1,1),ivec2(2,1),ivec2(3,1),ivec2(-2,2),ivec2(-1,2),ivec2(0,2),ivec2(1,2),ivec2(2,2),ivec2(-1,3),ivec2(0,3),ivec2(1,3),\nivec2(-2,-4),ivec2(-1,-4),ivec2(0,-4),ivec2(1,-4),ivec2(2,-4),ivec2(-3,-3),ivec2(-2,-3),ivec2(-1,-3),ivec2(0,-3),ivec2(1,-3),ivec2(2,-3),ivec2(3,-3),ivec2(-4,-2),ivec2(-3,-2),ivec2(-2,-2),ivec2(-1,-2),ivec2(0,-2),ivec2(1,-2),ivec2(2,-2),ivec2(3,-2),ivec2(4,-2),ivec2(-4,-1),ivec2(-3,-1),ivec2(-2,-1),ivec2(-1,-1),ivec2(0,-1),ivec2(1,-1),ivec2(2,-1),ivec2(3,-1),ivec2(4,-1),ivec2(-4,0),ivec2(-3,0),ivec2(-2,0),ivec2(-1,0),ivec2(1,0),ivec2(2,0),ivec2(3,0),ivec2(4,0),ivec2(-4,1),ivec2(-3,1),ivec2(-2,1),ivec2(-1,1),ivec2(0,1),ivec2(1,1),ivec2(2,1),ivec2(3,1),ivec2(4,1),ivec2(-4,2),ivec2(-3,2),ivec2(-2,2),ivec2(-1,2),ivec2(0,2),ivec2(1,2),ivec2(2,2),ivec2(3,2),ivec2(4,2),ivec2(-3,3),ivec2(-2,3),ivec2(-1,3),ivec2(0,3),ivec2(1,3),ivec2(2,3),ivec2(3,3),ivec2(-2,4),ivec2(-1,4),ivec2(0,4),ivec2(1,4),ivec2(2,4),\nivec2(-2,-5),ivec2(-1,-5),ivec2(0,-5),ivec2(1,-5),ivec2(2,-5),ivec2(-3,-4),ivec2(-2,-4),ivec2(-1,-4),ivec2(0,-4),ivec2(1,-4),ivec2(2,-4),ivec2(3,-4),ivec2(-4,-3),ivec2(-3,-3),ivec2(-2,-3),ivec2(-1,-3),ivec2(0,-3),ivec2(1,-3),ivec2(2,-3),ivec2(3,-3),ivec2(4,-3),ivec2(-5,-2),ivec2(-4,-2),ivec2(-3,-2),ivec2(-2,-2),ivec2(-1,-2),ivec2(0,-2),ivec2(1,-2),ivec2(2,-2),ivec2(3,-2),ivec2(4,-2),ivec2(5,-2),ivec2(-5,-1),ivec2(-4,-1),ivec2(-3,-1),ivec2(-2,-1),ivec2(-1,-1),ivec2(0,-1),ivec2(1,-1),ivec2(2,-1),ivec2(3,-1),ivec2(4,-1),ivec2(5,-1),ivec2(-5,0),ivec2(-4,0),ivec2(-3,0),ivec2(-2,0),ivec2(-1,0),ivec2(1,0),ivec2(2,0),ivec2(3,0),ivec2(4,0),ivec2(5,0),ivec2(-5,1),ivec2(-4,1),ivec2(-3,1),ivec2(-2,1),ivec2(-1,1),ivec2(0,1),ivec2(1,1),ivec2(2,1),ivec2(3,1),ivec2(4,1),ivec2(5,1),ivec2(-5,2),ivec2(-4,2),ivec2(-3,2),ivec2(-2,2),ivec2(-1,2),ivec2(0,2),ivec2(1,2),ivec2(2,2),ivec2(3,2),ivec2(4,2),ivec2(5,2),ivec2(-4,3),ivec2(-3,3),ivec2(-2,3),ivec2(-1,3),ivec2(0,3),ivec2(1,3),ivec2(2,3),ivec2(3,3),ivec2(4,3),ivec2(-3,4),ivec2(-2,4),ivec2(-1,4),ivec2(0,4),ivec2(1,4),ivec2(2,4),ivec2(3,4),ivec2(-2,5),ivec2(-1,5),ivec2(0,5),ivec2(1,5),ivec2(2,5),\nivec2(-2,-6),ivec2(-1,-6),ivec2(0,-6),ivec2(1,-6),ivec2(2,-6),ivec2(-3,-5),ivec2(-2,-5),ivec2(-1,-5),ivec2(0,-5),ivec2(1,-5),ivec2(2,-5),ivec2(3,-5),ivec2(-4,-4),ivec2(-3,-4),ivec2(-2,-4),ivec2(-1,-4),ivec2(0,-4),ivec2(1,-4),ivec2(2,-4),ivec2(3,-4),ivec2(4,-4),ivec2(-5,-3),ivec2(-4,-3),ivec2(-3,-3),ivec2(-2,-3),ivec2(-1,-3),ivec2(0,-3),ivec2(1,-3),ivec2(2,-3),ivec2(3,-3),ivec2(4,-3),ivec2(5,-3),ivec2(-6,-2),ivec2(-5,-2),ivec2(-4,-2),ivec2(-3,-2),ivec2(-2,-2),ivec2(-1,-2),ivec2(0,-2),ivec2(1,-2),ivec2(2,-2),ivec2(3,-2),ivec2(4,-2),ivec2(5,-2),ivec2(6,-2),ivec2(-6,-1),ivec2(-5,-1),ivec2(-4,-1),ivec2(-3,-1),ivec2(-2,-1),ivec2(-1,-1),ivec2(0,-1),ivec2(1,-1),ivec2(2,-1),ivec2(3,-1),ivec2(4,-1),ivec2(5,-1),ivec2(6,-1),ivec2(-6,0),ivec2(-5,0),ivec2(-4,0),ivec2(-3,0),ivec2(-2,0),ivec2(-1,0),ivec2(1,0),ivec2(2,0),ivec2(3,0),ivec2(4,0),ivec2(5,0),ivec2(6,0),ivec2(-6,1),ivec2(-5,1),ivec2(-4,1),ivec2(-3,1),ivec2(-2,1),ivec2(-1,1),ivec2(0,1),ivec2(1,1),ivec2(2,1),ivec2(3,1),ivec2(4,1),ivec2(5,1),ivec2(6,1),ivec2(-6,2),ivec2(-5,2),ivec2(-4,2),ivec2(-3,2),ivec2(-2,2),ivec2(-1,2),ivec2(0,2),ivec2(1,2),ivec2(2,2),ivec2(3,2),ivec2(4,2),ivec2(5,2),ivec2(6,2),ivec2(-5,3),ivec2(-4,3),ivec2(-3,3),ivec2(-2,3),ivec2(-1,3),ivec2(0,3),ivec2(1,3),ivec2(2,3),ivec2(3,3),ivec2(4,3),ivec2(5,3),ivec2(-4,4),ivec2(-3,4),ivec2(-2,4),ivec2(-1,4),ivec2(0,4),ivec2(1,4),ivec2(2,4),ivec2(3,4),ivec2(4,4),ivec2(-3,5),ivec2(-2,5),ivec2(-1,5),ivec2(0,5),ivec2(1,5),ivec2(2,5),ivec2(3,5),ivec2(-2,6),ivec2(-1,6),ivec2(0,6),ivec2(1,6),ivec2(2,6),\nivec2(-2,-7),ivec2(-1,-7),ivec2(0,-7),ivec2(1,-7),ivec2(2,-7),ivec2(-4,-6),ivec2(-3,-6),ivec2(-2,-6),ivec2(-1,-6),ivec2(0,-6),ivec2(1,-6),ivec2(2,-6),ivec2(3,-6),ivec2(4,-6),ivec2(-5,-5),ivec2(-3,-5),ivec2(-2,-5),ivec2(-1,-5),ivec2(0,-5),ivec2(1,-5),ivec2(2,-5),ivec2(3,-5),ivec2(5,-5),ivec2(-6,-4),ivec2(-4,-4),ivec2(-3,-4),ivec2(-2,-4),ivec2(-1,-4),ivec2(0,-4),ivec2(1,-4),ivec2(2,-4),ivec2(3,-4),ivec2(4,-4),ivec2(6,-4),ivec2(-6,-3),ivec2(-5,-3),ivec2(-4,-3),ivec2(-3,-3),ivec2(-2,-3),ivec2(-1,-3),ivec2(0,-3),ivec2(1,-3),ivec2(2,-3),ivec2(3,-3),ivec2(4,-3),ivec2(5,-3),ivec2(6,-3),ivec2(-7,-2),ivec2(-6,-2),ivec2(-5,-2),ivec2(-4,-2),ivec2(-3,-2),ivec2(-2,-2),ivec2(-1,-2),ivec2(0,-2),ivec2(1,-2),ivec2(2,-2),ivec2(3,-2),ivec2(4,-2),ivec2(5,-2),ivec2(6,-2),ivec2(7,-2),ivec2(-7,-1),ivec2(-6,-1),ivec2(-5,-1),ivec2(-4,-1),ivec2(-3,-1),ivec2(-2,-1),ivec2(-1,-1),ivec2(0,-1),ivec2(1,-1),ivec2(2,-1),ivec2(3,-1),ivec2(4,-1),ivec2(5,-1),ivec2(6,-1),ivec2(7,-1),ivec2(-7,0),ivec2(-6,0),ivec2(-5,0),ivec2(-4,0),ivec2(-3,0),ivec2(-2,0),ivec2(-1,0),ivec2(1,0),ivec2(2,0),ivec2(3,0),ivec2(4,0),ivec2(5,0),ivec2(6,0),ivec2(7,0),ivec2(-7,1),ivec2(-6,1),ivec2(-5,1),ivec2(-4,1),ivec2(-3,1),ivec2(-2,1),ivec2(-1,1),ivec2(0,1),ivec2(1,1),ivec2(2,1),ivec2(3,1),ivec2(4,1),ivec2(5,1),ivec2(6,1),ivec2(7,1),ivec2(-7,2),ivec2(-6,2),ivec2(-5,2),ivec2(-4,2),ivec2(-3,2),ivec2(-2,2),ivec2(-1,2),ivec2(0,2),ivec2(1,2),ivec2(2,2),ivec2(3,2),ivec2(4,2),ivec2(5,2),ivec2(6,2),ivec2(7,2),ivec2(-6,3),ivec2(-5,3),ivec2(-4,3),ivec2(-3,3),ivec2(-2,3),ivec2(-1,3),ivec2(0,3),ivec2(1,3),ivec2(2,3),ivec2(3,3),ivec2(4,3),ivec2(5,3),ivec2(6,3),ivec2(-6,4),ivec2(-4,4),ivec2(-3,4),ivec2(-2,4),ivec2(-1,4),ivec2(0,4),ivec2(1,4),ivec2(2,4),ivec2(3,4),ivec2(4,4),ivec2(6,4),ivec2(-5,5),ivec2(-3,5),ivec2(-2,5),ivec2(-1,5),ivec2(0,5),ivec2(1,5),ivec2(2,5),ivec2(3,5),ivec2(5,5),ivec2(-4,6),ivec2(-3,6),ivec2(-2,6),ivec2(-1,6),ivec2(0,6),ivec2(1,6),ivec2(2,6),ivec2(3,6),ivec2(4,6),ivec2(-2,7),ivec2(-1,7),ivec2(0,7),ivec2(1,7),ivec2(2,7)\n);\nconst int MIN_PATCH_RADIUS = 3;\nconst int MAX_PATCH_RADIUS = 7;\nvoid main()\n{\nvec4 pixel = threadPixel(encodedKeypoints);\nivec2 thread = threadLocation();\nKeypointAddress address = findKeypointAddress(thread, encoderLength, descriptorSize);\ncolor = pixel;\nif(address.offset != 1)\nreturn;\nKeypoint keypoint = decodeKeypoint(encodedKeypoints, encoderLength, address);\nfloat pot = exp2(keypoint.lod);\nvec2 m = vec2(0.0f);\nivec2 pyrBaseSize = textureSize(pyramid, 0);\nint scaledRadius = int(ceil(float(patchRadius) / pot));\nint radius = clamp(scaledRadius, MIN_PATCH_RADIUS, MAX_PATCH_RADIUS);\nint start = patchStart[radius];\nint count = patchPointCount[radius];\nfor(int j = 0; j < count; j++) {\nvec2 offset = vec2(patchData[start + j]);\nvec2 position = keypoint.position + round(pot * offset);\nvec4 patchPixel = pyrPixelAtEx(pyramid, position, keypoint.lod, pyrBaseSize);\nm += offset * patchPixel.g;\n}\nfloat angle = fastAtan2(m.y, m.x);\ncolor.g = encodeOrientation(angle);\n}'},function(e,t){e.exports='@include "pyramids.glsl"\nuniform sampler2D image;\nvoid main()\n{\nvec4 pixel = threadPixel(image);\nivec2 thread = threadLocation();\nfloat lod = decodeLod(pixel.a);\nfloat pot = exp2(lod);\ncolor = pixel;\nif(pixel.r == 0.0f)\nreturn;\nvec4 p0 = pixelAtShortOffset(image, ivec2(0, 1));\nvec4 p1 = pixelAtShortOffset(image, ivec2(1, 1));\nvec4 p2 = pixelAtShortOffset(image, ivec2(1, 0));\nvec4 p3 = pixelAtShortOffset(image, ivec2(1, -1));\nvec4 p4 = pixelAtShortOffset(image, ivec2(0, -1));\nvec4 p5 = pixelAtShortOffset(image, ivec2(-1, -1));\nvec4 p6 = pixelAtShortOffset(image, ivec2(-1, 0));\nvec4 p7 = pixelAtShortOffset(image, ivec2(-1, 1));\nmat3 score = mat3(\np0.r * float(isSameEncodedLod(p0.a, pixel.a)),\np1.r * float(isSameEncodedLod(p1.a, pixel.a)),\np2.r * float(isSameEncodedLod(p2.a, pixel.a)),\np3.r * float(isSameEncodedLod(p3.a, pixel.a)),\np4.r * float(isSameEncodedLod(p4.a, pixel.a)),\np5.r * float(isSameEncodedLod(p5.a, pixel.a)),\np6.r * float(isSameEncodedLod(p6.a, pixel.a)),\np7.r * float(isSameEncodedLod(p7.a, pixel.a)),\n0.0f\n);\nvec3 maxScore3 = max(score[0], max(score[1], score[2]));\nfloat maxScore = max(maxScore3.x, max(maxScore3.y, maxScore3.z));\nfloat myScore = step(maxScore, pixel.r) * pixel.r;\ncolor = vec4(myScore, pixel.gba);\n}'},function(e,t){e.exports="uniform sampler2D image;\nvoid main()\n{\nivec2 thread = threadLocation();\nivec2 pos = min(thread * 2, textureSize(image, 0) - 1);\ncolor = pixelAt(image, pos);\n}"},function(e,t){e.exports="uniform sampler2D image;\nvoid main()\n{\nivec2 thread = threadLocation();\nivec2 pos = min(thread * 3, textureSize(image, 0) - 1);\ncolor = pixelAt(image, pos);\n}"},function(e,t){e.exports="uniform sampler2D image;\nvoid main()\n{\nivec2 thread = threadLocation();\nvec4 pixel = pixelAt(image, thread / 2);\ncolor = (((thread.x + thread.y) & 1) == 0) ? pixel : vec4(0.0f, 0.0f, 0.0f, pixel.a);\n}"},function(e,t){e.exports="uniform sampler2D image;\nvoid main()\n{\nivec2 thread = threadLocation();\nvec4 pixel = pixelAt(image, thread / 3);\nbool cond = ((thread.x - (thread.y % 3) + 3) % 3) == 0;\ncolor = (((thread.x - (thread.y % 3) + 3) % 3) == 0) ? pixel : vec4(0.0f, 0.0f, 0.0f, pixel.a);\n}"},function(e,t){e.exports='@include "keypoints.glsl"\nuniform sampler2D pyramid;\nuniform sampler2D encodedKeypoints;\nuniform int windowSize;\nuniform float discardThreshold;\nuniform int firstKeypointIndex, lastKeypointIndex;\nuniform int descriptorSize;\nuniform int encoderLength;\n#ifndef MAX_WINDOW_SIZE\n#error Must define MAX_WINDOW_SIZE\n#endif\nconst int MAX_WINDOW_SIZE_PLUS = MAX_WINDOW_SIZE + 2;\nconst int MAX_WINDOW_SIZE_PLUS_SQUARED = MAX_WINDOW_SIZE_PLUS * MAX_WINDOW_SIZE_PLUS;\nconst int MAX_WINDOW_RADIUS_PLUS = (MAX_WINDOW_SIZE_PLUS - 1) / 2;\nconst float DISCARD_SCALE = 0.00024318695068359375f;\nfloat pixelBuffer[MAX_WINDOW_SIZE_PLUS_SQUARED];\n#define pixelIndex(i, j) (((j) + MAX_WINDOW_RADIUS_PLUS) * MAX_WINDOW_SIZE_PLUS + ((i) + MAX_WINDOW_RADIUS_PLUS))\n#define windowRadius() ((windowSize - 1) / 2)\nvoid readWindow(vec2 center, float lod)\n{\nivec2 pyrBaseSize = textureSize(pyramid, 0);\nfloat pot = exp2(lod);\nint r = windowRadius();\n#define readPixelAt(ox, oy) pixelBuffer[pixelIndex((ox), (oy))] = pyrSubpixelAtExOffset(pyramid, center, lod, pot, ivec2((ox), (oy)), pyrBaseSize).g\nfor(int j = 0; j < windowSize; j++) {\nfor(int i = 0; i < windowSize; i++) {\nreadPixelAt(i-r, j-r);\n}\n}\nint r1 = r+1;\nfor(int k = 0; k < windowSize; k++) {\nreadPixelAt(-r1, k-r);\nreadPixelAt( r1, k-r);\nreadPixelAt(k-r,-r1);\nreadPixelAt(k-r, r1);\n}\nreadPixelAt(-r1,-r1);\nreadPixelAt( r1,-r1);\nreadPixelAt(-r1, r1);\nreadPixelAt( r1, r1);\n}\nvec2 computeDerivatives(ivec2 offset)\n{\nconst mat3 derivX = mat3(\n3, 0, -3,\n10, 0, -10,\n3, 0, -3\n);\nconst mat3 derivY = mat3(\n3, 10, 3,\n0, 0, 0,\n-3, -10, -3\n);\nmat3 window = mat3(\npixelBuffer[pixelIndex(offset.x-1, offset.y-1)],\npixelBuffer[pixelIndex(offset.x+0, offset.y-1)],\npixelBuffer[pixelIndex(offset.x+1, offset.y-1)],\npixelBuffer[pixelIndex(offset.x-1, offset.y+0)],\n0.0f,\npixelBuffer[pixelIndex(offset.x+1, offset.y+0)],\npixelBuffer[pixelIndex(offset.x-1, offset.y+1)],\npixelBuffer[pixelIndex(offset.x+0, offset.y+1)],\npixelBuffer[pixelIndex(offset.x+1, offset.y+1)]\n);\nmat3 fx = matrixCompMult(derivX, window);\nmat3 fy = matrixCompMult(derivY, window);\nconst vec3 ones = vec3(1.0f);\nreturn vec2(\ndot(fx[0], ones) + dot(fx[1], ones) + dot(fx[2], ones),\ndot(fy[0], ones) + dot(fy[1], ones) + dot(fy[2], ones)\n);\n}\nvoid main()\n{\nvec4 pixel = threadPixel(encodedKeypoints);\nivec2 thread = threadLocation();\nKeypointAddress address = findKeypointAddress(thread, encoderLength, descriptorSize);\nint r = windowRadius();\ncolor = pixel;\nif(address.offset != 1)\nreturn;\nKeypoint keypoint = decodeKeypoint(encodedKeypoints, encoderLength, address);\nif(isDiscardedOrNullKeypoint(keypoint))\nreturn;\nint idx = findKeypointIndex(address, descriptorSize);\nif(idx < firstKeypointIndex || idx > lastKeypointIndex)\nreturn;\nreadWindow(keypoint.position, keypoint.lod);\nvec2 derivatives = vec2(0.0f);\nmat2 harris = mat2(0.0f, 0.0f, 0.0f, 0.0f);\nfor(int j = 0; j < windowSize; j++) {\nfor(int i = 0; i < windowSize; i++) {\nderivatives = computeDerivatives(ivec2(i-r, j-r));\nharris += mat2(\nderivatives.x * derivatives.x, derivatives.x * derivatives.y,\nderivatives.x * derivatives.y, derivatives.y * derivatives.y\n) * DISCARD_SCALE;\n}\n}\nfloat delta = harris[0][0] - harris[1][1];\nfloat eigenvalue = 0.5f * ((harris[0][0] + harris[1][1]) - sqrt(delta * delta - 4.0f * harris[0][1] * harris[0][1]));\nint windowArea = windowSize * windowSize;\nfloat cornerness = eigenvalue / float(windowArea);\nbool unsuitable = (cornerness < discardThreshold);\ncolor = vec4(pixel.rgb, float(unsuitable));\n}'},function(e,t){e.exports='@include "keypoints.glsl"\nuniform sampler2D nextPyramid;\nuniform sampler2D prevPyramid;\nuniform sampler2D prevKeypoints;\nuniform int windowSize;\nuniform int depth;\nuniform int firstKeypointIndex, lastKeypointIndex;\nuniform int descriptorSize;\nuniform int encoderLength;\n#ifndef NUM_ITERATIONS\n#define NUM_ITERATIONS 5\n#endif\n#ifndef MAX_WINDOW_SIZE\n#error Must define MAX_WINDOW_SIZE\n#endif\n#ifndef DISCARD_MARGIN\n#define DISCARD_MARGIN 20\n#endif\n#define NEXT_IMAGE 1\n#define PREV_IMAGE 0\nconst int MAX_WINDOW_SIZE_PLUS = MAX_WINDOW_SIZE + 2;\nconst int MAX_WINDOW_SIZE_PLUS_SQUARED = MAX_WINDOW_SIZE_PLUS * MAX_WINDOW_SIZE_PLUS;\nconst int DBL_MAX_WINDOW_SIZE_PLUS_SQUARED = 2 * MAX_WINDOW_SIZE_PLUS_SQUARED;\nconst int MAX_WINDOW_RADIUS_PLUS = (MAX_WINDOW_SIZE_PLUS - 1) / 2;\n#define windowRadius() ((windowSize - 1) / 2)\nfloat pixelBuffer[DBL_MAX_WINDOW_SIZE_PLUS_SQUARED];\n#define prevPixel(index) pixelBuffer[(index)]\n#define nextPixel(index) pixelBuffer[MAX_WINDOW_SIZE_PLUS_SQUARED + (index)]\n#define pixelIndex(i, j) (((j) + MAX_WINDOW_RADIUS_PLUS) * MAX_WINDOW_SIZE_PLUS + ((i) + MAX_WINDOW_RADIUS_PLUS))\nvoid readWindow(vec2 center, float lod)\n{\nivec2 pyrBaseSize = textureSize(prevPyramid, 0);\nfloat pot = exp2(lod);\nint r = windowRadius();\nivec2 offset; int idx;\n#define readPixelsAt(ox, oy) offset = ivec2((ox), (oy)); idx = pixelIndex(offset.x, offset.y); nextPixel(idx) = pyrSubpixelAtExOffset(nextPyramid, center, lod, pot, offset, pyrBaseSize).g; prevPixel(idx) = pyrSubpixelAtExOffset(prevPyramid, center, lod, pot, offset, pyrBaseSize).g\nfor(int j = 0; j < windowSize; j++) {\nfor(int i = 0; i < windowSize; i++) {\nreadPixelsAt(i-r, j-r);\n}\n}\nint r1 = r+1;\nfor(int k = 0; k < windowSize; k++) {\nreadPixelsAt(-r1, k-r);\nreadPixelsAt( r1, k-r);\nreadPixelsAt(k-r,-r1);\nreadPixelsAt(k-r, r1);\n}\nreadPixelsAt(-r1,-r1);\nreadPixelsAt( r1,-r1);\nreadPixelsAt(-r1, r1);\nreadPixelsAt( r1, r1);\n}\nvec2 computeDerivatives(int imageCode, ivec2 offset)\n{\nconst mat3 derivX = mat3(\n3, 0, -3,\n10, 0, -10,\n3, 0, -3\n);\nconst mat3 derivY = mat3(\n3, 10, 3,\n0, 0, 0,\n-3, -10, -3\n);\nint indexOffset = imageCode * MAX_WINDOW_SIZE_PLUS_SQUARED;\nmat3 window = mat3(\npixelBuffer[indexOffset + pixelIndex(offset.x-1, offset.y-1)],\npixelBuffer[indexOffset + pixelIndex(offset.x+0, offset.y-1)],\npixelBuffer[indexOffset + pixelIndex(offset.x+1, offset.y-1)],\npixelBuffer[indexOffset + pixelIndex(offset.x-1, offset.y+0)],\n0.0f,\npixelBuffer[indexOffset + pixelIndex(offset.x+1, offset.y+0)],\npixelBuffer[indexOffset + pixelIndex(offset.x-1, offset.y+1)],\npixelBuffer[indexOffset + pixelIndex(offset.x+0, offset.y+1)],\npixelBuffer[indexOffset + pixelIndex(offset.x+1, offset.y+1)]\n);\nmat3 fx = matrixCompMult(derivX, window);\nmat3 fy = matrixCompMult(derivY, window);\nconst vec3 ones = vec3(1.0f);\nreturn vec2(\ndot(fx[0], ones) + dot(fx[1], ones) + dot(fx[2], ones),\ndot(fy[0], ones) + dot(fy[1], ones) + dot(fy[2], ones)\n);\n}\nfloat readBufferedPixel(int imageCode, ivec2 offset)\n{\nivec2 limit = ivec2(windowRadius());\noffset = clamp(offset, -limit, limit);\nint indexOffset = imageCode * MAX_WINDOW_SIZE_PLUS_SQUARED;\nreturn pixelBuffer[indexOffset + pixelIndex(offset.x, offset.y)];\n}\nvoid main()\n{\nvec4 pixel = threadPixel(prevKeypoints);\nivec2 thread = threadLocation();\nKeypointAddress address = findKeypointAddress(thread, encoderLength, descriptorSize);\nint r = windowRadius();\ncolor = pixel;\nif(address.offset > 0)\nreturn;\nKeypoint keypoint = decodeKeypoint(prevKeypoints, encoderLength, address);\nif(isDiscardedOrNullKeypoint(keypoint))\nreturn;\nint idx = findKeypointIndex(address, descriptorSize);\nif(idx < firstKeypointIndex || idx > lastKeypointIndex)\nreturn;\nvec2 pyrGuess = vec2(0.0f);\nfor(int d = 0; d < depth; d++) {\nfloat lod = float(depth - 1 - d);\nreadWindow(keypoint.position, lod);\nhighp mat2 invHarris = mat2(0.0f, 0.0f, 0.0f, 0.0f);\nfor(int j = 0; j < windowSize; j++) {\nfor(int i = 0; i < windowSize; i++) {\nvec2 derivatives = computeDerivatives(PREV_IMAGE, ivec2(i-r, j-r));\ninvHarris += mat2(\nderivatives.y * derivatives.y, -derivatives.x * derivatives.y,\n-derivatives.x * derivatives.y, derivatives.x * derivatives.x\n);\n}\n}\nconst float minDet = 0.00001f;\nhighp float det = invHarris[0][0] * invHarris[1][1] - invHarris[0][1] * invHarris[1][0];\nhighp vec2 localGuess = vec2(0.0f);\nfor(int k = 0; k < NUM_ITERATIONS; k++) {\nhighp vec2 spaceTime = vec2(0.0f);\nfor(int _y = 0; _y < windowSize; _y++) {\nfor(int _x = 0; _x < windowSize; _x++) {\nint x = _x - r; int y = _y - r;\nvec2 spatialDerivative = computeDerivatives(PREV_IMAGE, ivec2(x, y));\nfloat timeDerivative = readBufferedPixel(NEXT_IMAGE,\nivec2(round(vec2(x, y) + pyrGuess + localGuess))\n) - readBufferedPixel(PREV_IMAGE, ivec2(x, y));\nspaceTime += spatialDerivative * timeDerivative;\n}\n}\nhighp vec2 localOpticalFlow = abs(det) < minDet ? vec2(0.0f) : invHarris * spaceTime / det;\nlocalGuess += localOpticalFlow;\n}\npyrGuess = 2.0f * (pyrGuess + localGuess);\n}\nvec2 opticalFlow = pyrGuess;\nvec2 nextPosition = keypoint.position + opticalFlow;\nvec2 imageSize = vec2(textureSize(nextPyramid, 0));\nfloat margin = float(DISCARD_MARGIN);\nbool keypointIsWithinBoundaries = (\nnextPosition.x >= margin &&\nnextPosition.y >= margin &&\nnextPosition.x <= imageSize.x - margin &&\nnextPosition.y <= imageSize.y - margin\n);\ncolor = keypointIsWithinBoundaries ? encodeKeypointPosition(nextPosition) : encodeDiscardedKeypointPosition();\n}'},function(e,t){e.exports='@include "colors.glsl"\nuniform sampler2D dest, src;\nuniform int destComponents;\nuniform int srcComponentId;\nvoid main()\n{\nvec4 destPixel = threadPixel(dest);\nvec4 srcPixel = threadPixel(src);\nbvec4 flags = bvec4(\n(destComponents & PIXELCOMPONENT_RED) != 0,\n(destComponents & PIXELCOMPONENT_GREEN) != 0,\n(destComponents & PIXELCOMPONENT_BLUE) != 0,\n(destComponents & PIXELCOMPONENT_ALPHA) != 0\n);\ncolor = mix(destPixel, vec4(srcPixel[srcComponentId]), flags);\n}'},function(e,t){e.exports='@include "colors.glsl"\nuniform sampler2D image;\nuniform int pixelComponents;\nuniform float value;\nvoid main()\n{\nvec4 pixel = threadPixel(image);\nbvec4 flags = bvec4(\n(pixelComponents & PIXELCOMPONENT_RED) != 0,\n(pixelComponents & PIXELCOMPONENT_GREEN) != 0,\n(pixelComponents & PIXELCOMPONENT_BLUE) != 0,\n(pixelComponents & PIXELCOMPONENT_ALPHA) != 0\n);\ncolor = mix(pixel, vec4(value), flags);\n}'},function(e,t){e.exports="uniform float value;\nvoid main()\n{\ncolor = vec4(value);\n}"},function(e,t){e.exports="uniform sampler2D image;\nvoid main() {\nivec2 pos = threadLocation();\npos.y = int(texSize.y) - 1 - pos.y;\ncolor = pixelAt(image, pos);\n}"},function(e,t){e.exports="uniform sampler2D image;\nvoid main()\n{\ncolor = threadPixel(image);\n}"},function(e,t){e.exports="uniform sampler2D image;\nuniform int iterationNumber;\nvoid main()\n{\nivec2 thread = threadLocation();\nivec2 last = outputSize() - ivec2(1);\nint jump = (1 << iterationNumber);\nint clusterLength = jump << 1;\nint clusterMask = clusterLength - 1;\nivec2 clusterPos = ivec2(thread >> (1 + iterationNumber)) << (1 + iterationNumber);\nivec2 next1 = clusterPos + ((thread - clusterPos + ivec2(jump, 0)) & clusterMask);\nivec2 next2 = clusterPos + ((thread - clusterPos + ivec2(0, jump)) & clusterMask);\nivec2 next3 = clusterPos + ((thread - clusterPos + ivec2(jump, jump)) & clusterMask);\nvec4 p0 = texelFetch(image, thread, 0);\nvec4 p1 = texelFetch(image, min(next1, last), 0);\nvec4 p2 = texelFetch(image, min(next2, last), 0);\nvec4 p3 = texelFetch(image, min(next3, last), 0);\nvec4 pmax = max(max(p0, p1), max(p2, p3));\nvec4 pmin = min(min(p0, p1), min(p2, p3));\ncolor = vec4(pmax.r, pmin.g, pmax.r - pmin.g, p0.a);\n}"},function(e,t,i){"use strict";i.r(t),i.d(t,"Speedy",(function(){return pt}));var n=i(2),r=i(0);const s=navigator.userAgent.includes("Firefox");class o{static getError(e){const t=e.getError(),i=["NO_ERROR","INVALID_ENUM","INVALID_VALUE","INVALID_OPERATION","INVALID_FRAMEBUFFER_OPERATION","OUT_OF_MEMORY","CONTEXT_LOST_WEBGL"].find(i=>e[i]==t)||"Unknown";return new r.e(i)}static createShader(e,t,i){const n=e.createShader(t);return e.shaderSource(n,i),e.compileShader(n),n}static createProgram(e,t,i){const n=e.createProgram(),s=o.createShader(e,e.VERTEX_SHADER,t),a=o.createShader(e,e.FRAGMENT_SHADER,i);if(e.attachShader(n,s),e.attachShader(n,a),e.linkProgram(n),e.validateProgram(n),!e.getProgramParameter(n,e.LINK_STATUS)&&!e.isContextLost()){const t=[e.getShaderInfoLog(a),e.getShaderInfoLog(s),e.getProgramInfoLog(n)];e.deleteProgram(n),e.deleteShader(a),e.deleteShader(s);const o=e=>Math.max(0,2-Math.floor(Math.log10(e))),c=e=>Array(o(e)).fill(" ").join("")+e+". ",l=i.split("\n").map((e,t)=>c(1+t)+e).join("\n");throw new r.e("Can't create shader.\n\n---------- ERROR ----------\n"+t.join("\n")+"\n\n---------- SOURCE CODE ----------\n"+l)}return n}static createStandardGeometry(e,t,i){const n=o.createStandardGeometry,r=n._cache||(n._cache=new WeakMap);if(r.has(e))return r.get(e);const s=e.createVertexArray(),a=[e.createBuffer(),e.createBuffer()];e.bindVertexArray(s),e.bindBuffer(e.ARRAY_BUFFER,a[0]),e.bufferData(e.ARRAY_BUFFER,new Float32Array([-1,-1,1,-1,-1,1,1,1]),e.STATIC_DRAW),e.enableVertexAttribArray(t),e.vertexAttribPointer(t,2,e.FLOAT,!1,0,0),e.bindBuffer(e.ARRAY_BUFFER,a[1]),e.bufferData(e.ARRAY_BUFFER,new Float32Array([0,0,1,0,0,1,1,1]),e.STATIC_DRAW),e.enableVertexAttribArray(i),e.vertexAttribPointer(i,2,e.FLOAT,!1,0,0),e.bindBuffer(e.ARRAY_BUFFER,null);const c={vao:s,vbo:a};return r.set(e,c),c}static createTexture(e,t,i){if(t<=0||i<=0)throw new r.f("Invalid dimensions given to createTexture()");const n=e.createTexture();return e.bindTexture(e.TEXTURE_2D,n),e.texParameteri(e.TEXTURE_2D,e.TEXTURE_MIN_FILTER,e.NEAREST),e.texParameteri(e.TEXTURE_2D,e.TEXTURE_MAG_FILTER,e.NEAREST),e.texParameteri(e.TEXTURE_2D,e.TEXTURE_WRAP_S,e.MIRRORED_REPEAT),e.texParameteri(e.TEXTURE_2D,e.TEXTURE_WRAP_T,e.MIRRORED_REPEAT),e.texImage2D(e.TEXTURE_2D,0,e.RGBA8,t,i,0,e.RGBA,e.UNSIGNED_BYTE,null),e.bindTexture(e.TEXTURE_2D,null),n}static destroyTexture(e,t){return e.deleteTexture(t),null}static uploadToTexture(e,t,i,n,r,s=0){return e.bindTexture(e.TEXTURE_2D,t),e.texImage2D(e.TEXTURE_2D,s,e.RGBA8,e.RGBA,e.UNSIGNED_BYTE,r),e.bindTexture(e.TEXTURE_2D,null),t}static generateMipmap(e,t){e.bindTexture(e.TEXTURE_2D,t),e.texParameteri(e.TEXTURE_2D,e.TEXTURE_MIN_FILTER,e.LINEAR_MIPMAP_NEAREST),e.generateMipmap(e.TEXTURE_2D),e.bindTexture(e.TEXTURE_2D,null)}static bindTextures(e,t,i){const n=Object.keys(t);if(!e.isContextLost()){if(n.length>e.MAX_COMBINED_TEXTURE_IMAGE_UNITS)throw new r.e(`Can't bind ${n.length} textures to a program: max is ${e.MAX_COMBINED_TEXTURE_IMAGE_UNITS}`);for(let r=0;r<n.length;r++)e.activeTexture(e.TEXTURE0+r),e.bindTexture(e.TEXTURE_2D,t[n[r]]),e.uniform1i(i[n[r]],r)}}static createFramebuffer(e,t){const i=e.createFramebuffer();e.bindFramebuffer(e.FRAMEBUFFER,i),e.framebufferTexture2D(e.FRAMEBUFFER,e.COLOR_ATTACHMENT0,e.TEXTURE_2D,t,0);const n=e.checkFramebufferStatus(e.FRAMEBUFFER);if(n!=e.FRAMEBUFFER_COMPLETE){const t=["FRAMEBUFFER_UNSUPPORTED","FRAMEBUFFER_INCOMPLETE_ATTACHMENT","FRAMEBUFFER_INCOMPLETE_DIMENSIONS","FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT","FRAMEBUFFER_INCOMPLETE_MULTISAMPLE"].filter(t=>e[t]===n)[0]||"unknown error";throw new r.e(`Can't create framebuffer: ${t} (${n})`)}return e.bindFramebuffer(e.FRAMEBUFFER,null),i}static destroyFramebuffer(e,t){return e.deleteFramebuffer(t),null}static clientWaitAsync(e,t,i=0){return new Promise((r,a)=>{!function c(){const l=e.clientWaitSync(t,i,0);l==e.TIMEOUT_EXPIRED?n.a.setZeroTimeout(c):l==e.WAIT_FAILED?s&&e.getError()==e.NO_ERROR?n.a.setZeroTimeout(c):a(o.getError(e)):r()}()})}static getBufferSubDataAsync(e,t,i,n,s,a=0,c=0){const l=e.fenceSync(e.SYNC_GPU_COMMANDS_COMPLETE,0),d=performance.now();return e.flush(),o.clientWaitAsync(e,l).then(()=>(e.bindBuffer(i,t),e.getBufferSubData(i,n,s,a,c),e.bindBuffer(i,null),performance.now()-d)).catch(e=>{throw new r.g("Can't getBufferSubDataAsync(): error in clientWaitAsync()",e)}).finally(()=>{e.deleteSync(l)})}static readPixelsViaPBO(e,t,i,n,s,a,c=null){const l=e.createBuffer();if(!(t.byteLength>=s*a*4))throw new r.f("Can't read pixels: invalid buffer size");return e.bindBuffer(e.PIXEL_PACK_BUFFER,l),e.bufferData(e.PIXEL_PACK_BUFFER,t.byteLength,e.STREAM_READ),c?(e.bindFramebuffer(e.FRAMEBUFFER,c),e.readPixels(i,n,s,a,e.RGBA,e.UNSIGNED_BYTE,0),e.bindFramebuffer(e.FRAMEBUFFER,null)):e.readPixels(i,n,s,a,e.RGBA,e.UNSIGNED_BYTE,0),e.bindBuffer(e.PIXEL_PACK_BUFFER,null),o.getBufferSubDataAsync(e,l,e.PIXEL_PACK_BUFFER,0,t,0,0).then(e=>e).catch(e=>{throw new r.g("Can't read pixels",e)}).finally(()=>{e.deleteBuffer(l)})}}class a{constructor(e,t,i){this._gl=e,this._width=t,this._height=i,this._glTexture=o.createTexture(this._gl,this._width,this._height),this._hasMipmaps=!1}release(){if(null===this._glTexture)throw new r.g("The SpeedyTexture has already been released");return o.destroyTexture(this._gl,this._glTexture),this._glTexture=null,this._width=this._height=0,null}upload(e,t=0){this._hasMipmaps=!1,o.uploadToTexture(this._gl,this._glTexture,this._width,this._height,e,0|t)}generateMipmap(){return this._hasMipmaps||(o.generateMipmap(this._gl,this._glTexture),this._hasMipmaps=!0),this}discardMipmap(){this._hasMipmaps=!1}get glTexture(){return this._glTexture}get width(){return this._width}get height(){return this._height}get gl(){return this._gl}}const c={sampler2D:"uniform1i",float:"uniform1f",int:"uniform1i",uint:"uniform1ui",bool:"uniform1i",vec2:"uniform2f",vec3:"uniform3f",vec4:"uniform4f",ivec2:"uniform2i",ivec3:"uniform3i",ivec4:"uniform4i",uvec2:"uniform2ui",uvec3:"uniform3ui",uvec4:"uniform4ui",bvec2:"uniform2i",bvec3:"uniform3i",bvec4:"uniform4i"};class l extends Function{constructor(e,t,i={}){return super("...args","return this._self._call(...args)"),this._self=this.bind(this),this._self._init(e,t,i),this._self}resize(e,t){if(this._gl.isContextLost())return;if(e=Math.max(1,0|e),t=Math.max(1,0|t),e===this._stdprog.width&&t===this._stdprog.height)return;const i=this._options;i.output[0]=e,i.output[1]=t,this._reallocatePixelBuffers(e,t),this._stdprog.resize(e,t)}readPixelsSync(e=0,t=0,i=-1,n=-1){const r=this._gl;return r.isContextLost()||(i<0&&(i=this._stdprog.width),n<0&&(n=this._stdprog.height),i=Math.min(i,this._stdprog.width),n=Math.min(n,this._stdprog.height),e=Math.max(0,Math.min(e,i-1)),t=Math.max(0,Math.min(t,n-1)),null==this._pixelBuffer[0]&&this._reallocatePixelBuffers(this._stdprog.width,this._stdprog.height),null!=this._stdprog.fbo?(r.bindFramebuffer(r.FRAMEBUFFER,this._stdprog.fbo),r.readPixels(e,t,i,n,r.RGBA,r.UNSIGNED_BYTE,this._pixelBuffer[0]),r.bindFramebuffer(r.FRAMEBUFFER,null)):r.readPixels(e,t,i,n,r.RGBA,r.UNSIGNED_BYTE,this._pixelBuffer[0])),this._pixelBuffer[0]}readPixelsAsync(e=0,t=0,i=-1,n=-1,r=!0){const s=this._gl;if(s.isContextLost())return Promise.resolve(this._pixelBuffer[0]);if(i<0&&(i=this._stdprog.width),n<0&&(n=this._stdprog.height),i=Math.min(i,this._stdprog.width),n=Math.min(n,this._stdprog.height),e=Math.max(0,Math.min(e,i-1)),t=Math.max(0,Math.min(t,n-1)),null==this._pixelBuffer[0]&&this._reallocatePixelBuffers(this._stdprog.width,this._stdprog.height),!r)return o.readPixelsViaPBO(s,this._pixelBuffer[0],e,t,i,n,this._stdprog.fbo).then(e=>this._pixelBuffer[0]);if(this._pboProducerQueue.length>0){const r=this._pboProducerQueue.shift();o.readPixelsViaPBO(s,this._pixelBuffer[r],e,t,i,n,this._stdprog.fbo).then(e=>{this._pboConsumerQueue.push(r)})}else f(this._pboProducerQueue).then(r=>{const a=this._pboProducerQueue.shift();o.readPixelsViaPBO(s,this._pixelBuffer[a],e,t,i,n,this._stdprog.fbo).then(e=>{this._pboConsumerQueue.push(a)})});if(this._pboConsumerQueue.length>0){const e=this._pboConsumerQueue.shift();return new Promise(t=>{t(this._pixelBuffer[e]),this._pboProducerQueue.push(e)})}return new Promise(e=>{f(this._pboConsumerQueue).then(t=>{const i=this._pboConsumerQueue.shift();e(this._pixelBuffer[i]),this._pboProducerQueue.push(i)})})}setUBO(e,t){null===this._ubo&&(this._ubo=new p(this._gl,this._stdprog.program)),this._ubo.set(e,t)}get uniforms(){return this._stdprog.uniform}clear(e=1,t=1,i=1,n=1){const r=this._gl,s=this._stdprog;return r.isContextLost()||s.clear(e,t,i,n),s.texture}_init(e,t,i){if((i={output:[e.drawingBufferWidth,e.drawingBufferHeight],uniforms:{},renderToTexture:!0,recycleTexture:!0,pingpong:!1,...i}).pingpong&&!i.renderToTexture)throw new r.g("Pingpong rendering can only be used when rendering to textures");let n=Math.max(1,0|i.output[0]),s=Math.max(1,0|i.output[1]);i.output=[n,s];const o=e.canvas;n>o.width&&(o.width=n),s>o.height&&(o.height=s);const a=new d(e,n,s,t,i.uniforms);i.renderToTexture&&a.attachFBO(i.pingpong);const c=t.arguments;for(let e=0;e<c.length;e++)if(!a.uniform.hasOwnProperty(c[e])&&!a.uniform.hasOwnProperty(c[e]+"[0]"))throw new r.g(`Can't run shader: expected uniform "${c[e]}"`);this._gl=e,this._source=t.fragmentSource,this._options=Object.freeze(i),this._stdprog=a,this._params=c,this._ubo=null,this._initPixelBuffers(e)}_call(...e){const t=this._gl,i=this._options,n=this._stdprog,s=this._params;if(t.isContextLost())return n.texture;if(e.length!=s.length)throw new r.f("Can't run shader: incorrect number of arguments");t.useProgram(n.program),n.dirtySize&&(t.uniform2f(n.uniform.texSize.location,n.width,n.height),n.dirtySize=!1);for(let t=0,i=0;t<e.length;t++){const o=s[t];let a=n.uniform[o];if(a)i=this._setUniform(a,e[t],i);else{if(!n.uniform.hasOwnProperty(o+"[0]"))throw new r.f(`Can't run shader: unknown parameter "${o}": ${e[t]}`);{const s=e[t];if(n.uniform.hasOwnProperty(`${o}[${s.length}]`))throw new r.f(`Can't run shader: too few elements in array "${o}"`);for(let e=0;a=n.uniform[`${o}[${e}]`];e++)i=this._setUniform(a,s[e],i)}}}null!==this._ubo&&this._ubo.update(),i.renderToTexture?t.bindFramebuffer(t.FRAMEBUFFER,n.fbo):t.bindFramebuffer(t.FRAMEBUFFER,null),t.viewport(0,0,n.width,n.height),t.drawArrays(t.TRIANGLE_STRIP,0,4);let o=null;if(i.renderToTexture){if(o=n.texture,!i.recycleTexture){const e=new a(t,n.width,n.height);t.activeTexture(t.TEXTURE0),t.bindTexture(t.TEXTURE_2D,e.glTexture),t.copyTexSubImage2D(t.TEXTURE_2D,0,0,0,0,0,n.width,n.height),t.bindTexture(t.TEXTURE_2D,null),o=e}i.pingpong&&n.pingpong(),o.discardMipmap()}return t.bindFramebuffer(t.FRAMEBUFFER,null),o}_setUniform(e,t,i){const n=this._gl;if("sampler2D"==e.type){if(i>n.MAX_COMBINED_TEXTURE_IMAGE_UNITS)throw new r.i(`Can't bind ${i} textures to a program: max is ${n.MAX_COMBINED_TEXTURE_IMAGE_UNITS}`);if(t===this._stdprog.texture)throw new r.i("Can't run shader: cannot use its output texture as an input to itself");if(null==t)throw new r.f("Can't run shader: cannot use null as an input texture");n.activeTexture(n.TEXTURE0+i),n.bindTexture(n.TEXTURE_2D,t.glTexture),n.uniform1i(e.location,i),i++}else if("number"==typeof t||"boolean"==typeof t)n[c[e.type]](e.location,t);else{if(!Array.isArray(t))throw new r.f(`Can't run shader: unrecognized argument "${t}"`);n[c[e.type]](e.location,...t)}return i}_initPixelBuffers(e){this._pixelBuffer=Array(1).fill(null),this._pixelBufferSize=[0,0],this._pboConsumerQueue=Array(1).fill(0).map((e,t)=>t),this._pboProducerQueue=[]}_reallocatePixelBuffers(e,t){if(!(e*t<=this._pixelBufferSize[0]*this._pixelBufferSize[1])){this._pixelBufferSize[0]=e,this._pixelBufferSize[1]=t;for(let i=0;i<1;i++){const n=this._pixelBuffer[i];this._pixelBuffer[i]=this._createPixelBuffer(e,t),n&&(n.length>this._pixelBuffer[i].length?this._pixelBuffer[i].set(n.slice(0,this._pixelBuffer[i].length)):this._pixelBuffer[i].set(n))}}}_createPixelBuffer(e,t){const i=new Uint8Array(e*t*4);return i.fill(255,0,4),i}}function d(e,t,i,n,s={}){const a=o.createProgram(e,n.vertexSource,n.fragmentSource);e.bindAttribLocation(a,0,n.attributes.position),e.bindAttribLocation(a,1,n.attributes.texCoord);const l=o.createStandardGeometry(e,0,1);t=Math.max(0|t,1),i=Math.max(0|i,1),s.texSize=[t,i];const d={};for(const e of n.uniforms)d[e]={type:n.uniformType(e)};e.useProgram(a);for(const t in d){if(d[t].location=e.getUniformLocation(a,t),!c.hasOwnProperty(d[t].type))throw new r.i("Unknown uniform type: "+d[t].type);if(s.hasOwnProperty(t)){const i=s[t];if("number"==typeof i||"boolean"==typeof i)e[c[d[t].type]](d[t].location,i);else{if("object"!=typeof i)throw new r.f(`Unrecognized uniform value: "${i}"`);e[c[d[t].type]](d[t].location,...Array.from(i))}}}this.gl=e,this.program=a,this.uniform=d,this.width=t,this.height=i,this.dirtySize=!1,this.vertexObjects=l,this._fbo=this._texture=null,this._texIndex=0,Object.defineProperty(this,"fbo",{get:()=>this._fbo?this._fbo[this._texIndex]:null}),Object.defineProperty(this,"texture",{get:()=>this._texture?this._texture[this._texIndex]:null})}function f(e){return new Promise(t=>{const i=performance.now();!function n(){e.length>0?t(performance.now()-i):setTimeout(n,0)}()})}function p(e,t){this._gl=e,this._program=t,this._nextIndex=0,this._ubo={}}d.prototype.attachFBO=function(e=!1){const t=this.gl,i=this.width,n=this.height,r=e?2:1;this._texIndex=0,this._texture=Array(r),this._fbo=Array(r);for(let e=0;e<r;e++)this._texture[e]=new a(t,i,n),this._fbo[e]=o.createFramebuffer(t,this._texture[e].glTexture)},d.prototype.detachFBO=function(){const e=this.gl;if(null!=this._fbo){for(let t of this._fbo)o.destroyFramebuffer(e,t);this._fbo=null}if(null!=this._texture){for(let e of this._texture)e.release();this._texture=null}this._texIndex=0},d.prototype.pingpong=function(){null!=this._fbo&&this._fbo.length>1&&(this._texIndex=1-this._texIndex)},d.prototype.resize=function(e,t){const i=this.gl;this.width,this.height;if(e=Math.max(1,0|e),t=Math.max(1,0|t),this.width=e,this.height=t,this.dirtySize=!0,null!=this._fbo){const n=this._fbo.length,r=Array(n),s=Array(n);for(let c=0;c<n;c++)r[c]=new a(i,e,t),s[c]=o.createFramebuffer(i,r[c].glTexture);for(let e of this._fbo)o.destroyFramebuffer(i,e);for(let e of this._texture)e.release();this._texture=r,this._fbo=s}},d.prototype.clear=function(e,t,i,n){const r=this.gl;if(null!=this._fbo){for(let s=0;s<this._fbo.length;s++)r.bindFramebuffer(r.FRAMEBUFFER,this._fbo[s]),r.viewport(0,0,this.width,this.height),r.clearColor(e,t,i,n),r.clear(r.COLOR_BUFFER_BIT);r.bindFramebuffer(r.FRAMEBUFFER,null)}},d.prototype.invalidateFramebuffer=function(){const e=this.gl;if(null!=this._fbo){for(let t=0;t<this._fbo.length;t++)e.bindFramebuffer(e.FRAMEBUFFER,this._fbo[t]),e.invalidateFramebuffer(e.FRAMEBUFFER,[e.COLOR_ATTACHMENT0]);e.bindFramebuffer(e.FRAMEBUFFER,null)}},p.prototype.set=function(e,t){const i=this._gl,n=this._program;this._ubo.hasOwnProperty(e)||(this._ubo[e]={buffer:i.createBuffer(),blockBindingIndex:this._nextIndex++});const r=this._ubo[e];if(!r.hasOwnProperty("blockIndex")){const t=i.getUniformBlockIndex(n,e);i.uniformBlockBinding(n,t,r.blockBindingIndex)}r.data=t},p.prototype.update=function(){const e=this._gl;for(const t in this._ubo){const i=this._ubo[t];e.bindBuffer(e.UNIFORM_BUFFER,i.buffer),e.bufferData(e.UNIFORM_BUFFER,i.data.byteLength,e.DYNAMIC_DRAW),e.bufferData(e.UNIFORM_BUFFER,i.data,e.DYNAMIC_DRAW),e.bindBufferBase(e.UNIFORM_BUFFER,i.blockBindingIndex,i.buffer),e.bindBuffer(e.UNIFORM_BUFFER,null)}};class h{constructor(e,t,i){this._gpu=e,this._width=t,this._height=i}declare(e,t,i={}){return Object.defineProperty(this,e,{get:(()=>{const n="__k_"+e;return function(){return this[n]||(this[n]=this._createProgram(t,i))}.bind(this)})()}),this}compose(e,...t){return Object.defineProperty(this,e,{get:(()=>{const i="__c_"+e;return function(){return this[i]||(this[i]=2==t.length?(()=>(t=t.map(e=>this[e]),function(e,...i){return t[1](t[0](e,...i),...i)}))():3==t.length?(()=>(t=t.map(e=>this[e]),function(e,...i){return t[2](t[1](t[0](e,...i),...i),...i)}))():4==t.length?(()=>(t=t.map(e=>this[e]),function(e,...i){return t[3](t[2](t[1](t[0](e,...i),...i),...i),...i)}))():(()=>(t=t.map(e=>this[e]),function(e,...i){return t.reduce((e,t)=>t(e,...i),e)}))())}.bind(this)})()}),this}get program(){return this._helpers||(this.helpers={hasTextureSize:(e,t)=>({output:[0|e,0|t]}),displaysGraphics:()=>({renderToTexture:!1}),doesNotRecycleTextures:()=>({recycleTexture:!1}),usesPingpongRendering:()=>({pingpong:!0})})}_createProgram(e,t={}){return new l(this._gpu.gl,e,{output:[this._width,this._height],...t})}}var u=i(1),m=i(4);const v=Object(u.b)("utils/identity.glsl").withArguments("image"),g=Object(u.b)("utils/flip-y.glsl").withArguments("image"),_=Object(u.b)("utils/fill.glsl").withArguments("value"),x=Object(u.b)("utils/fill-components.glsl").withArguments("image","pixelComponents","value"),S=Object(u.b)("utils/copy-components.glsl").withArguments("dest","src","destComponents","srcComponentId"),y=Object(u.b)("utils/scan-minmax2d.glsl").withArguments("image","iterationNumber");class b extends h{constructor(e,t,i){super(e,t,i),this.declare("identity",v).declare("output",g,{...this.program.displaysGraphics()}).declare("clone",v,{...this.program.doesNotRecycleTextures()}).declare("flipY",g).declare("fill",_).declare("fillComponents",x).declare("_copyComponents",S).declare("_scanMinMax2D",y,{...this.program.usesPingpongRendering()})}scanMax(e,t){const i=this._scanMinMax(e,t);return this.copyComponents(e,i,t,m.d.RED)}scanMin(e,t){const i=this._scanMinMax(e,t);return this.copyComponents(e,i,t,m.d.GREEN)}copyComponents(e,t,i,n){if(!m.a.hasOwnProperty(n))throw new r.f("Invalid srcComponent: "+n);const s=m.a[n];return this._copyComponents(e,t,i,s)}_scanMinMax(e,t){const i=0|Math.ceil(Math.log2(Math.max(this._width,this._height)));let n=this.copyComponents(e,e,m.d.ALL,t);for(let e=0;e<i;e++)n=this._scanMinMax2D(n,e);return n}}const O=Object(u.b)("colors/rgb2grey.glsl").withArguments("image");class w extends h{constructor(e,t,i){super(e,t,i),this.declare("rgb2grey",O)}}var A=i(3),E=i(6);const M=Object(u.b)("filters/fast-median.glsl").withArguments("image").withDefines({WINDOW_SIZE:3}),T=Object(u.b)("filters/fast-median.glsl").withArguments("image").withDefines({WINDOW_SIZE:5}),P=e=>Math.max(1,e/6);class L extends h{constructor(e,t,i){super(e,t,i),this.compose("gauss3","_gauss3x","_gauss3y").compose("gauss5","_gauss5x","_gauss5y").compose("gauss7","_gauss7x","_gauss7y").compose("gauss9","_gauss9x","_gauss9y").compose("gauss11","_gauss11x","_gauss11y").compose("box3","_box3x","_box3y").compose("box5","_box5x","_box5y").compose("box7","_box7x","_box7y").compose("box9","_box9x","_box9y").compose("box11","_box11x","_box11y").declare("median3",M).declare("median5",T).declare("median7",Object(E.median)(7)).compose("dog16_1","_dog16_1x","_dog16_1y").declare("texConv2D3",Object(A.texConv2D)(3),{...this.program.usesPingpongRendering()}).declare("texConv2D5",Object(A.texConv2D)(5),{...this.program.usesPingpongRendering()}).declare("texConv2D7",Object(A.texConv2D)(7),{...this.program.usesPingpongRendering()}).compose("texConvXY3","texConvX3","texConvY3").declare("texConvX3",Object(A.texConvX)(3)).declare("texConvY3",Object(A.texConvY)(3)).compose("texConvXY5","texConvX5","texConvY5").declare("texConvX5",Object(A.texConvX)(5)).declare("texConvY5",Object(A.texConvY)(5)).compose("texConvXY7","texConvX7","texConvY7").declare("texConvX7",Object(A.texConvX)(7)).declare("texConvY7",Object(A.texConvY)(7)).compose("texConvXY9","texConvX9","texConvY9").declare("texConvX9",Object(A.texConvX)(9)).declare("texConvY9",Object(A.texConvY)(9)).compose("texConvXY11","texConvX11","texConvY11").declare("texConvX11",Object(A.texConvX)(11)).declare("texConvY11",Object(A.texConvY)(11)).declare("createKernel3x3",Object(A.createKernel2D)(3),{...this.program.hasTextureSize(3,3),...this.program.doesNotRecycleTextures()}).declare("createKernel5x5",Object(A.createKernel2D)(5),{...this.program.hasTextureSize(5,5),...this.program.doesNotRecycleTextures()}).declare("createKernel7x7",Object(A.createKernel2D)(7),{...this.program.hasTextureSize(7,7),...this.program.doesNotRecycleTextures()}).declare("createKernel3x1",Object(A.createKernel1D)(3),{...this.program.hasTextureSize(3,1),...this.program.doesNotRecycleTextures()}).declare("createKernel5x1",Object(A.createKernel1D)(5),{...this.program.hasTextureSize(5,1),...this.program.doesNotRecycleTextures()}).declare("createKernel7x1",Object(A.createKernel1D)(7),{...this.program.hasTextureSize(7,1),...this.program.doesNotRecycleTextures()}).declare("createKernel9x1",Object(A.createKernel1D)(9),{...this.program.hasTextureSize(9,1),...this.program.doesNotRecycleTextures()}).declare("createKernel11x1",Object(A.createKernel1D)(11),{...this.program.hasTextureSize(11,1),...this.program.doesNotRecycleTextures()}).declare("_gauss3x",Object(A.convX)([.25,.5,.25])).declare("_gauss3y",Object(A.convY)([.25,.5,.25])).declare("_gauss5x",Object(A.convX)([.05,.25,.4,.25,.05])).declare("_gauss5y",Object(A.convY)([.05,.25,.4,.25,.05])).declare("_gauss7x",Object(A.convX)(n.a.gaussianKernel(P(7),7))).declare("_gauss7y",Object(A.convY)(n.a.gaussianKernel(P(7),7))).declare("_gauss9x",Object(A.convX)(n.a.gaussianKernel(P(9),9))).declare("_gauss9y",Object(A.convY)(n.a.gaussianKernel(P(9),9))).declare("_gauss11x",Object(A.convX)(n.a.gaussianKernel(P(11),11))).declare("_gauss11y",Object(A.convY)(n.a.gaussianKernel(P(11),11))).declare("_box3x",Object(A.convX)([1,1,1],1/3)).declare("_box3y",Object(A.convY)([1,1,1],1/3)).declare("_box5x",Object(A.convX)([1,1,1,1,1],.2)).declare("_box5y",Object(A.convY)([1,1,1,1,1],.2)).declare("_box7x",Object(A.convX)([1,1,1,1,1,1,1],1/7)).declare("_box7y",Object(A.convY)([1,1,1,1,1,1,1],1/7)).declare("_box9x",Object(A.convX)([1,1,1,1,1,1,1,1,1],1/9)).declare("_box9y",Object(A.convY)([1,1,1,1,1,1,1,1,1],1/9)).declare("_box11x",Object(A.convX)([1,1,1,1,1,1,1,1,1,1,1],1/11)).declare("_box11y",Object(A.convY)([1,1,1,1,1,1,1,1,1,1,1],1/11)).declare("_dog16_1x",Object(A.convX)([.011725,.038976,.055137,-.037649,-.136377,-.037649,.055137,.038976,.011725])).declare("_dog16_1y",Object(A.convY)([.011725,.038976,.055137,-.037649,-.136377,-.037649,.055137,.038976,.011725]))}}const R=Object(u.b)("keypoints/fast9lg.glsl").withArguments("image","threshold"),I=Object(u.b)("keypoints/fast7.glsl").withArguments("image","threshold"),k=Object(u.b)("keypoints/fast5.glsl").withArguments("image","threshold"),D=Object(u.b)("keypoints/fast-score16.glsl").withArguments("image","threshold"),C=Object(u.b)("keypoints/fast-score12.glsl").withArguments("image","threshold"),z=Object(u.b)("keypoints/fast-score8.glsl").withArguments("image","threshold"),N=Object(u.b)("keypoints/multiscale-fast.glsl").withArguments("pyramid","threshold","numberOfOctaves"),F=Object(u.b)("keypoints/multiscale-fast.glsl").withArguments("pyramid","threshold","numberOfOctaves").withDefines({USE_HARRIS_SCORE:1}),B=Object(u.b)("keypoints/multiscale-harris.glsl").withArguments("pyramid","windowSize","numberOfOctaves","sobelDerivatives"),j=Object(u.b)("keypoints/harris-cutoff.glsl").withArguments("corners","maxScore","quality"),K=Object(u.b)("keypoints/brisk.glsl").withArguments("image","layerA","layerB","scaleA","scaleB","lgM","h"),X=Object(u.b)("keypoints/orb-descriptor.glsl").withArguments("pyramid","encodedCorners","encoderLength"),U=Object(u.b)("keypoints/nonmax-suppression.glsl").withArguments("image"),G=Object(u.b)("keypoints/multiscale-suppression.glsl").withArguments("image"),q=Object(u.b)("keypoints/samescale-suppression.glsl").withArguments("image"),W=Object(u.b)("filters/multiscale-sobel.glsl").withArguments("pyramid","lod"),Y=Object(u.b)("keypoints/orientation-via-centroid.glsl").withArguments("pyramid","encodedKeypoints","patchRadius","descriptorSize","encoderLength");class $ extends h{constructor(e,t,i){super(e,t,i),this.compose("fast9","_fast9","_fastScore16").declare("_fast9",R).declare("_fastScore16",D).compose("fast7","_fast7","_fastScore12").declare("_fast7",I).declare("_fastScore12",C).compose("fast5","_fast5","_fastScore8").declare("_fast5",k).declare("_fastScore8",z).declare("multiscaleFast",N).declare("multiscaleFastWithHarris",F).declare("brisk",K).declare("multiscaleHarris",B).declare("harrisCutoff",j).declare("_orb",X).declare("nonmaxSuppression",U).declare("multiscaleSuppression",G).declare("samescaleSuppression",q).declare("multiscaleSobel",W,{...this.program.doesNotRecycleTextures()}).declare("_orientationViaCentroid",Y)}orb(e,t,i){return this._orb.resize(i,i),this._orb(e,t,i)}orientationViaCentroid(e,t,i,n,r){return this._orientationViaCentroid.resize(r,r),this._orientationViaCentroid(e,t,i,n,r)}}class H{constructor(){}get data(){return null}get size(){return 0}}class V extends H{constructor(e){super(),this._data=e}get data(){return this._data}get size(){return this._data.length}}const Z=new class extends H{constructor(){super()}get data(){return null}};class J{constructor(e,t,i=0,n=0,r=0,s=null){this._x=+e,this._y=+t,this._lod=+i,this._rotation=+n,this._score=+r,this._scale=Math.pow(2,+i),this._descriptor=null===s?Z:s}toString(){return`(${this._x},${this._y})`}get x(){return this._x}get y(){return this._y}get lod(){return this._lod}get scale(){return this._scale}get rotation(){return this._rotation}get score(){return this._score}get descriptor(){return this._descriptor}}class Q{constructor(e=32,t=5){if(this._bucketSize=1<<Math.ceil(Math.log2(e)),this._windowSize=t+(1-t%2),e<this._windowSize)throw new r.f("Invalid bucketSize of "+e);this._head=this._bucketSize-1,this._rawData=new Float32Array(this._bucketSize).fill(0),this._smoothedData=new Float32Array(this._bucketSize).fill(0),this._average=0,this._isSmooth=!0}put(e){this._head=this._head+1&this._bucketSize-1,this._rawData[this._head]=e,this._isSmooth=!1}get size(){return this._bucketSize}get average(){return this._isSmooth||this._smooth(),this._average}fill(e){return this._rawData.fill(e),this._smoothedData.fill(e),this._average=e,this._isSmooth=!0,this._head=this._bucketSize-1,this}_smooth(){this._average=0;for(let e=0;e<this._bucketSize;e++)this._smoothedData[e]=this._median(this._window(e)),this._average+=this._smoothedData[e];this._average/=this._bucketSize,this._isSmooth=!0}_window(e){const t=this._rawData,i=this._win||(this._win=new Float32Array(this._windowSize)),n=t.length,r=i.length>>1,s=this._head,o=s+1&n-1;for(let a=0,c=-r;c<=r;c++){let r=e+c;e<=s?r>s&&(r=s+(s-r)):r<o&&(r=o+(o-r)),r<0?r+=n:r>=n&&(r-=n),i[a++]=t[r]}return i}_median(e){switch(e.length){case 1:return e[0];case 3:return e[0]>e[1]&&([e[0],e[1]]=[e[1],e[0]]),e[1]>e[2]&&([e[1],e[2]]=[e[2],e[1]]),e[0]>e[1]&&([e[0],e[1]]=[e[1],e[0]]),e[1];case 5:return e[0]>e[1]&&([e[0],e[1]]=[e[1],e[0]]),e[3]>e[4]&&([e[3],e[4]]=[e[4],e[3]]),e[0]>e[3]&&([e[0],e[3]]=[e[3],e[0]]),e[1]>e[4]&&([e[1],e[4]]=[e[4],e[1]]),e[1]>e[2]&&([e[1],e[2]]=[e[2],e[1]]),e[2]>e[3]&&([e[2],e[3]]=[e[3],e[2]]),e[1]>e[2]&&([e[1],e[2]]=[e[2],e[1]]),e[2];case 7:return e[0]>e[5]&&([e[0],e[5]]=[e[5],e[0]]),e[0]>e[3]&&([e[0],e[3]]=[e[3],e[0]]),e[1]>e[6]&&([e[1],e[6]]=[e[6],e[1]]),e[2]>e[4]&&([e[2],e[4]]=[e[4],e[2]]),e[0]>e[1]&&([e[0],e[1]]=[e[1],e[0]]),e[3]>e[5]&&([e[3],e[5]]=[e[5],e[3]]),e[2]>e[6]&&([e[2],e[6]]=[e[6],e[2]]),e[2]>e[3]&&([e[2],e[3]]=[e[3],e[2]]),e[3]>e[6]&&([e[3],e[6]]=[e[6],e[3]]),e[4]>e[5]&&([e[4],e[5]]=[e[5],e[4]]),e[1]>e[4]&&([e[1],e[4]]=[e[4],e[1]]),e[1]>e[3]&&([e[1],e[3]]=[e[3],e[1]]),e[3]>e[4]&&([e[3],e[4]]=[e[4],e[3]]),e[3];default:return e.sort((e,t)=>e-t),(e[e.length-1>>1]+e[e.length>>1])/2}}}class ee{constructor(e,t,i){if(this.constructor===ee)throw new r.a;if(t>=i)throw new r.f(`Invalid boundaries [${t},${i}] given to the Tuner`);e=Math.max(t,Math.min(e,i)),this._state=e,this._prevState=e,this._prevPrevState=e,this._initialState=e,this._minState=t,this._maxState=i,this._bucket=new Array(i-t+1).fill(null).map(e=>new Q(this._bucketSetup().size,this._bucketSetup().window)),this._iterations=0,this._epoch=0}currentValue(){return this._state}feedObservation(e){const t=this._bucketOf(this._state);if(t.put(+e),++this._iterations>=t.size){0==this._epoch&&(this._bucket.forEach(e=>e.fill(t.average)),isFinite(this._costOfBestState)||(this._costOfBestState=t.average));const e=e=>Math.max(this._minState,Math.min(0|e,this._maxState)),i=this._prevState,n=this._state;this._state=e(this._nextState()),this._prevState=n,this._prevPrevState=i,this._iterations=0,this._epoch++}}reset(){this._state=this._initialState,this._prevState=this._initialState,this._prevPrevState=this._initialState,this._iterations=0,this._epoch=0}finished(){return!1}_bucketOf(e){return e=Math.max(this._minState,Math.min(0|e,this._maxState)),this._bucket[e-this._minState]}_bucketSetup(){return{size:4,window:3}}_nextState(){throw new r.a}info(){const e=this._bucketOf(this._state),t=this._bucketOf(this._prevState);return{now:this._state,avg:e.average,itr:[this._iterations,this._epoch],bkt:e._smoothedData,cur:new Array(e.size).fill(0).map((t,i)=>i==e._head?1:0),prv:[this._prevState,t.average],fim:this.finished()}}}class te extends ee{constructor(e,t,i,n=.5,r=8,s=100,o=null){super(e,t,i),this._bestState=this._initialState,this._costOfBestState=1/0,this._initialTemperature=Math.max(0,s),this._temperature=this._initialTemperature,this._numIterations=0,this._maxIterationsPerTemperature=Math.max(1,r),this._alpha=Math.max(0,Math.min(n,1)),o||(o=e=>this._minState+Math.floor(Math.random()*(this._maxState-this._minState+1))),this._pickNeighbor=o}reset(){this._temperature=this._initialTemperature,this._numIterations=0}finished(){return this._temperature<=1e-5}_nextState(){if(this.finished())return this._bestState;const e=e=>this._bucketOf(e).average;let t=this._state,i=0|this._pickNeighbor(this._state,e(this._state));return i=Math.max(this._minState,Math.min(i,this._maxState)),(e(i)<e(this._state)||Math.random()<Math.exp((e(this._state)-e(i))/this._temperature))&&(t=i),e(t)<this._costOfBestState&&(this._bestState=t,this._costOfBestState=e(t)),++this._numIterations>=this._maxIterationsPerTemperature&&(this._temperature*=this._alpha,this._numIterations=0),t}info(){return{best:[this._bestState,this._costOfBestState],state:[this._state,this._bucketOf(this._state).average],iterations:[this._numIterations,this._maxIterationsPerTemperature],temperature:this._temperature,alpha:this._alpha,cool:this.finished()}}}var ie=i(5);const ne=Object(u.b)("encoders/encode-keypoint-offsets.glsl").withArguments("image","imageSize","maxIterations"),re=Object(u.b)("encoders/encode-keypoints.glsl").withArguments("image","imageSize","encoderLength","descriptorSize"),se=Object(u.b)("utils/identity.glsl").withArguments("image"),oe=Object(u.b)("encoders/upload-keypoints.glsl").withArguments("keypointCount","encoderLength","descriptorSize").withDefines({KEYPOINT_BUFFER_LENGTH:1024});class ae extends h{constructor(e,t,i){super(e,t,i),this.declare("_encodeKeypointOffsets",ne).declare("_encodeKeypoints",re,{...this.program.hasTextureSize(16,16)}).declare("_downloadKeypoints",se,{...this.program.hasTextureSize(16,16)}).declare("_uploadKeypoints",oe,{...this.program.hasTextureSize(16,16)});this._tuner=new te(48,32,48,.2,8,60,e=>Math.round(n.a.gaussianNoise(e,64))%256),this._encoderLength=16,this._spawnedAt=performance.now(),this._uploadBuffer=null}get encoderLength(){return this._encoderLength}optimize(e,t){const i=this._minimumEncoderLength(e,t),n=this._encoderLength;return this._encoderLength=i,i-n!=0}reserveSpace(e,t){return this._minimumEncoderLength(e,t)>this._encoderLength&&this.optimize(e,t)}encodeKeypoints(e,t){const i=this._encoderLength,n=[this._width,this._height],r=this._tuner.currentValue(),s=this._encodeKeypointOffsets(e,n,r);return this._encodeKeypoints.resize(this._encoderLength,this._encoderLength),this._encodeKeypoints.clear(0,0,0,0),this._encodeKeypoints(s,n,i,t)}decodeKeypoints(e,t,i={}){const n=2+t/4;let r,s,o,a,c,l,d,f=0;const p=[];null!=i.userData&&(i.userData.length=0),null!=i.discard&&(i.discard.length=0);const h=this._encoderLength,u=h*h*n*4,m=Math.min(e.length,u);for(let h=0;h<m&&(r=e[h+1]<<8|e[h],s=e[h+3]<<8|e[h+2],!(r>=65535&&s>=65535));h+=4*n){if(r+s==0&&e[h+6]+e[h+5]==0)continue;r/=ie.b,s/=ie.b;const n=r>ie.d||s>ie.d||r<0||s<0;if(null!=i.discard&&i.discard.push(n),null!=i.discardCount&&n&&(i.discardCount[0]=++f),l=e[h+4]<255,o=l?-ie.c+(ie.c+ie.e)*e[h+4]/255:0,d=l,a=d?(2*e[h+5]/255-1)*Math.PI:0,c=e[h+6]/255,null!=i.userData){const t=e[h+7]/255;i.userData.push(t)}if(t>0){const i=new Uint8Array(e.slice(h+8,h+8+t)),n=new V(i);p.push(new J(r,s,o,a,c,n))}else p.push(new J(r,s,o,a,c))}return 0==p.length&&this._tuner.finished()&&this._tuner.reset(),p}async downloadEncodedKeypoints(e,t=!0,i=!0){try{this._downloadKeypoints.resize(this._encoderLength,this._encoderLength),this._downloadKeypoints(e);let n,r=performance.now();return n=t?await this._downloadKeypoints.readPixelsAsync(0,0,-1,-1,i):this._downloadKeypoints.readPixelsSync(),r=performance.now()-r,performance.now()>=this._spawnedAt+2e3&&this._tuner.feedObservation(r),n}catch(e){throw new r.g("Can't download encoded keypoint texture",e)}}uploadKeypoints(e,t){if(null===this._uploadBuffer){const e=4*Float32Array.BYTES_PER_ELEMENT,t=new ArrayBuffer(1024*e);this._uploadBuffer=new Float32Array(t)}const i=e.length;for(let t=0;t<i;t++){const i=e[t],n=4*t;this._uploadBuffer[n]=+i.x||0,this._uploadBuffer[n+1]=+i.y||0,this._uploadBuffer[n+2]=+i.lod||0,this._uploadBuffer[n+3]=+i.score||0}return this.reserveSpace(i,t),this._uploadKeypoints.resize(this._encoderLength,this._encoderLength),this._uploadKeypoints.setUBO("KeypointBuffer",this._uploadBuffer),this._uploadKeypoints(i,this._encoderLength,t)}_minimumEncoderLength(e,t){const i=Math.max(0,Math.min(Math.ceil(e),5e3)),n=Math.ceil(2+t/4),r=Math.ceil(Math.sqrt(i*n));return Math.max(1,Math.min(r,300))}}const ce=Object(u.b)("pyramids/upsample2.glsl").withArguments("image"),le=Object(u.b)("pyramids/downsample2.glsl").withArguments("image"),de=Object(u.b)("pyramids/upsample3.glsl").withArguments("image"),fe=Object(u.b)("pyramids/downsample3.glsl").withArguments("image"),pe=Object(u.b)("utils/flip-y.glsl").withArguments("image");class he extends h{constructor(e,t,i){super(e,t,i),this.compose("reduce","_smoothX","_smoothY","_downsample2").compose("expand","_upsample2","_smoothX2","_smoothY2").compose("intraReduce","_upsample2","_smoothX2","_smoothY2","_downsample3/2").compose("intraExpand","_upsample3","_smoothX3","_smoothY3","_downsample2/3").declare("output1",pe,{...this.program.hasTextureSize(this._width,this._height),...this.program.displaysGraphics()}).declare("output2",pe,{...this.program.hasTextureSize(2*this._width,2*this._height),...this.program.displaysGraphics()}).declare("output3",pe,{...this.program.hasTextureSize(3*this._width,3*this._height),...this.program.displaysGraphics()}).declare("_smoothX",Object(A.convX)([.05,.25,.4,.25,.05])).declare("_smoothY",Object(A.convY)([.05,.25,.4,.25,.05])).declare("_smoothX2",Object(A.convX)([.1,.5,.8,.5,.1]),this.program.hasTextureSize(2*this._width,2*this._height)).declare("_smoothY2",Object(A.convY)([.1,.5,.8,.5,.1],.5),this.program.hasTextureSize(2*this._width,2*this._height)).declare("_smoothX3",Object(A.convX)([.2,.8,1,.8,.2]),this.program.hasTextureSize(3*this._width,3*this._height)).declare("_smoothY3",Object(A.convY)([.2,.8,1,.8,.2],1/3),this.program.hasTextureSize(3*this._width,3*this._height)).declare("_upsample2",ce,this.program.hasTextureSize(2*this._width,2*this._height)).declare("_downsample2",le,this.program.hasTextureSize((1+this._width)/2,(1+this._height)/2)).declare("_upsample3",de,this.program.hasTextureSize(3*this._width,3*this._height)).declare("_downsample3",fe,this.program.hasTextureSize((2+this._width)/3,(2+this._height)/3)).declare("_downsample2/3",le,this.program.hasTextureSize(3*this._width/2,3*this._height/2)).declare("_downsample3/2",fe,this.program.hasTextureSize(2*this._width/3,2*this._height/3))}}const ue=Object(u.b)("enhancements/normalize-image.glsl").withArguments("minmax2d","minValue","maxValue").withDefines({GREYSCALE:1}),me=Object(u.b)("enhancements/normalize-image.glsl").withArguments("minmax2dRGB","minValue","maxValue"),ve=Object(u.b)("enhancements/nightvision.glsl").withArguments("image","illuminationMap","gain","offset","decay"),ge=Object(u.b)("enhancements/nightvision.glsl").withArguments("image","illuminationMap","gain","offset","decay").withDefines({GREYSCALE:1});class _e extends h{constructor(e,t,i){super(e,t,i),this.declare("_normalizeGreyscaleImage",ue).declare("_normalizeColoredImage",me).declare("_nightvision",ve).declare("_nightvisionGreyscale",ge).compose("_illuminationMapLo","_illuminationMapLoX","_illuminationMapLoY").declare("_illuminationMapLoX",Object(A.convX)(n.a.gaussianKernel(80,31))).declare("_illuminationMapLoY",Object(A.convY)(n.a.gaussianKernel(80,31))).compose("_illuminationMap","_illuminationMapX","_illuminationMapY").declare("_illuminationMapX",Object(A.convX)(n.a.gaussianKernel(80,63))).declare("_illuminationMapY",Object(A.convY)(n.a.gaussianKernel(80,63))).compose("_illuminationMapHi","_illuminationMapHiX","_illuminationMapHiY").declare("_illuminationMapHiX",Object(A.convX)(n.a.gaussianKernel(80,255))).declare("_illuminationMapHiY",Object(A.convY)(n.a.gaussianKernel(80,255)))}normalizeGreyscaleImage(e,t=0,i=255){const n=this._gpu.programs.utils._scanMinMax(e,m.d.GREEN);return this._normalizeGreyscaleImage(n,Math.min(t,i),Math.max(t,i))}normalizeColoredImage(e,t=0,i=255){const n=this._gpu,r=new Array(3);r[0]=n.programs.utils.clone(n.programs.utils._scanMinMax(e,m.d.RED)),r[1]=n.programs.utils.clone(n.programs.utils._scanMinMax(e,m.d.GREEN)),r[2]=n.programs.utils._scanMinMax(e,m.d.BLUE);const s=this._normalizeColoredImage(r,Math.min(t,i),Math.max(t,i));return r[1].release(),r[0].release(),s}nightvision(e,t=.5,i=.5,n=0,s="medium",o=!1){let a=null;if("medium"==s)a=this._illuminationMap(e);else if("high"==s)a=this._illuminationMapHi(e);else{if("low"!=s)throw new r.f(`Invalid quality level for nightvision: "${s}"`);a=this._illuminationMapLo(e)}return(o?this._nightvisionGreyscale:this._nightvision)(e,a,t,i,n)}}const xe=Object(u.b)("trackers/lk.glsl").withArguments("nextPyramid","prevPyramid","prevKeypoints","windowSize","depth","firstKeypointIndex","lastKeypointIndex","descriptorSize","encoderLength").withDefines({MAX_WINDOW_SIZE:21}),Se=Object(u.b)("trackers/lk-discard.glsl").withArguments("pyramid","encodedKeypoints","windowSize","discardThreshold","firstKeypointIndex","lastKeypointIndex","descriptorSize","encoderLength").withDefines({MAX_WINDOW_SIZE:21}),ye=Object(u.b)("trackers/lk.glsl").withArguments("nextPyramid","prevPyramid","prevKeypoints","windowSize","depth","firstKeypointIndex","lastKeypointIndex","descriptorSize","encoderLength").withDefines({MAX_WINDOW_SIZE:15}),be=Object(u.b)("trackers/lk-discard.glsl").withArguments("pyramid","encodedKeypoints","windowSize","discardThreshold","firstKeypointIndex","lastKeypointIndex","descriptorSize","encoderLength").withDefines({MAX_WINDOW_SIZE:15}),Oe=Object(u.b)("trackers/lk.glsl").withArguments("nextPyramid","prevPyramid","prevKeypoints","windowSize","depth","firstKeypointIndex","lastKeypointIndex","descriptorSize","encoderLength").withDefines({MAX_WINDOW_SIZE:11}),we=Object(u.b)("trackers/lk-discard.glsl").withArguments("pyramid","encodedKeypoints","windowSize","discardThreshold","firstKeypointIndex","lastKeypointIndex","descriptorSize","encoderLength").withDefines({MAX_WINDOW_SIZE:11}),Ae=Object(u.b)("trackers/lk.glsl").withArguments("nextPyramid","prevPyramid","prevKeypoints","windowSize","depth","firstKeypointIndex","lastKeypointIndex","descriptorSize","encoderLength").withDefines({MAX_WINDOW_SIZE:7}),Ee=Object(u.b)("trackers/lk-discard.glsl").withArguments("pyramid","encodedKeypoints","windowSize","discardThreshold","firstKeypointIndex","lastKeypointIndex","descriptorSize","encoderLength").withDefines({MAX_WINDOW_SIZE:7});class Me extends h{constructor(e,t,i){super(e,t,i),this.declare("_lk",xe).declare("_lkSmall",ye).declare("_lkSmaller",Oe).declare("_lkSmallest",Ae).declare("_lkDiscard",Se).declare("_lkDiscardSmall",be).declare("_lkDiscardSmaller",we).declare("_lkDiscardSmallest",Ee)}lk(e,t,i,n,r,s,o,a){const c=ie.e;r=Math.max(1,Math.min(0|r,c)),n+=(n+1)%2;let l="_lk",d="_lkDiscard";(n=Math.max(5,Math.min(n,21)))<=7?(l="_lkSmallest",d="_lkDiscardSmallest"):n<=11?(l="_lkSmaller",d="_lkDiscardSmaller"):n<=15&&(l="_lkSmall",d="_lkDiscardSmall"),this[l].resize(a,a),this[d].resize(a,a);const f=a*a/(2+o/4),p=Math.ceil(Math.max(1,f)/100);let h=i;for(let i=0;i<p;i++){const c=100*i,f=c+100-1;h=this[l](e,t,h,n,r,c,f,o,a),h=this[d](e,h,n,s,c,f,o,a)}return h}}class Te{constructor(e,t,i){this._gpu=e,this._width=t,this._height=i,this._utils=null,this._colors=null,this._filters=null,this._keypoints=null,this._encoders=null,this._descriptors=null,this._pyramids=null,this._enhancements=null,this._trackers=null}get width(){return this._width}get height(){return this._height}get utils(){return this._utils||(this._utils=new b(this._gpu,this._width,this._height))}get colors(){return this._colors||(this._colors=new w(this._gpu,this._width,this._height))}get filters(){return this._filters||(this._filters=new L(this._gpu,this._width,this._height))}get keypoints(){return this._keypoints||(this._keypoints=new $(this._gpu,this._width,this._height))}get encoders(){return this._encoders||(this._encoders=new ae(this._gpu,this._width,this._height))}get trackers(){return this._trackers||(this._trackers=new Me(this._gpu,this._width,this._height))}get pyramids(){return this._pyramids||(this._pyramids=new he(this._gpu,this._width,this._height))}get enhancements(){return this._enhancements||(this._enhancements=new _e(this._gpu,this._width,this._height))}}class Pe{constructor(e,t){this._gl=null,this._canvas=null,this._width=0,this._height=0,this._programs=null,this._inputTexture=null,this._inputTextureIndex=0,this._omitGLContextWarning=!1,function(){if("undefined"==typeof WebGL2RenderingContext)throw new r.i("WebGL2 is required by this application, but it's not available in your browser. Please use a different browser.")}(),this._width=Math.max(1,0|e),this._height=Math.max(1,0|t),(this._width>ie.d||this._height>ie.d)&&(n.a.warning(`Maximum texture size exceeded (using ${this._width} x ${this._height}).`),this._width=Math.min(this._width,ie.d),this._height=Math.min(this._height,ie.d)),this._setupWebGL()}get gl(){return this._gl}get canvas(){return this._canvas}get programs(){return this._programs}upload(e,t=-1,i=-1){const s=this._gl;if(s.isContextLost())return n.a.warning("Can't upload texture without a WebGL context"),this._inputTexture=null;if(t<0&&(t=s.canvas.width),i<0&&(i=s.canvas.height),0==t||0==i)throw new r.f("Can't upload an image of area 0");if(null===this._inputTexture)s.canvas.width=Math.max(s.canvas.width,t),s.canvas.height=Math.max(s.canvas.height,i),this._inputTexture=Array(4).fill(null).map(e=>new a(s,s.canvas.width,s.canvas.height));else if(t>s.canvas.width||i>s.canvas.height)return n.a.log(`Resizing input texture to ${t} x ${i}`),this._inputTexture.forEach(e=>e.release()),this._inputTexture=null,this.upload(e,t,i);if("HTMLVideoElement"==e.constructor.name&&e.readyState<2){if(null!=this._inputTexture[this._inputTextureIndex])return this._inputTexture[this._inputTextureIndex];n.a.warning("Trying to process a video that isn't ready yet")}this._inputTextureIndex=(1+this._inputTextureIndex)%4;const o=this._inputTexture[this._inputTextureIndex];return o.upload(e),o}loseAndRestoreWebGLContext(e=1){const t=this._gl;if(t.isContextLost())return Promise.reject("Context already lost");const i=t.getExtension("WEBGL_lose_context");if(i)return i.loseContext(),new Promise(t=>{isFinite(e)?setTimeout(()=>{i.restoreContext(),setTimeout(()=>t(),0)},1e3*Math.max(e,0)):t()});throw new r.i("WEBGL_lose_context is unavailable")}loseWebGLContext(){return this._omitGLContextWarning=!0,this.loseAndRestoreWebGLContext(1/0)}_setupWebGL(){const e=this._width,t=this._height;this._programs=null,this._inputTexture=null,this._inputTextureIndex=0,this._omitGLContextWarning=!1,void 0!==this._canvas&&delete this._canvas,this._canvas=function(e,t){if("function"==typeof importScripts&&"undefined"!=typeof WorkerGlobalScope){if("function"!=typeof OffscreenCanvas)throw new r.i("OffscreenCanvas is not available in your browser. Please upgrade.");return new OffscreenCanvas(e,t)}return n.a.createCanvas(e,t)}(e,t),this._canvas.addEventListener("webglcontextlost",e=>{this._omitGLContextWarning||n.a.warning("Lost WebGL context"),e.preventDefault()},!1),this._canvas.addEventListener("webglcontextrestored",e=>{this._omitGLContextWarning||n.a.warning("Restoring WebGL context..."),this._setupWebGL()},!1),this._gl=function(e){const t=e.getContext("webgl2",{premultipliedAlpha:!1,preserveDrawingBuffer:!1,alpha:!0,antialias:!1,depth:!1,stencil:!1});if(!t)throw new r.i("Can't create WebGL2 context. Try in a different browser.");return t}(this._canvas),this._programs=new Te(this,e,t)}}class Le{constructor(){throw new r.a("Namespaces can't be instantiated")}}const Re=Object.freeze({FEATURE_DETECTOR_RESET_CAPACITY:1,F32:0,F32C1:0,F32C2:1,F32C3:2,F32C4:3,U8:4,U8C1:4,U8C2:5,U8C3:6,U8C4:7});class Ie{constructor(){this._subscribers=[]}subscribe(e){this._subscribers.indexOf(e)<0&&this._subscribers.push(e)}unsubscribe(e){this._subscribers=this._subscribers.filter(t=>t!==e)}_notify(e){for(const t of this._subscribers)t(e)}}class ke{constructor(){this._gain=.85,this._state=600,this._prevState=this._state}estimate(e){const t=Math.max(0,this._state+(this._state-this._prevState)),i=t+this._gain*(e-t);return this._gain=Math.min(.85,this._gain+.3),this._prevState=this._state,this._state=i,Math.round(this._state)}reset(){this._gain=0,this._state=this._prevState=600}get maxGrowth(){return 1.5}}class De extends Ie{constructor(){super(),this._useBufferedDownloads=!1,this._estimator=new ke}download(e,t,i,n=-1,s=!0,o){return e.programs.encoders.downloadEncodedKeypoints(t,s,this._useBufferedDownloads).then(t=>{const r=Object.assign({discardCount:[0]},o),a=e.programs.encoders.decodeKeypoints(t,i,r),c=this._estimator.estimate(a.length-r.discardCount[0]);if(s){const t=Math.max(c,32),n=this._estimator.maxGrowth*t;e.programs.encoders.optimize(n,i)}else{const t=Math.max(c,32);e.programs.encoders.reserveSpace(t,i)}return n=Number(n),Number.isFinite(n)&&n>=0&&(a.sort(this._compareKeypoints),a.splice(n,a.length-n)),this._notify(a),a}).catch(e=>{throw new r.g("Can't download keypoints",e)})}reset(e,t){this._estimator.reset(),e.programs.encoders.reserveSpace(600,t)}enableBufferedDownloads(){this._useBufferedDownloads=!0}disableBufferedDownloads(){this._useBufferedDownloads=!1}usingBufferedDownloads(){return this._useBufferedDownloads}_compareKeypoints(e,t){return+t.score-+e.score}}class Ce extends ee{constructor(e,t,i=.1,r=.05){super(Math.round(n.a.gaussianNoise((e+t)/2,5)),e,t),this._tolerance=Math.max(0,i),this._bestState=this._initialState,this._expected=null,this._learningRate=Math.max(0,r),this._lastObservation=0}reset(){super.reset(),this._expected=null}feedObservation(e,t){const i=+e,n=+t;n!==this._expected&&this.reset(),this._expected=n;const r=Math.abs(i)>2*Math.abs(this._lastObservation);if(this._lastObservation=i,r)return;const s=(i-n)*(i-n)/(n*n);super.feedObservation(s)}finished(){return(e=>Math.sqrt(this._bucketOf(e).average)*Math.abs(this._expected))(this._bestState)<=this._tolerance*this._expected}get tolerance(){return this._tolerance}set tolerance(e){this._tolerance=Math.max(0,e)}_nextState(){if(this.finished())return this._bestState;const e=e=>Math.sqrt(this._bucketOf(e).average)*Math.abs(this._expected);e(this._state)<e(this._bestState)&&(this._bestState=this._state);const t=Math.abs(this._maxState),i=this._learningRate*(e=>Math.sqrt(this._bucketOf(e).average)*t)(this._state),r=e=>Number(e>=0)-Number(e<0),s=e(this._state)-e(this._prevState),o=r(s)*r(0!=s?-(this._state-this._prevState):1)*r(Math.random()-.15),a=n.a.gaussianNoise(1,.1);let c=Math.round(this._state+o*a*i);return(c>this._maxState||c<this._minState)&&(c=this._bestState),c}info(){return{now:[this._state,this._prevState],bkt:this._bucketOf(this._state)._rawData,cur:this._bucketOf(this._state)._head,err:[this._bucketOf(this._state).average,this._bucketOf(this._prevState).average],sqt:Math.sqrt(this._bucketOf(this._state).average),done:this.finished()}}}class ze extends Ie{constructor(e){super(),this._sensitivity=0,this._expected=0,this._tolerance=.1,this._tuner=null,this._downloader=e,this._onDownloadKeypoints=this._onDownloadKeypoints.bind(this),this.enable()}get sensitivity(){return this._sensitivity}get expected(){return this._expected}set expected(e){this._expected=Math.max(0,0|e)}get tolerance(){return this._tolerance}set tolerance(e){this._tolerance=Math.max(0,+e)}enable(){this._downloader.subscribe(this._onDownloadKeypoints)}disable(){this._downloader.unsubscribe(this._onDownloadKeypoints)}_onDownloadKeypoints(e){null==this._tuner&&(this._tuner=new Ce(0,1200)),this._tuner.tolerance=this._tolerance,this._tuner.feedObservation(e.length,this._expected);const t=this._tuner.currentValue();this._sensitivity=Math.max(0,Math.min(.001*t,1)),this._notify(this._sensitivity)}}class Ne{constructor(){this._downloader=new De}download(e,t){throw new r.a}resetDownloader(e,t){if(void 0===t)throw new r.f;this._downloader.reset(e,t),this._downloader.usingBufferedDownloads()&&n.a.warning("The feature downloader has been reset, but buffered downloads are enabled and cause a 1-frame delay")}}class Fe extends Ne{constructor(){super(),this._downloader.enableBufferedDownloads()}get descriptorSize(){throw new r.a}detect(e,t){throw new r.a}describe(e,t,i){return i}download(e,t,i,n=!0){const r=this._downloader.download(e,t,this.descriptorSize,i,n);return this._downloader.usingBufferedDownloads()||this._downloader.enableBufferedDownloads(),r}resetDownloader(e){this._downloader.disableBufferedDownloads(),super.resetDownloader(e,this.descriptorSize)}}class Be extends Fe{get descriptorSize(){return 0}detect(e,t,i=9,n=10){const s=n/255,o=this.descriptorSize;let a=null;if(9==i)a=e.programs.keypoints.fast9(t,s);else if(7==i)a=e.programs.keypoints.fast7(t,s);else{if(5!=i)throw new r.i;a=e.programs.keypoints.fast5(t,s)}return a=e.programs.keypoints.nonmaxSuppression(a),e.programs.encoders.encodeKeypoints(a,o)}}class je extends Be{detect(e,t,i=10,n=3,r=!1){const s=i/255,o=2*n-1,a=this.descriptorSize,c=t.generateMipmap();let l=null;return l=r?e.programs.keypoints.multiscaleFastWithHarris(c,s,o):e.programs.keypoints.multiscaleFast(c,s,o),l=e.programs.keypoints.samescaleSuppression(l),l=e.programs.keypoints.multiscaleSuppression(l),e.programs.encoders.encodeKeypoints(l,a)}describe(e,t,i){const n=this.descriptorSize,r=t.generateMipmap(),s=e.programs.encoders.encoderLength;return e.programs.keypoints.orientationViaCentroid(r,i,7,n,s)}}const Ke=2*ie.e-1;class Xe extends Fe{get descriptorSize(){return 0}detect(e,t,i=.1){const n=this.descriptorSize,r=e.programs.keypoints.multiscaleSobel(t,0),s=Array(Ke).fill(r),o=e.programs.keypoints.multiscaleHarris(t,3,1,s);r.release();const a=e.programs.utils.scanMax(o,m.d.RED),c=e.programs.keypoints.harrisCutoff(o,a,i),l=e.programs.keypoints.nonmaxSuppression(c);return e.programs.encoders.encodeKeypoints(l,n)}}class Ue extends Xe{detect(e,t,i=.1,n=3){const r=this.descriptorSize,s=2*n-1,o=t.generateMipmap(),a=Array(Ke);for(let t=0;t<s;t++)a[t]=e.programs.keypoints.multiscaleSobel(o,.5*t);for(let e=s;e<a.length;e++)a[e]=a[e-1];const c=e.programs.keypoints.multiscaleHarris(o,3,s,a);for(let e=0;e<s;e++)a[e].release();const l=e.programs.utils.scanMax(c,m.d.RED),d=e.programs.keypoints.harrisCutoff(c,l,i),f=e.programs.keypoints.samescaleSuppression(d),p=e.programs.keypoints.multiscaleSuppression(f);return e.programs.encoders.encodeKeypoints(p,r)}describe(e,t,i){const n=this.descriptorSize,r=t.generateMipmap(),s=e.programs.encoders.encoderLength;return e.programs.keypoints.orientationViaCentroid(r,i,7,n,s)}}class Ge extends Ue{get descriptorSize(){return 32}detect(e,t,i,n){return super.detect(e,t,i,n)}describe(e,t,i){const n=super.describe(e,t,i),r=e.programs.filters.gauss7(t).generateMipmap(),s=e.programs.encoders.encoderLength;return e.programs.keypoints.orb(r,n,s)}}class qe extends Fe{get descriptorSize(){return 64}detect(e,t){throw new r.h}describe(e,t,i){throw new r.h}}class We{constructor(e){this._algorithm=e,this._sensitivity=0,this._max=void 0,this._enhancements={denoise:!0,illumination:!1,nightvision:null},this._automaticSensitivity=null}detect(e,t=0){const i=e._gpu,n="static"==e.options.usage;if(e.isReleased())throw new r.g("Can't detect features: the SpeedyMedia has been released");if(t&Re.FEATURE_DETECTOR_RESET_CAPACITY&&this._algorithm.resetDownloader(i),n){const e=3072;i.programs.encoders.reserveSpace(e,this._algorithm.descriptorSize)}const s=i.upload(e.source),o=this._preprocessTexture(i,s,1==this._enhancements.denoise,e._colorFormat!=m.b.Greyscale),a=this._enhanceTexture(i,o,1==this._enhancements.illumination||this._enhancements.nightvision),c=this._detectFeatures(i,a),l=this._describeFeatures(i,o,c);return this._algorithm.download(i,l,this._max,!n)}get sensitivity(){return this._sensitivity}set sensitivity(e){this._sensitivity=Math.max(0,Math.min(+e,1)),this._onSensitivityChange(this._sensitivity)}get max(){return this._max}set max(e){this._max=void 0!==e?Math.max(0,0|e):void 0}enhance(e){if("object"!=typeof e)throw new r.f("enhancements must be an object");this._enhancements=Object.assign(this._enhancements,e)}expect(e,t=.1){void 0!==e?(null==this._automaticSensitivity&&(this._automaticSensitivity=new ze(this._algorithm._downloader),this._automaticSensitivity.subscribe(e=>this._algorithm.sensitivity=e)),this._automaticSensitivity.expected=e,this._automaticSensitivity.tolerance=t):(null!=this._automaticSensitivity&&this._automaticSensitivity.disable(),this._automaticSensitivity=null)}_preprocessTexture(e,t,i=!0,n=!0){let r=t;return i&&(r=e.programs.filters.gauss5(r)),n&&(r=e.programs.colors.rgb2grey(r)),r}_enhanceTexture(e,t,i=!1){let n=t,r={gain:.9,offset:.5,decay:.85,quality:"low"};return"object"==typeof i&&(r=Object.assign(r,i)),0!=i&&(n=e.programs.enhancements.nightvision(n,r.gain,r.offset,r.decay,r.quality,!0),n=e.programs.filters.gauss3(n)),n}_detectFeatures(e,t){return this._algorithm.detect(e,t)}_describeFeatures(e,t,i){return this._algorithm.describe(e,t,i)}_onSensitivityChange(e){throw new r.a}}class Ye extends We{constructor(e=9,t=null){if(9!=e&&7!=e&&5!=e)throw new r.i("Can't create FAST feature detector with n = "+e);super(t||new Be),this._n=0|e,this._threshold=10}get threshold(){return this._threshold}set threshold(e){this._threshold=Math.max(0,Math.min(0|e,255))}_onSensitivityChange(e){this.threshold=Math.round(255*(1-Math.tanh(2.77*e)))}_detectFeatures(e,t){return this._algorithm.detect(e,t,this._n,this._threshold)}}class $e extends Ye{constructor(e=9){if(9!=e)throw new r.i("Can't create Multiscale FAST feature detector with n = "+e);super(9,new je),this._depth=3,this._useHarrisScore=!1}get depth(){return this._depth}set depth(e){if(e<1||e>ie.e)throw new r.f("Invalid depth: "+e);this._depth=0|e}get useHarrisScore(){return this._useHarrisScore}set useHarrisScore(e){this._useHarrisScore=Boolean(e)}_detectFeatures(e,t){return this._algorithm.detect(e,t,this._threshold,this._depth,this._useHarrisScore)}}class He extends We{constructor(e=null){super(e||new Xe),this._quality=.9}get quality(){return this._quality}set quality(e){this._quality=Math.max(0,Math.min(e,1))}_onSensitivityChange(e){this.quality=1-Math.tanh(2.3*e)}_detectFeatures(e,t){return this._algorithm.detect(e,t,this._quality)}}class Ve extends He{constructor(e=null){super(e||new Ue),this._depth=3}get depth(){return this._depth}set depth(e){if(e<1||e>ie.e)throw new r.f("Invalid depth: "+e);this._depth=0|e}_detectFeatures(e,t){return this._algorithm.detect(e,t,this._quality,this._depth)}}class Ze extends Ve{constructor(){super(new Ge)}}class Je extends We{constructor(){super(new qe),this._depth=4}get depth(){return this._depth}set depth(e){if(e<1||e>ie.e)throw new r.f("Invalid depth: "+e);this._depth=0|e}}class Qe extends Le{static FAST(e=9){return new Ye(e)}static MultiscaleFAST(e=9){return new $e(e)}static Harris(){return new He}static MultiscaleHarris(){return new Ve}static ORB(){return new Ze}static BRISK(){return new Je}}class et{constructor(e,t,i,s={}){if(arguments.length>1)this._source=e,this._width=0|t,this._height=0|i,this._type=function(e){if(e&&e.constructor)switch(e.constructor.name){case"HTMLImageElement":return m.c.Image;case"HTMLVideoElement":return m.c.Video;case"HTMLCanvasElement":return m.c.Canvas;case"ImageBitmap":return m.c.Bitmap}throw new r.f("Can't get media type: invalid media source. "+e)}(this._source),this._colorFormat=m.b.RGB,this._type==m.c.Canvas&&void 0===s.usage&&n.a.warning('Loading a canvas without an explicit usage flag. I will set the usage to "static", resulting in suboptimal performance if the canvas is animated'),this._options=function(e,t){"dynamic"!=(e=Object.assign(t,e)).usage&&"static"!=e.usage&&(n.a.warning(`Can't load media. Unrecognized usage option: "${e.usage}"`),e.usage=t.usage);return Object.freeze(e)}(s,{usage:this._type==m.c.Video?"dynamic":"static"}),this._gpu=new Pe(this._width,this._height);else{if(1!=arguments.length)throw new r.f("Invalid instantiation of SpeedyMedia");{const e=arguments[0];this._source=e._source,this._width=e._width,this._height=e._height,this._type=e._type,this._colorFormat=e._colorFormat,this._options=e._options,this._gpu=e._gpu}}}static load(e,t={}){return function(e,t=3e4){const i=i=>new Promise((s,o)=>{n.a.log(`Loading media ${e} ...`);const a=setTimeout(()=>{o(new r.k(`Can't load ${e}: timeout (${t}ms)`))},t);e.addEventListener(i,t=>{clearTimeout(a),s(e)})});if(e&&e.constructor)switch(e.constructor.name){case"HTMLImageElement":return e.complete&&0!==e.naturalWidth?Promise.resolve(e):i("load");case"HTMLVideoElement":return e.readyState>=4?Promise.resolve(e):i("canplaythrough");case"HTMLCanvasElement":case"ImageBitmap":return Promise.resolve(e)}throw new r.f("Can't load the media: unrecognized media type. "+e)}(e).then(()=>{const i=function(e){if(e&&e.constructor&&e.constructor.name){const t=e.constructor.name,i={HTMLImageElement:{width:"naturalWidth",height:"naturalHeight"},HTMLVideoElement:{width:"videoWidth",height:"videoHeight"},HTMLCanvasElement:{width:"width",height:"height"},ImageBitmap:{width:"width",height:"height"}};if(i.hasOwnProperty(t))return{width:e[i[t].width],height:e[i[t].height]}}return null}(e);if(0==i.width||0==i.height)throw new r.g("Can't load media: invalid dimensions");const s=new et(e,i.width,i.height,t);return n.a.log(`Loaded SpeedyMedia with a ${e}.`),s})}static loadCameraStream(e=426,t=240,i={},s={}){return function(e,t,i={}){return new Promise((s,o)=>{if(n.a.log("Accessing the webcam..."),!navigator.mediaDevices||!navigator.mediaDevices.getUserMedia)return o(new r.i("Unsupported browser: no mediaDevices.getUserMedia()"));navigator.mediaDevices.getUserMedia({audio:!1,video:{width:{ideal:e},height:{ideal:t},aspectRatio:{ideal:e/t},facingMode:"environment",frameRate:30},...i}).then(e=>{const t=document.createElement("video");t.srcObject=e,t.onloadedmetadata=i=>{t.play(),n.a.log("The camera device is turned on!"),s(t,e)}}).catch(e=>{o(new r.b("Please give access to the camera and reload the page",e))})})}(e,t,i).then(e=>et.load(e,s))}get source(){return this._source}get width(){return this._width}get height(){return this._height}get type(){switch(this._type){case m.c.Image:return"image";case m.c.Video:return"video";case m.c.Canvas:return"canvas";case m.c.Bitmap:return"bitmap";default:return"unknown"}}get options(){return this._options}release(){return this.isReleased()||(n.a.log("Releasing SpeedyMedia object..."),this._gpu.loseWebGLContext(),this._gpu=null,this._source=null),Promise.resolve()}isReleased(){return null==this._gpu}clone(e={}){if(e={lightweight:!1,...e},this.isReleased())throw new r.g("Can't clone a SpeedyMedia that has been released");if(e.lightweight)return Promise.resolve(new et(this));if(this._type==m.c.Bitmap)return createImageBitmap(this._source).then(e=>new et(e,this._width,this._height));if(this._type==m.c.Canvas){const e=n.a.createCanvas(this._width,this._height);return this.draw(e),Promise.resolve(new et(e,this._width,this._height))}{const e=this._source.cloneNode(!0);return Promise.resolve(new et(e,this._width,this._height))}}run(e){if(this.isReleased())throw new r.g("Can't run pipeline: SpeedyMedia has been released");return this.clone({lightweight:!0}).then(t=>{let i=t._gpu.upload(t._source);return i=e._run(i,t._gpu,t),t._gpu.programs.utils.output(i),createImageBitmap(t._gpu.canvas,0,0,t.width,t.height).then(e=>(t._type=m.c.Bitmap,t._source=e,t))})}draw(e,t=0,i=0,n=this.width,r=this.height){if(this.isReleased())return;t=Math.max(+t,0),i=Math.max(+i,0),n=Math.max(+n,0),r=Math.max(+r,0),e.getContext("2d").drawImage(this._source,t,i,n,r)}toBitmap(){if(this.isReleased())throw new r.g("Can't convert to SpeedyMedia to ImageBitmap: the media has been released");return createImageBitmap(this._source)}findFeatures(e={}){e.hasOwnProperty("method")||(e.method="fast"),e.method=String(e.method);const t={fast:Qe.FAST,"multiscale-fast":Qe.MultiscaleFAST,harris:Qe.Harris,"multiscale-harris":Qe.MultiscaleHarris,orb:Qe.ORB,brisk:Qe.BRISK};if(!t.hasOwnProperty(e.method))throw new r.f(`Invalid method "${e.method}" for feature detection`);if(null==this._featureDetector||this._currFeatureDetector!==t[e.method]){const i=t[e.method];this._currFeatureDetector=i,this._featureDetector=i()}return e.hasOwnProperty("sensitivity")&&(this._featureDetector.sensitivity=+e.sensitivity),e.hasOwnProperty("max")&&(this._featureDetector.max=0|e.max),e.hasOwnProperty("denoise")&&this._featureDetector.enhance({denoise:Boolean(e.denoise)}),e.hasOwnProperty("expected")&&("object"==typeof e.expected?this._featureDetector.expect(0|e.expected.number,+e.expected.tolerance):this._featureDetector.expect(0|e.expected)),this._featureDetector.detect(this)}}const tt={};class it{constructor(){this._loadOptions=()=>({})}run(e,t,i){return e}release(){}_saveOptions(e,t={}){if("object"==typeof e){const i=Object.assign(t,e);this._loadOptions=()=>i}else{if("function"!=typeof e)throw new r.f("Expected an options object | function");this._loadOptions=()=>Object.assign(t,e())}}}tt.ConvertToGreyscale=class extends it{run(e,t,i){if(i._colorFormat==m.b.RGB)e=t.programs.colors.rgb2grey(e);else if(i._colorFormat!=m.b.Greyscale)throw new r.i("Can't convert image to greyscale: unknown color format");return i._colorFormat=m.b.Greyscale,e}},tt.Blur=class extends it{constructor(e={}){super(),this._saveOptions(e,{filter:"gaussian",size:5})}run(e,t,i){const{filter:n,size:s}=this._loadOptions();if("gaussian"!=n&&"box"!=n)throw new r.f(`Invalid filter: "${n}"`);if(3!=s&&5!=s&&7!=s)throw new r.f("Invalid kernel size: "+s);let o="gaussian"==n?"gauss":"box";return t.programs.filters[o+s](e)}},tt.Convolve=class extends it{constructor(e,t=1){let i=new Float32Array(e).map(e=>e/t);const n=i.length,s=0|Math.sqrt(n),o={3:["createKernel3x3","texConv2D3"],5:["createKernel5x5","texConv2D5"],7:["createKernel7x7","texConv2D7"]}[s]||null;if(super(),1==n)throw new r.f("Cannot convolve with a kernel containing a single element");if(s*s!=n||!o)throw new r.f(`Cannot convolve with a non-square kernel of ${n} elements`);const a=Math.min(...i),c=Math.max(...i),l=a,d=Math.abs(c-a)>1e-5?c-a:1;i=i.map(e=>(e-l)/d),this._method=o,this._scale=d,this._offset=l,this._kernel=i,this._kernelSize=s,this._texKernel=null,this._gl=null}run(e,t,i){if(t.gl.isContextLost())this._texKernel=null,this._gl=null;else if(null==this._texKernel||this._gl!==t.gl&&null!==this._gl){if(this._gl!==t.gl&&null!==this._gl&&!this._gl.isContextLost()){const e="Performance warning: need to recreate the texture kernel. Consider duplicating the pipeline when using convolutions for different media objects.";n.a.warning(e),this._texKernel.release()}this._texKernel=t.programs.filters[this._method[0]](this._kernel),this._gl=t.gl}return t.programs.filters[this._method[1]](e,this._texKernel,this._scale,this._offset)}release(){null!=this._texKernel&&(this._texKernel.release(),this._texKernel=this._gl=null),super.release()}},tt.Normalize=class extends it{constructor(e={}){super(),this._saveOptions(e,{min:void 0,max:void 0})}run(e,t,i){const{min:n,max:s}=this._loadOptions();if(i._colorFormat==m.b.RGB)return t.programs.enhancements.normalizeColoredImage(e,n,s);if(i._colorFormat==m.b.Greyscale)return t.programs.enhancements.normalizeGreyscaleImage(e,n,s);throw new r.i("Invalid color format")}},tt.Nightvision=class extends it{constructor(e={}){super(),this._saveOptions(e,{gain:void 0,offset:void 0,decay:void 0,quality:void 0})}run(e,t,i){const{gain:n,offset:s,decay:o,quality:a}=this._loadOptions();if(i._colorFormat==m.b.RGB)return t.programs.enhancements.nightvision(e,n,s,o,a,!1);if(i._colorFormat==m.b.Greyscale)return t.programs.enhancements.nightvision(e,n,s,o,a,!0);throw new r.i("Invalid color format")}};class nt{constructor(){this._operations=[]}get length(){return this._operations.length}release(){return new Promise((e,t)=>{for(let e=this._operations.length-1;e>=0;e--)this._operations[e].release();this._operations.length=0,e(this)})}_spawn(e){return this._operations.push(e),this}_run(e,t,i){for(let n=0;n<this._operations.length;n++)e=this._operations[n].run(e,t,i);return e}concat(e){if(e instanceof nt)return this._operations=this._operations.concat(e._operations),this;throw new r.f(`Invalid argument "${e}" given to SpeedyPipeline.concatenate()`)}convertTo(e=null){if("greyscale"==e||"grayscale"==e)return this._spawn(new tt.ConvertToGreyscale);throw new r.f(`Can't convert to unknown color space: "${e}"`)}blur(e={}){return this._spawn(new tt.Blur(e))}convolve(e,t=1){return this._spawn(new tt.Convolve(e,t))}normalize(e={}){return this._spawn(new tt.Normalize(e))}nightvision(e={}){return this._spawn(new tt.Nightvision(e))}}let rt=null;class st{constructor(){if(this._fps=60,this._frames=0,this._updateInterval=500,this._lastUpdate=performance.now(),this._boundUpdate=this._update.bind(this),null!==rt)throw new r.g("Can't have multiple instances of FPSCounter");this._boundUpdate()}static get instance(){return null===rt&&(rt=new st),rt}get fps(){return this._fps}_update(){const e=performance.now(),t=e-this._lastUpdate;t>=this._updateInterval&&(this._fps=Math.round(this._frames/(.001*t)),this._frames=0,this._lastUpdate=e),this._frames++,requestAnimationFrame(this._boundUpdate)}}class ot extends Ne{constructor(){super(),this._downloader.disableBufferedDownloads()}track(e,t,i,n,s){throw new r.a}download(e,t,i,n=!0,r){const s=r?{discard:r,userData:[]}:void 0;return this._downloader.download(e,t,i,void 0,n,s).then(e=>{if(r)for(let e=0;e<r.length;e++)r[e]=r[e]||s.userData[e]>0;return e})}upload(e,t,i){return e.programs.encoders.uploadKeypoints(t,i)}}const at={[Re.F32]:Float32Array,[Re.U8]:Uint8Array};class ct extends class{constructor(e,t,i=Re.F32){this._type=-4&i;const n=1+(3&i),s=at[this._type];if(e<=0||t<=0)throw new r.f("Invalid dimensions");if(n<1||n>4)throw new r.f("Invalid number of channels");if(null==s)throw new r.f("Invalid data type");this._rows=0|e,this._cols=0|t,this._channels=n,this._length=this._rows*this._cols*this._channels,this._data=new s(this._length)}get rows(){return this._rows}get columns(){return this._cols}get channels(){return this._channels}toString(){return`SpeedyMatrix(${this._rows}, ${this._cols})`}at(e,t=0){return this._data[e*this._cols+t]}fill(e){const t=this._length;for(let i=0;i<t;i++)this._data[i]=e;return this}}{constructor(e,t){super(2,1,Re.F32),this._data[0]=e,this._data[1]=t}get x(){return this._data[0]}set x(e){this._data[0]=e}get y(){return this._data[1]}set y(e){this._data[1]=e}toString(){return`SpeedyVector2(${this._data[0]}, ${this._data[1]})`}at(e){return this._data[e]}dot(e){return this._data[0]*e._data[0]+this._data[1]*e._data[1]}distanceTo(e){const t=this._data[0]-e._data[0],i=this._data[1]-e._data[1];return Math.sqrt(t*t+i*i)}length(){return Math.sqrt(this._data[0]*this._data[0]+this._data[1]*this._data[1])}normalize(){const e=this.length();return 0==e?(this._data[0]=this._data[1]=0,this):(this._data[0]/=e,this._data[1]/=e,this)}}class lt extends ot{track(e,t,i,n,r,s=21,o=5,a=1e-4){const c=t.generateMipmap(),l=i.generateMipmap(),d=e.programs.encoders.encoderLength;return e.programs.trackers.lk(c,l,n,s,o,a,r,d)}}class dt extends class{constructor(e,t){this._media=t,this._trackingAlgorithm=e,this._descriptionAlgorithm=null,this._inputTexture=null,this._prevInputTexture=null,this._updateLock=!1}includeDescriptor(e){const t=e._algorithm;return this._descriptionAlgorithm=t,this}track(e,t=null,i=null){const n=this._media._gpu;if(!Array.isArray(e)||null!=i&&!Array.isArray(i)||null!=t&&!Array.isArray(t))throw new r.f;this._updateMedia(this._media,n);const s=this._inputTexture,o=this._prevInputTexture,a=null!=this._descriptionAlgorithm?this._descriptionAlgorithm.descriptorSize:0,c="static"!=this._media.options.usage;n.programs.encoders.reserveSpace(e.length,a);const l=this._trackingAlgorithm.upload(n,e,a),d=this._trackFeatures(n,s,o,l,a),f=null==this._descriptionAlgorithm?d:this._descriptionAlgorithm.describe(n,s,d),p=[];return this._trackingAlgorithm.download(n,f,a,c,p).then(n=>{const r=[];null!=i&&(i.length=n.length),null!=t&&(t.length=n.length);for(let s=0;s<n.length;s++){const o=!p[s];o&&r.push(n[s]),null!=i&&(i[s]=o),null!=t&&(t[s]=o?new ct(n[s].x-e[s].x,n[s].y-e[s].y):new ct(0,0))}return r})}_updateMedia(e,t){if(e.isReleased())throw new r.g("The media has been released");if(this._updateLock)return;setTimeout(()=>this._updateLock=!1,20),this._updateLock=!0;const i=t.upload(e.source);if(this._prevInputTexture=this._inputTexture,this._inputTexture=i,null==this._inputTexture)throw new r.g("Tracking error: can't upload image to the GPU "+e.source);null==this._prevInputTexture&&(this._prevInputTexture=i)}_trackFeatures(e,t,i,n,r){return this._trackingAlgorithm.track(e,t,i,n,r)}}{constructor(e){super(new lt,e),this._windowSize=15,this._depth=5,this._discardThreshold=1e-4}_trackFeatures(e,t,i,n,r){return this._trackingAlgorithm.track(e,t,i,n,r,this._windowSize,this._depth,this._discardThreshold)}get windowSize(){return this._windowSize}set windowSize(e){if("number"!=typeof e||e<1||e%2==0)throw new r.f("Window newSize must be a positive odd number");this._windowSize=0|e}get depth(){return this._depth}set depth(e){if("number"!=typeof e||e<1)throw new r.f("Invalid depth: "+e);this._depth=0|e}get discardThreshold(){return this._discardThreshold}set discardThreshold(e){if("number"!=typeof e)throw new r.f("Invalid discardThreshold");this._discardThreshold=Math.max(0,e)}}class ft extends Le{static LK(e){return new dt(e)}}class pt{static load(e,t={}){return et.load(e,t)}static camera(e=426,t=240,i={},n={}){return et.loadCameraStream(e,t,i,n)}static pipeline(){return new nt}static get version(){return"0.4.0"}static get fps(){return st.instance.fps}static get FeatureDetector(){return Qe}static get FeatureTracker(){return ft}static Vector2(e,t){return new ct(e,t)}}Object.assign(pt.constructor.prototype,Re)}]);